{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":271117,"sourceType":"datasetVersion","datasetId":113673}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyts","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:57:06.272265Z","iopub.execute_input":"2025-04-28T10:57:06.272541Z","iopub.status.idle":"2025-04-28T10:57:12.639747Z","shell.execute_reply.started":"2025-04-28T10:57:06.272515Z","shell.execute_reply":"2025-04-28T10:57:12.638417Z"}},"outputs":[{"name":"stdout","text":"Collecting pyts\n  Downloading pyts-0.13.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.26.4)\nRequirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.15.2)\nRequirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.4.2)\nRequirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.11/dist-packages (from pyts) (0.60.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.55.2->pyts) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (2.4.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pyts) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.4->pyts) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.4->pyts) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pyts) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.4->pyts) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.4->pyts) (2024.2.0)\nDownloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyts\nSuccessfully installed pyts-0.13.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom pyts.image import GramianAngularField\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\ndef root_directory():\n    \"\"\"Returns the root directory of the project.\"\"\"\n    return \"/kaggle/input/swell-heart-rate-variability-hrv/hrv dataset\"\n\ndef data_directory():\n    \"\"\"Returns the data directory path.\"\"\"\n    return os.path.join(root_directory(), \"data\") \ndef load_train_set():\n    \"\"\"Loads training dataset as a Pandas DataFrame.\"\"\"\n    train_file = os.path.join(data_directory(), \"final\", \"train.csv\")\n    return pd.read_csv(train_file)\n\ndef load_test_set():\n    \"\"\"Loads test dataset as a Pandas DataFrame.\"\"\"\n    test_file = os.path.join(data_directory(), \"final\", \"test.csv\")\n    return pd.read_csv(test_file)\n\n\ntrain = load_train_set()\ntest = load_test_set()\n\ntarget = \"condition\"\n\nhrv_features = [col for col in train.columns if col != target]\n\nlabel_map = {\"no stress\": 0, \"interruption\": 1, \"time pressure\": 2}\ntrain[target] = train[target].map(label_map)\ntest[target] = test[target].map(label_map)\n\n\ndef sample_data(df, label_col, n_samples):\n    \"\"\"Safely sample n_samples per class without errors.\"\"\"\n    sampled_df = []\n    for label in df[label_col].unique():\n        class_data = df[df[label_col] == label]\n        sample_size = min(n_samples, len(class_data)) \n        sampled_df.append(class_data.sample(n=sample_size, random_state=42))\n    return pd.concat(sampled_df).reset_index(drop=True)\n\ntrain_balanced = sample_data(train, target, 10000)\ntest_balanced = sample_data(test, target, 3000)  \n\nX_train = train_balanced[hrv_features]\ny_train = train_balanced[target]\n\nif \"datasetId\" in X_train.columns:\n    X_train = X_train.drop(columns=\"datasetId\")\n\n\nX_test = test_balanced[hrv_features]\ny_test = test_balanced[target]\n\n\nif \"datasetId\" in X_test.columns:\n    X_test = X_test.drop(columns=\"datasetId\")\n\n\nprint(f\"Train Set Shape: {X_train.shape}, Labels Shape: {y_train.shape}\")\nprint(f\"Test Set Shape: {X_test.shape}, Labels Shape: {y_test.shape}\")\n\ndisplay(X_train.head())\ndisplay(y_train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:57:58.276139Z","iopub.execute_input":"2025-04-28T10:57:58.276459Z","iopub.status.idle":"2025-04-28T10:58:03.049546Z","shell.execute_reply.started":"2025-04-28T10:57:58.276437Z","shell.execute_reply":"2025-04-28T10:58:03.048599Z"}},"outputs":[{"name":"stdout","text":"Train Set Shape: (30000, 34), Labels Shape: (30000,)\nTest Set Shape: (9000, 34), Labels Shape: (9000,)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      MEAN_RR   MEDIAN_RR        SDRR      RMSSD       SDSD  SDRR_RMSSD  \\\n0  896.720876  880.459590  106.101117  13.924951  13.924949    7.619497   \n1  903.325242  905.495460   72.285411  12.387407  12.386563    5.835395   \n2  934.870026  916.307545  128.556268  16.728592  16.728579    7.684823   \n3  726.048217  726.396200   58.167902   9.760850   9.760850    5.959307   \n4  903.212333  918.237180  108.998652  16.905228  16.905228    6.447630   \n\n          HR      pNN25     pNN50        SD1  ...     LF_PCT      LF_NU  \\\n0  67.818401   7.733333  0.466667   9.849712  ...  28.035932  98.809256   \n1  66.855229   4.466667  0.133333   8.761546  ...  23.244445  99.726832   \n2  65.364253  13.200000  1.066667  11.832839  ...  28.280122  99.507931   \n3  83.181060   1.400000  0.000000   6.904267  ...  22.022647  93.990424   \n4  67.479959  12.400000  1.333333  11.957790  ...  23.825552  98.769012   \n\n          HF    HF_PCT     HF_NU           TP       LF_HF     HF_LF    sampen  \\\n0   9.922258  0.337859  1.190744  2936.803667   82.981135  0.012051  2.127076   \n1   1.783522  0.063670  0.273168  2801.178306  365.074431  0.002739  2.192351   \n2   6.164162  0.139846  0.492069  4407.828115  202.223606  0.004945  2.160318   \n3  26.015607  1.408088  6.009576  1847.584044   15.640109  0.063938  2.157452   \n4  13.625402  0.296945  1.230988  4588.526989   80.235569  0.012463  2.179244   \n\n     higuci  \n0  1.134921  \n1  1.069071  \n2  1.126186  \n3  1.152640  \n4  1.177820  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEAN_RR</th>\n      <th>MEDIAN_RR</th>\n      <th>SDRR</th>\n      <th>RMSSD</th>\n      <th>SDSD</th>\n      <th>SDRR_RMSSD</th>\n      <th>HR</th>\n      <th>pNN25</th>\n      <th>pNN50</th>\n      <th>SD1</th>\n      <th>...</th>\n      <th>LF_PCT</th>\n      <th>LF_NU</th>\n      <th>HF</th>\n      <th>HF_PCT</th>\n      <th>HF_NU</th>\n      <th>TP</th>\n      <th>LF_HF</th>\n      <th>HF_LF</th>\n      <th>sampen</th>\n      <th>higuci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>896.720876</td>\n      <td>880.459590</td>\n      <td>106.101117</td>\n      <td>13.924951</td>\n      <td>13.924949</td>\n      <td>7.619497</td>\n      <td>67.818401</td>\n      <td>7.733333</td>\n      <td>0.466667</td>\n      <td>9.849712</td>\n      <td>...</td>\n      <td>28.035932</td>\n      <td>98.809256</td>\n      <td>9.922258</td>\n      <td>0.337859</td>\n      <td>1.190744</td>\n      <td>2936.803667</td>\n      <td>82.981135</td>\n      <td>0.012051</td>\n      <td>2.127076</td>\n      <td>1.134921</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>903.325242</td>\n      <td>905.495460</td>\n      <td>72.285411</td>\n      <td>12.387407</td>\n      <td>12.386563</td>\n      <td>5.835395</td>\n      <td>66.855229</td>\n      <td>4.466667</td>\n      <td>0.133333</td>\n      <td>8.761546</td>\n      <td>...</td>\n      <td>23.244445</td>\n      <td>99.726832</td>\n      <td>1.783522</td>\n      <td>0.063670</td>\n      <td>0.273168</td>\n      <td>2801.178306</td>\n      <td>365.074431</td>\n      <td>0.002739</td>\n      <td>2.192351</td>\n      <td>1.069071</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>934.870026</td>\n      <td>916.307545</td>\n      <td>128.556268</td>\n      <td>16.728592</td>\n      <td>16.728579</td>\n      <td>7.684823</td>\n      <td>65.364253</td>\n      <td>13.200000</td>\n      <td>1.066667</td>\n      <td>11.832839</td>\n      <td>...</td>\n      <td>28.280122</td>\n      <td>99.507931</td>\n      <td>6.164162</td>\n      <td>0.139846</td>\n      <td>0.492069</td>\n      <td>4407.828115</td>\n      <td>202.223606</td>\n      <td>0.004945</td>\n      <td>2.160318</td>\n      <td>1.126186</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>726.048217</td>\n      <td>726.396200</td>\n      <td>58.167902</td>\n      <td>9.760850</td>\n      <td>9.760850</td>\n      <td>5.959307</td>\n      <td>83.181060</td>\n      <td>1.400000</td>\n      <td>0.000000</td>\n      <td>6.904267</td>\n      <td>...</td>\n      <td>22.022647</td>\n      <td>93.990424</td>\n      <td>26.015607</td>\n      <td>1.408088</td>\n      <td>6.009576</td>\n      <td>1847.584044</td>\n      <td>15.640109</td>\n      <td>0.063938</td>\n      <td>2.157452</td>\n      <td>1.152640</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>903.212333</td>\n      <td>918.237180</td>\n      <td>108.998652</td>\n      <td>16.905228</td>\n      <td>16.905228</td>\n      <td>6.447630</td>\n      <td>67.479959</td>\n      <td>12.400000</td>\n      <td>1.333333</td>\n      <td>11.957790</td>\n      <td>...</td>\n      <td>23.825552</td>\n      <td>98.769012</td>\n      <td>13.625402</td>\n      <td>0.296945</td>\n      <td>1.230988</td>\n      <td>4588.526989</td>\n      <td>80.235569</td>\n      <td>0.012463</td>\n      <td>2.179244</td>\n      <td>1.177820</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0    0\n1    0\n2    0\n3    0\n4    0\nName: condition, dtype: int64"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def quantile_normalize(df):\n    \"\"\"Applies quantile normalization to the DataFrame.\"\"\"\n    df_sorted = pd.DataFrame(np.sort(df.values, axis=0), index=df.index, columns=df.columns)\n    df_mean = df_sorted.mean(axis=1)\n    df_mean.index = np.arange(1, len(df_mean) + 1)\n    df_qn = df.rank(method=\"min\").stack().astype(int).map(df_mean).unstack()\n    return df_qn\n\nx_train_swell = quantile_normalize(X_train)\nx_test_swell = quantile_normalize(X_test)\n\ndisplay(x_train_swell.head())\ndisplay(x_test_swell.head())\nprint(x_train_swell.describe())\nprint(x_test_swell.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:59:04.180030Z","iopub.execute_input":"2025-04-28T10:59:04.180383Z","iopub.status.idle":"2025-04-28T10:59:04.947773Z","shell.execute_reply.started":"2025-04-28T10:59:04.180358Z","shell.execute_reply":"2025-04-28T10:59:04.946970Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"      MEAN_RR   MEDIAN_RR        SDRR       RMSSD        SDSD  SDRR_RMSSD  \\\n0  276.697101  261.548330  281.634094  201.939225  201.948873  306.099269   \n1  283.060633  290.437894  183.073989  167.021640  166.952993  215.238532   \n2  312.856441  298.311570  333.659979  277.912510  277.935225  309.649467   \n3  118.124366  124.548167  136.809099  117.415260  117.430190  221.768654   \n4  282.869530  300.263695  289.169845  283.041251  283.046942  248.500700   \n\n           HR       pNN25       pNN50         SD1  ...      LF_PCT  \\\n0  186.792253  220.098299  219.751609  201.948873  ...  209.281585   \n1  178.099179  165.854182  166.058400  166.952993  ...  175.512435   \n2  167.908511  315.431057  277.893149  277.935225  ...  211.163474   \n3  463.050505  112.676927   57.594885  117.430190  ...  165.622387   \n4  183.634928  300.234227  309.342415  283.046942  ...  179.713401   \n\n        LF_NU          HF      HF_PCT       HF_NU          TP       LF_HF  \\\n0  309.383929  166.989622  170.844721  172.502720  229.176610  309.383929   \n1  527.319177  104.591577  111.702021  111.394438  220.181001  527.319177   \n2  434.164037  141.753598  139.078646  129.723889  339.437487  434.164037   \n3  158.516499  250.212396  280.129440  339.707893  158.679659  158.516499   \n4  305.818680  184.847490  165.565337  174.383861  355.878824  305.818680   \n\n        HF_LF      sampen      higuci  \n0  172.502720  220.280335  160.774105  \n1  111.394438  390.664047   91.473882  \n2  129.723889  264.643133  147.015168  \n3  339.707893  259.802904  193.893174  \n4  174.383861  315.449174  240.393451  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEAN_RR</th>\n      <th>MEDIAN_RR</th>\n      <th>SDRR</th>\n      <th>RMSSD</th>\n      <th>SDSD</th>\n      <th>SDRR_RMSSD</th>\n      <th>HR</th>\n      <th>pNN25</th>\n      <th>pNN50</th>\n      <th>SD1</th>\n      <th>...</th>\n      <th>LF_PCT</th>\n      <th>LF_NU</th>\n      <th>HF</th>\n      <th>HF_PCT</th>\n      <th>HF_NU</th>\n      <th>TP</th>\n      <th>LF_HF</th>\n      <th>HF_LF</th>\n      <th>sampen</th>\n      <th>higuci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276.697101</td>\n      <td>261.548330</td>\n      <td>281.634094</td>\n      <td>201.939225</td>\n      <td>201.948873</td>\n      <td>306.099269</td>\n      <td>186.792253</td>\n      <td>220.098299</td>\n      <td>219.751609</td>\n      <td>201.948873</td>\n      <td>...</td>\n      <td>209.281585</td>\n      <td>309.383929</td>\n      <td>166.989622</td>\n      <td>170.844721</td>\n      <td>172.502720</td>\n      <td>229.176610</td>\n      <td>309.383929</td>\n      <td>172.502720</td>\n      <td>220.280335</td>\n      <td>160.774105</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>283.060633</td>\n      <td>290.437894</td>\n      <td>183.073989</td>\n      <td>167.021640</td>\n      <td>166.952993</td>\n      <td>215.238532</td>\n      <td>178.099179</td>\n      <td>165.854182</td>\n      <td>166.058400</td>\n      <td>166.952993</td>\n      <td>...</td>\n      <td>175.512435</td>\n      <td>527.319177</td>\n      <td>104.591577</td>\n      <td>111.702021</td>\n      <td>111.394438</td>\n      <td>220.181001</td>\n      <td>527.319177</td>\n      <td>111.394438</td>\n      <td>390.664047</td>\n      <td>91.473882</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>312.856441</td>\n      <td>298.311570</td>\n      <td>333.659979</td>\n      <td>277.912510</td>\n      <td>277.935225</td>\n      <td>309.649467</td>\n      <td>167.908511</td>\n      <td>315.431057</td>\n      <td>277.893149</td>\n      <td>277.935225</td>\n      <td>...</td>\n      <td>211.163474</td>\n      <td>434.164037</td>\n      <td>141.753598</td>\n      <td>139.078646</td>\n      <td>129.723889</td>\n      <td>339.437487</td>\n      <td>434.164037</td>\n      <td>129.723889</td>\n      <td>264.643133</td>\n      <td>147.015168</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>118.124366</td>\n      <td>124.548167</td>\n      <td>136.809099</td>\n      <td>117.415260</td>\n      <td>117.430190</td>\n      <td>221.768654</td>\n      <td>463.050505</td>\n      <td>112.676927</td>\n      <td>57.594885</td>\n      <td>117.430190</td>\n      <td>...</td>\n      <td>165.622387</td>\n      <td>158.516499</td>\n      <td>250.212396</td>\n      <td>280.129440</td>\n      <td>339.707893</td>\n      <td>158.679659</td>\n      <td>158.516499</td>\n      <td>339.707893</td>\n      <td>259.802904</td>\n      <td>193.893174</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>282.869530</td>\n      <td>300.263695</td>\n      <td>289.169845</td>\n      <td>283.041251</td>\n      <td>283.046942</td>\n      <td>248.500700</td>\n      <td>183.634928</td>\n      <td>300.234227</td>\n      <td>309.342415</td>\n      <td>283.046942</td>\n      <td>...</td>\n      <td>179.713401</td>\n      <td>305.818680</td>\n      <td>184.847490</td>\n      <td>165.565337</td>\n      <td>174.383861</td>\n      <td>355.878824</td>\n      <td>305.818680</td>\n      <td>174.383861</td>\n      <td>315.449174</td>\n      <td>240.393451</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      MEAN_RR   MEDIAN_RR        SDRR       RMSSD        SDSD  SDRR_RMSSD  \\\n0  154.981903  130.948799  357.917964  218.603896  218.603896  399.488499   \n1  206.332670  212.064032  158.559158  158.894224  158.894224  188.846044   \n2  108.774609  110.761248  174.510012  123.887169  123.887169  272.919928   \n3  184.635339  206.397936  343.041840  204.879360  204.879360  387.853716   \n4  173.729083  170.568761  115.378578  158.499353  158.499353  143.334814   \n\n           HR       pNN25       pNN50         SD1  ...      LF_PCT  \\\n0  376.844594  226.243094  239.203434  218.603896  ...  181.232421   \n1  240.684831  152.445046   58.596835  158.894224  ...  190.435567   \n2  513.057777  134.679136   58.596835  123.887169  ...  207.303791   \n3  305.771471  206.484818  278.290686  204.879360  ...  166.258531   \n4  289.746416  143.353928   58.596835  158.499353  ...  522.481666   \n\n        LF_NU          HF      HF_PCT       HF_NU          TP       LF_HF  \\\n0  142.039242  396.002894  311.944479  386.663115  242.885987  142.039242   \n1  171.716120  259.323638  280.144485  306.319210  163.331167  171.716120   \n2  223.802244  209.252014  228.533895  232.983896  175.664416  223.802244   \n3  211.404028  272.407888  219.344145  244.743676  281.113670  211.404028   \n4  276.389324  196.987243  244.559104  188.324377  140.363456  276.389324   \n\n        HF_LF      sampen      higuci  \n0  386.663115   94.875043  272.298257  \n1  306.319210  250.749993  301.416603  \n2  232.983896  297.822034  161.413623  \n3  244.743676  194.813778  174.500443  \n4  188.324377  267.048739  166.388660  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEAN_RR</th>\n      <th>MEDIAN_RR</th>\n      <th>SDRR</th>\n      <th>RMSSD</th>\n      <th>SDSD</th>\n      <th>SDRR_RMSSD</th>\n      <th>HR</th>\n      <th>pNN25</th>\n      <th>pNN50</th>\n      <th>SD1</th>\n      <th>...</th>\n      <th>LF_PCT</th>\n      <th>LF_NU</th>\n      <th>HF</th>\n      <th>HF_PCT</th>\n      <th>HF_NU</th>\n      <th>TP</th>\n      <th>LF_HF</th>\n      <th>HF_LF</th>\n      <th>sampen</th>\n      <th>higuci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>154.981903</td>\n      <td>130.948799</td>\n      <td>357.917964</td>\n      <td>218.603896</td>\n      <td>218.603896</td>\n      <td>399.488499</td>\n      <td>376.844594</td>\n      <td>226.243094</td>\n      <td>239.203434</td>\n      <td>218.603896</td>\n      <td>...</td>\n      <td>181.232421</td>\n      <td>142.039242</td>\n      <td>396.002894</td>\n      <td>311.944479</td>\n      <td>386.663115</td>\n      <td>242.885987</td>\n      <td>142.039242</td>\n      <td>386.663115</td>\n      <td>94.875043</td>\n      <td>272.298257</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>206.332670</td>\n      <td>212.064032</td>\n      <td>158.559158</td>\n      <td>158.894224</td>\n      <td>158.894224</td>\n      <td>188.846044</td>\n      <td>240.684831</td>\n      <td>152.445046</td>\n      <td>58.596835</td>\n      <td>158.894224</td>\n      <td>...</td>\n      <td>190.435567</td>\n      <td>171.716120</td>\n      <td>259.323638</td>\n      <td>280.144485</td>\n      <td>306.319210</td>\n      <td>163.331167</td>\n      <td>171.716120</td>\n      <td>306.319210</td>\n      <td>250.749993</td>\n      <td>301.416603</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>108.774609</td>\n      <td>110.761248</td>\n      <td>174.510012</td>\n      <td>123.887169</td>\n      <td>123.887169</td>\n      <td>272.919928</td>\n      <td>513.057777</td>\n      <td>134.679136</td>\n      <td>58.596835</td>\n      <td>123.887169</td>\n      <td>...</td>\n      <td>207.303791</td>\n      <td>223.802244</td>\n      <td>209.252014</td>\n      <td>228.533895</td>\n      <td>232.983896</td>\n      <td>175.664416</td>\n      <td>223.802244</td>\n      <td>232.983896</td>\n      <td>297.822034</td>\n      <td>161.413623</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>184.635339</td>\n      <td>206.397936</td>\n      <td>343.041840</td>\n      <td>204.879360</td>\n      <td>204.879360</td>\n      <td>387.853716</td>\n      <td>305.771471</td>\n      <td>206.484818</td>\n      <td>278.290686</td>\n      <td>204.879360</td>\n      <td>...</td>\n      <td>166.258531</td>\n      <td>211.404028</td>\n      <td>272.407888</td>\n      <td>219.344145</td>\n      <td>244.743676</td>\n      <td>281.113670</td>\n      <td>211.404028</td>\n      <td>244.743676</td>\n      <td>194.813778</td>\n      <td>174.500443</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>173.729083</td>\n      <td>170.568761</td>\n      <td>115.378578</td>\n      <td>158.499353</td>\n      <td>158.499353</td>\n      <td>143.334814</td>\n      <td>289.746416</td>\n      <td>143.353928</td>\n      <td>58.596835</td>\n      <td>158.499353</td>\n      <td>...</td>\n      <td>522.481666</td>\n      <td>276.389324</td>\n      <td>196.987243</td>\n      <td>244.559104</td>\n      <td>188.324377</td>\n      <td>140.363456</td>\n      <td>276.389324</td>\n      <td>188.324377</td>\n      <td>267.048739</td>\n      <td>166.388660</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"            MEAN_RR     MEDIAN_RR          SDRR         RMSSD          SDSD  \\\ncount  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \nmean     272.534334    272.434753    272.534334    272.534334    272.534334   \nstd      161.064480    160.681748    161.064480    161.064480    161.064480   \nmin       57.594885     57.594885     57.594885     57.594885     57.594885   \n25%      161.769849    161.769849    161.769849    161.769849    161.769849   \n50%      229.496375    229.489324    229.496375    229.496375    229.496375   \n75%      332.274137    332.242212    332.274137    332.274137    332.274137   \nmax     1242.394745   1144.375092   1242.394745   1242.394745   1242.394745   \n\n         SDRR_RMSSD            HR         pNN25         pNN50           SD1  \\\ncount  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \nmean     272.534334    272.534334    271.779447    253.502644    272.534334   \nstd      161.064480    161.064480    160.934737    173.991796    161.064480   \nmin       57.594885     57.594885     57.594885     57.594885     57.594885   \n25%      161.769849    161.769849    161.525190    157.635702    161.769849   \n50%      229.496375    229.496375    228.712355    224.236676    229.496375   \n75%      332.274137    332.274137    331.051105    332.262775    332.274137   \nmax     1242.394745   1242.394745   1242.394745   1242.394745   1242.394745   \n\n       ...        LF_PCT         LF_NU            HF        HF_PCT  \\\ncount  ...  30000.000000  30000.000000  30000.000000  30000.000000   \nmean   ...    272.534334    272.534334    272.534334    272.534334   \nstd    ...    161.064480    161.064480    161.064480    161.064480   \nmin    ...     57.594885     57.594885     57.594885     57.594885   \n25%    ...    161.769849    161.769849    161.769849    161.769849   \n50%    ...    229.496375    229.496375    229.496375    229.496375   \n75%    ...    332.274137    332.274137    332.274137    332.274137   \nmax    ...   1242.394745   1242.394745   1242.394745   1242.394745   \n\n              HF_NU            TP         LF_HF         HF_LF        sampen  \\\ncount  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \nmean     272.534334    272.534334    272.534334    272.534334    272.518826   \nstd      161.064480    161.064480    161.064480    161.064480    161.039607   \nmin       57.594885     57.594885     57.594885     57.594885     57.594885   \n25%      161.769849    161.769849    161.769849    161.769849    161.768069   \n50%      229.496375    229.496375    229.496375    229.496375    229.496375   \n75%      332.274137    332.274137    332.274137    332.274137    332.262775   \nmax     1242.394745   1242.394745   1242.394745   1242.394745   1242.394745   \n\n             higuci  \ncount  30000.000000  \nmean     272.534334  \nstd      161.064480  \nmin       57.594885  \n25%      161.769849  \n50%      229.496375  \n75%      332.274137  \nmax     1242.394745  \n\n[8 rows x 34 columns]\n           MEAN_RR    MEDIAN_RR         SDRR        RMSSD         SDSD  \\\ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000   \nmean    270.802541   270.717383   270.802541   270.802541   270.802541   \nstd     160.659658   160.343754   160.659658   160.659658   160.659658   \nmin      58.596835    58.596835    58.596835    58.596835    58.596835   \n25%     160.556477   160.556477   160.556477   160.556477   160.556477   \n50%     228.452560   228.452560   228.452560   228.452560   228.452560   \n75%     330.168948   330.168948   330.168948   330.168948   330.168948   \nmax    1234.324066  1167.337049  1234.324066  1234.324066  1234.324066   \n\n        SDRR_RMSSD           HR        pNN25        pNN50          SD1  ...  \\\ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000  ...   \nmean    270.802541   270.802541   270.047725   252.342726   270.802541  ...   \nstd     160.659658   160.659658   160.541381   173.061263   160.659658  ...   \nmin      58.596835    58.596835    58.596835    58.596835    58.596835  ...   \n25%     160.556477   160.556477   160.241940   156.411510   160.556477  ...   \n50%     228.452560   228.452560   227.704178   223.068524   228.452560  ...   \n75%     330.168948   330.168948   329.177168   327.284772   330.168948  ...   \nmax    1234.324066  1234.324066  1234.324066  1234.324066  1234.324066  ...   \n\n            LF_PCT        LF_NU           HF       HF_PCT        HF_NU  \\\ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000   \nmean    270.802541   270.802541   270.802541   270.802541   270.802541   \nstd     160.659658   160.659658   160.659658   160.659658   160.659658   \nmin      58.596835    58.596835    58.596835    58.596835    58.596835   \n25%     160.556477   160.556477   160.556477   160.556477   160.556477   \n50%     228.452560   228.452560   228.452560   228.452560   228.452560   \n75%     330.168948   330.168948   330.168948   330.168948   330.168948   \nmax    1234.324066  1234.324066  1234.324066  1234.324066  1234.324066   \n\n                TP        LF_HF        HF_LF       sampen       higuci  \ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000  \nmean    270.802541   270.802541   270.802541   270.783826   270.802541  \nstd     160.659658   160.659658   160.659658   160.619619   160.659658  \nmin      58.596835    58.596835    58.596835    58.596835    58.596835  \n25%     160.556477   160.556477   160.556477   160.535503   160.556477  \n50%     228.452560   228.452560   228.452560   228.452560   228.452560  \n75%     330.168948   330.168948   330.168948   330.120840   330.168948  \nmax    1234.324066  1234.324066  1234.324066  1234.324066  1234.324066  \n\n[8 rows x 34 columns]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"gaf = GramianAngularField()\n\nX_train_gaf = gaf.fit_transform(X_train.to_numpy())\nX_test_gaf = gaf.fit_transform(X_test.to_numpy())\n\nX_train_gaf = X_train_gaf.reshape(X_train_gaf.shape[0], 34, 34, 1)\nX_test_gaf = X_test_gaf.reshape(X_test_gaf.shape[0], 34, 34, 1)\n\nX_train_gaf /= np.max(X_train_gaf, axis=(1, 2, 3), keepdims=True)\nX_test_gaf /= np.max(X_test_gaf, axis=(1, 2, 3), keepdims=True)\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=3)\nprint(X_train_gaf.shape)\nprint(X_test_gaf.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:59:11.620958Z","iopub.execute_input":"2025-04-28T10:59:11.621294Z","iopub.status.idle":"2025-04-28T10:59:16.853818Z","shell.execute_reply.started":"2025-04-28T10:59:11.621268Z","shell.execute_reply":"2025-04-28T10:59:16.852990Z"}},"outputs":[{"name":"stdout","text":"(30000, 34, 34, 1)\n(9000, 34, 34, 1)\n(30000, 3)\n(9000, 3)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"x_train_lstm = X_train_gaf.reshape(-1, 34, 34)\nx_test_lstm = X_test_gaf.reshape(-1, 34, 34)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:59:22.659456Z","iopub.execute_input":"2025-04-28T10:59:22.659807Z","iopub.status.idle":"2025-04-28T10:59:22.665065Z","shell.execute_reply.started":"2025-04-28T10:59:22.659774Z","shell.execute_reply":"2025-04-28T10:59:22.663786Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(\"Train set:\", x_train_lstm.shape, y_train.shape)   \nprint(\"Test set:\", x_test_lstm.shape, y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:59:25.958229Z","iopub.execute_input":"2025-04-28T10:59:25.958541Z","iopub.status.idle":"2025-04-28T10:59:25.964259Z","shell.execute_reply.started":"2025-04-28T10:59:25.958517Z","shell.execute_reply":"2025-04-28T10:59:25.962993Z"}},"outputs":[{"name":"stdout","text":"Train set: (30000, 34, 34) (30000, 3)\nTest set: (9000, 34, 34) (9000, 3)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    return true_positives / (predicted_positives + K.epsilon())\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T10:59:29.087664Z","iopub.execute_input":"2025-04-28T10:59:29.088042Z","iopub.status.idle":"2025-04-28T10:59:29.097122Z","shell.execute_reply.started":"2025-04-28T10:59:29.088004Z","shell.execute_reply":"2025-04-28T10:59:29.095989Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\n# Mean Absolute Error (MAE)\ndef mae_m(y_true, y_pred):\n    y_true = K.cast(y_true, dtype='float32')  \n    y_pred = K.cast(y_pred, dtype='float32')  \n    return K.mean(K.abs(y_true - y_pred))\n\ndef mape_m(y_true, y_pred):\n    y_true = K.cast(y_true, dtype='float32')\n    y_pred = K.cast(y_pred, dtype='float32')\n    diff = K.abs(y_true - y_pred)\n    denom = K.maximum(K.abs(y_true), 1.0)  # Use 1.0 instead of tiny epsilon\n    return 100.0 * K.mean(diff / denom)\n\n# Root Mean Squared Error (RMSE)\ndef rmse_m(y_true, y_pred):\n    y_true = K.cast(y_true, dtype='float32')\n    y_pred = K.cast(y_pred, dtype='float32')\n    return K.sqrt(K.mean(K.square(y_true - y_pred)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:00:30.944978Z","iopub.execute_input":"2025-04-28T11:00:30.945312Z","iopub.status.idle":"2025-04-28T11:00:30.953201Z","shell.execute_reply.started":"2025-04-28T11:00:30.945288Z","shell.execute_reply":"2025-04-28T11:00:30.952256Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, regularizers, callbacks\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, BatchNormalization, Dense, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\n\ndef model_BiLSTM():\n    model = Sequential()\n    model.add(Bidirectional(LSTM(64, return_sequences=True, activation='tanh'), input_shape=(34, 34)))\n    model.add(BatchNormalization())\n    model.add(Bidirectional(LSTM(64, return_sequences=True, activation='tanh')))\n    model.add(BatchNormalization())\n    model.add(Bidirectional(LSTM(64, activation='tanh')))\n    model.add(BatchNormalization())\n    model.add(Dense(6)) \n    model.add(Dense(3, activation='softmax'))  \n    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m,mae_m, mape_m, rmse_m])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:04:35.393486Z","iopub.execute_input":"2025-04-28T11:04:35.393820Z","iopub.status.idle":"2025-04-28T11:04:35.402323Z","shell.execute_reply.started":"2025-04-28T11:04:35.393798Z","shell.execute_reply":"2025-04-28T11:04:35.401021Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model=model_BiLSTM()\nloss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss=loss,\n    metrics=['accuracy', f1_m, precision_m, recall_m,mae_m, mape_m, rmse_m] \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:04:43.538084Z","iopub.execute_input":"2025-04-28T11:04:43.539226Z","iopub.status.idle":"2025-04-28T11:04:43.786082Z","shell.execute_reply.started":"2025-04-28T11:04:43.539182Z","shell.execute_reply":"2025-04-28T11:04:43.785288Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"'''early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)'''\nmodel_checkpoint = callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor='val_loss', verbose=1)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\nhistory = model.fit(x_train_lstm, y_train, epochs=50, batch_size=32,\n                    validation_data=(x_test_lstm, y_test),\n                    callbacks=[model_checkpoint,reduce_lr])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:06:16.972882Z","iopub.execute_input":"2025-04-28T11:06:16.973244Z","iopub.status.idle":"2025-04-28T12:14:53.509975Z","shell.execute_reply.started":"2025-04-28T11:06:16.973224Z","shell.execute_reply":"2025-04-28T12:14:53.508795Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6543 - f1_m: 0.6082 - loss: 0.8452 - mae_m: 0.3184 - mape_m: 31.8429 - precision_m: 0.7224 - recall_m: 0.5299 - rmse_m: 0.3901\nEpoch 1: val_loss improved from inf to 0.88482, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 94ms/step - accuracy: 0.6543 - f1_m: 0.6082 - loss: 0.8452 - mae_m: 0.3184 - mape_m: 31.8407 - precision_m: 0.7224 - recall_m: 0.5300 - rmse_m: 0.3901 - val_accuracy: 0.6288 - val_f1_m: 0.5998 - val_loss: 0.8848 - val_mae_m: 0.3102 - val_mape_m: 31.0247 - val_precision_m: 0.6674 - val_recall_m: 0.5465 - val_rmse_m: 0.3982 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7500 - f1_m: 0.7339 - loss: 0.7144 - mae_m: 0.2563 - mape_m: 25.6327 - precision_m: 0.7898 - recall_m: 0.6871 - rmse_m: 0.3417\nEpoch 2: val_loss did not improve from 0.88482\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 89ms/step - accuracy: 0.7501 - f1_m: 0.7339 - loss: 0.7144 - mae_m: 0.2563 - mape_m: 25.6313 - precision_m: 0.7898 - recall_m: 0.6871 - rmse_m: 0.3417 - val_accuracy: 0.3558 - val_f1_m: 0.3355 - val_loss: 1.7521 - val_mae_m: 0.4250 - val_mape_m: 42.4977 - val_precision_m: 0.3472 - val_recall_m: 0.3250 - val_rmse_m: 0.5295 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8071 - f1_m: 0.7997 - loss: 0.6302 - mae_m: 0.2143 - mape_m: 21.4288 - precision_m: 0.8416 - recall_m: 0.7631 - rmse_m: 0.3041\nEpoch 3: val_loss did not improve from 0.88482\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 89ms/step - accuracy: 0.8071 - f1_m: 0.7997 - loss: 0.6302 - mae_m: 0.2143 - mape_m: 21.4280 - precision_m: 0.8416 - recall_m: 0.7631 - rmse_m: 0.3041 - val_accuracy: 0.5689 - val_f1_m: 0.5579 - val_loss: 1.1659 - val_mae_m: 0.3249 - val_mape_m: 32.4917 - val_precision_m: 0.5857 - val_recall_m: 0.5335 - val_rmse_m: 0.4342 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8401 - f1_m: 0.8352 - loss: 0.5757 - mae_m: 0.1875 - mape_m: 18.7535 - precision_m: 0.8664 - recall_m: 0.8072 - rmse_m: 0.2780\nEpoch 4: val_loss improved from 0.88482 to 0.67624, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 93ms/step - accuracy: 0.8401 - f1_m: 0.8352 - loss: 0.5757 - mae_m: 0.1875 - mape_m: 18.7530 - precision_m: 0.8664 - recall_m: 0.8072 - rmse_m: 0.2780 - val_accuracy: 0.7693 - val_f1_m: 0.7617 - val_loss: 0.6762 - val_mae_m: 0.2192 - val_mape_m: 21.9184 - val_precision_m: 0.7939 - val_recall_m: 0.7330 - val_rmse_m: 0.3213 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8704 - f1_m: 0.8662 - loss: 0.5306 - mae_m: 0.1651 - mape_m: 16.5080 - precision_m: 0.8912 - recall_m: 0.8433 - rmse_m: 0.2543\nEpoch 5: val_loss did not improve from 0.67624\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 89ms/step - accuracy: 0.8704 - f1_m: 0.8662 - loss: 0.5306 - mae_m: 0.1651 - mape_m: 16.5074 - precision_m: 0.8912 - recall_m: 0.8433 - rmse_m: 0.2543 - val_accuracy: 0.5486 - val_f1_m: 0.5367 - val_loss: 1.1936 - val_mae_m: 0.3285 - val_mape_m: 32.8494 - val_precision_m: 0.5676 - val_recall_m: 0.5100 - val_rmse_m: 0.4522 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8960 - f1_m: 0.8921 - loss: 0.4878 - mae_m: 0.1429 - mape_m: 14.2950 - precision_m: 0.9125 - recall_m: 0.8732 - rmse_m: 0.2283\nEpoch 6: val_loss did not improve from 0.67624\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 88ms/step - accuracy: 0.8960 - f1_m: 0.8921 - loss: 0.4878 - mae_m: 0.1429 - mape_m: 14.2948 - precision_m: 0.9125 - recall_m: 0.8732 - rmse_m: 0.2283 - val_accuracy: 0.7314 - val_f1_m: 0.7226 - val_loss: 0.7729 - val_mae_m: 0.2374 - val_mape_m: 23.7416 - val_precision_m: 0.7554 - val_recall_m: 0.6936 - val_rmse_m: 0.3514 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9099 - f1_m: 0.9074 - loss: 0.4689 - mae_m: 0.1327 - mape_m: 13.2745 - precision_m: 0.9244 - recall_m: 0.8916 - rmse_m: 0.2161\nEpoch 7: val_loss did not improve from 0.67624\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 96ms/step - accuracy: 0.9099 - f1_m: 0.9074 - loss: 0.4689 - mae_m: 0.1327 - mape_m: 13.2740 - precision_m: 0.9244 - recall_m: 0.8916 - rmse_m: 0.2161 - val_accuracy: 0.4393 - val_f1_m: 0.4264 - val_loss: 1.4891 - val_mae_m: 0.3845 - val_mape_m: 38.4488 - val_precision_m: 0.4488 - val_recall_m: 0.4070 - val_rmse_m: 0.4939 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9488 - f1_m: 0.9470 - loss: 0.4040 - mae_m: 0.1021 - mape_m: 10.2149 - precision_m: 0.9562 - recall_m: 0.9383 - rmse_m: 0.1698\nEpoch 8: val_loss did not improve from 0.67624\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 102ms/step - accuracy: 0.9488 - f1_m: 0.9470 - loss: 0.4040 - mae_m: 0.1021 - mape_m: 10.2145 - precision_m: 0.9562 - recall_m: 0.9383 - rmse_m: 0.1698 - val_accuracy: 0.5951 - val_f1_m: 0.5887 - val_loss: 1.1598 - val_mae_m: 0.2930 - val_mape_m: 29.2964 - val_precision_m: 0.6005 - val_recall_m: 0.5779 - val_rmse_m: 0.4192 - learning_rate: 5.0000e-04\nEpoch 9/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9578 - f1_m: 0.9572 - loss: 0.3881 - mae_m: 0.0930 - mape_m: 9.3000 - precision_m: 0.9637 - recall_m: 0.9510 - rmse_m: 0.1555\nEpoch 9: val_loss did not improve from 0.67624\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 96ms/step - accuracy: 0.9578 - f1_m: 0.9572 - loss: 0.3881 - mae_m: 0.0930 - mape_m: 9.2999 - precision_m: 0.9637 - recall_m: 0.9510 - rmse_m: 0.1555 - val_accuracy: 0.7158 - val_f1_m: 0.7092 - val_loss: 0.8199 - val_mae_m: 0.2294 - val_mape_m: 22.9445 - val_precision_m: 0.7249 - val_recall_m: 0.6949 - val_rmse_m: 0.3428 - learning_rate: 5.0000e-04\nEpoch 10/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9638 - f1_m: 0.9630 - loss: 0.3766 - mae_m: 0.0872 - mape_m: 8.7214 - precision_m: 0.9691 - recall_m: 0.9571 - rmse_m: 0.1450\nEpoch 10: val_loss improved from 0.67624 to 0.50702, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 100ms/step - accuracy: 0.9638 - f1_m: 0.9630 - loss: 0.3766 - mae_m: 0.0872 - mape_m: 8.7214 - precision_m: 0.9691 - recall_m: 0.9571 - rmse_m: 0.1450 - val_accuracy: 0.8879 - val_f1_m: 0.8851 - val_loss: 0.5070 - val_mae_m: 0.1374 - val_mape_m: 13.7427 - val_precision_m: 0.9012 - val_recall_m: 0.8702 - val_rmse_m: 0.2293 - learning_rate: 5.0000e-04\nEpoch 11/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9660 - f1_m: 0.9647 - loss: 0.3755 - mae_m: 0.0857 - mape_m: 8.5739 - precision_m: 0.9704 - recall_m: 0.9592 - rmse_m: 0.1428\nEpoch 11: val_loss did not improve from 0.50702\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 91ms/step - accuracy: 0.9660 - f1_m: 0.9647 - loss: 0.3755 - mae_m: 0.0857 - mape_m: 8.5738 - precision_m: 0.9704 - recall_m: 0.9592 - rmse_m: 0.1428 - val_accuracy: 0.7801 - val_f1_m: 0.7755 - val_loss: 0.6965 - val_mae_m: 0.1959 - val_mape_m: 19.5907 - val_precision_m: 0.7966 - val_recall_m: 0.7562 - val_rmse_m: 0.3123 - learning_rate: 5.0000e-04\nEpoch 12/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9686 - f1_m: 0.9676 - loss: 0.3702 - mae_m: 0.0831 - mape_m: 8.3059 - precision_m: 0.9724 - recall_m: 0.9631 - rmse_m: 0.1389\nEpoch 12: val_loss did not improve from 0.50702\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 84ms/step - accuracy: 0.9686 - f1_m: 0.9676 - loss: 0.3702 - mae_m: 0.0831 - mape_m: 8.3059 - precision_m: 0.9724 - recall_m: 0.9631 - rmse_m: 0.1389 - val_accuracy: 0.8413 - val_f1_m: 0.8377 - val_loss: 0.6112 - val_mae_m: 0.1586 - val_mape_m: 15.8594 - val_precision_m: 0.8503 - val_recall_m: 0.8259 - val_rmse_m: 0.2767 - learning_rate: 5.0000e-04\nEpoch 13/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9735 - f1_m: 0.9726 - loss: 0.3613 - mae_m: 0.0786 - mape_m: 7.8648 - precision_m: 0.9769 - recall_m: 0.9684 - rmse_m: 0.1301\nEpoch 13: val_loss did not improve from 0.50702\n\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 84ms/step - accuracy: 0.9735 - f1_m: 0.9726 - loss: 0.3613 - mae_m: 0.0786 - mape_m: 7.8649 - precision_m: 0.9769 - recall_m: 0.9684 - rmse_m: 0.1301 - val_accuracy: 0.7538 - val_f1_m: 0.7499 - val_loss: 0.7730 - val_mae_m: 0.2078 - val_mape_m: 20.7778 - val_precision_m: 0.7643 - val_recall_m: 0.7365 - val_rmse_m: 0.3349 - learning_rate: 5.0000e-04\nEpoch 14/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9817 - f1_m: 0.9814 - loss: 0.3452 - mae_m: 0.0713 - mape_m: 7.1253 - precision_m: 0.9850 - recall_m: 0.9780 - rmse_m: 0.1135\nEpoch 14: val_loss improved from 0.50702 to 0.36660, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 83ms/step - accuracy: 0.9817 - f1_m: 0.9814 - loss: 0.3452 - mae_m: 0.0713 - mape_m: 7.1252 - precision_m: 0.9850 - recall_m: 0.9780 - rmse_m: 0.1135 - val_accuracy: 0.9642 - val_f1_m: 0.9638 - val_loss: 0.3666 - val_mae_m: 0.0769 - val_mape_m: 7.6865 - val_precision_m: 0.9690 - val_recall_m: 0.9589 - val_rmse_m: 0.1358 - learning_rate: 2.5000e-04\nEpoch 15/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9846 - f1_m: 0.9843 - loss: 0.3395 - mae_m: 0.0680 - mape_m: 6.8000 - precision_m: 0.9869 - recall_m: 0.9817 - rmse_m: 0.1072\nEpoch 15: val_loss did not improve from 0.36660\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 84ms/step - accuracy: 0.9846 - f1_m: 0.9843 - loss: 0.3395 - mae_m: 0.0680 - mape_m: 6.8001 - precision_m: 0.9869 - recall_m: 0.9817 - rmse_m: 0.1072 - val_accuracy: 0.6092 - val_f1_m: 0.6003 - val_loss: 1.0861 - val_mae_m: 0.2801 - val_mape_m: 28.0136 - val_precision_m: 0.6129 - val_recall_m: 0.5889 - val_rmse_m: 0.4065 - learning_rate: 2.5000e-04\nEpoch 16/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9848 - f1_m: 0.9844 - loss: 0.3377 - mae_m: 0.0671 - mape_m: 6.7052 - precision_m: 0.9870 - recall_m: 0.9818 - rmse_m: 0.1055\nEpoch 16: val_loss did not improve from 0.36660\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 83ms/step - accuracy: 0.9848 - f1_m: 0.9844 - loss: 0.3377 - mae_m: 0.0671 - mape_m: 6.7052 - precision_m: 0.9870 - recall_m: 0.9818 - rmse_m: 0.1055 - val_accuracy: 0.9539 - val_f1_m: 0.9524 - val_loss: 0.3894 - val_mae_m: 0.0867 - val_mape_m: 8.6742 - val_precision_m: 0.9587 - val_recall_m: 0.9464 - val_rmse_m: 0.1540 - learning_rate: 2.5000e-04\nEpoch 17/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9866 - f1_m: 0.9865 - loss: 0.3352 - mae_m: 0.0656 - mape_m: 6.5646 - precision_m: 0.9883 - recall_m: 0.9849 - rmse_m: 0.1021\nEpoch 17: val_loss improved from 0.36660 to 0.36385, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 86ms/step - accuracy: 0.9866 - f1_m: 0.9865 - loss: 0.3352 - mae_m: 0.0656 - mape_m: 6.5646 - precision_m: 0.9883 - recall_m: 0.9849 - rmse_m: 0.1021 - val_accuracy: 0.9661 - val_f1_m: 0.9649 - val_loss: 0.3639 - val_mae_m: 0.0780 - val_mape_m: 7.8041 - val_precision_m: 0.9702 - val_recall_m: 0.9598 - val_rmse_m: 0.1369 - learning_rate: 2.5000e-04\nEpoch 18/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9860 - f1_m: 0.9859 - loss: 0.3347 - mae_m: 0.0655 - mape_m: 6.5501 - precision_m: 0.9881 - recall_m: 0.9838 - rmse_m: 0.1021\nEpoch 18: val_loss improved from 0.36385 to 0.32361, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 83ms/step - accuracy: 0.9860 - f1_m: 0.9859 - loss: 0.3347 - mae_m: 0.0655 - mape_m: 6.5501 - precision_m: 0.9881 - recall_m: 0.9838 - rmse_m: 0.1021 - val_accuracy: 0.9882 - val_f1_m: 0.9881 - val_loss: 0.3236 - val_mae_m: 0.0556 - val_mape_m: 5.5560 - val_precision_m: 0.9896 - val_recall_m: 0.9866 - val_rmse_m: 0.0869 - learning_rate: 2.5000e-04\nEpoch 19/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9879 - f1_m: 0.9871 - loss: 0.3321 - mae_m: 0.0646 - mape_m: 6.4586 - precision_m: 0.9895 - recall_m: 0.9849 - rmse_m: 0.0986\nEpoch 19: val_loss did not improve from 0.32361\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 85ms/step - accuracy: 0.9879 - f1_m: 0.9871 - loss: 0.3321 - mae_m: 0.0646 - mape_m: 6.4586 - precision_m: 0.9895 - recall_m: 0.9849 - rmse_m: 0.0986 - val_accuracy: 0.9708 - val_f1_m: 0.9702 - val_loss: 0.3599 - val_mae_m: 0.0795 - val_mape_m: 7.9483 - val_precision_m: 0.9749 - val_recall_m: 0.9656 - val_rmse_m: 0.1325 - learning_rate: 2.5000e-04\nEpoch 20/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9887 - f1_m: 0.9880 - loss: 0.3320 - mae_m: 0.0637 - mape_m: 6.3713 - precision_m: 0.9898 - recall_m: 0.9863 - rmse_m: 0.0975\nEpoch 20: val_loss did not improve from 0.32361\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 88ms/step - accuracy: 0.9887 - f1_m: 0.9880 - loss: 0.3320 - mae_m: 0.0637 - mape_m: 6.3712 - precision_m: 0.9898 - recall_m: 0.9863 - rmse_m: 0.0975 - val_accuracy: 0.8888 - val_f1_m: 0.8869 - val_loss: 0.5094 - val_mae_m: 0.1316 - val_mape_m: 13.1649 - val_precision_m: 0.8985 - val_recall_m: 0.8760 - val_rmse_m: 0.2332 - learning_rate: 2.5000e-04\nEpoch 21/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9884 - f1_m: 0.9885 - loss: 0.3297 - mae_m: 0.0630 - mape_m: 6.2960 - precision_m: 0.9906 - recall_m: 0.9865 - rmse_m: 0.0952\nEpoch 21: val_loss did not improve from 0.32361\n\nEpoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 88ms/step - accuracy: 0.9884 - f1_m: 0.9885 - loss: 0.3297 - mae_m: 0.0630 - mape_m: 6.2960 - precision_m: 0.9906 - recall_m: 0.9865 - rmse_m: 0.0952 - val_accuracy: 0.9502 - val_f1_m: 0.9498 - val_loss: 0.3979 - val_mae_m: 0.0879 - val_mape_m: 8.7893 - val_precision_m: 0.9547 - val_recall_m: 0.9450 - val_rmse_m: 0.1565 - learning_rate: 2.5000e-04\nEpoch 22/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9905 - f1_m: 0.9903 - loss: 0.3261 - mae_m: 0.0607 - mape_m: 6.0711 - precision_m: 0.9919 - recall_m: 0.9888 - rmse_m: 0.0906\nEpoch 22: val_loss improved from 0.32361 to 0.31559, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 91ms/step - accuracy: 0.9905 - f1_m: 0.9903 - loss: 0.3261 - mae_m: 0.0607 - mape_m: 6.0710 - precision_m: 0.9919 - recall_m: 0.9888 - rmse_m: 0.0906 - val_accuracy: 0.9902 - val_f1_m: 0.9903 - val_loss: 0.3156 - val_mae_m: 0.0472 - val_mape_m: 4.7226 - val_precision_m: 0.9909 - val_recall_m: 0.9897 - val_rmse_m: 0.0742 - learning_rate: 1.2500e-04\nEpoch 23/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9922 - f1_m: 0.9923 - loss: 0.3206 - mae_m: 0.0582 - mape_m: 5.8170 - precision_m: 0.9936 - recall_m: 0.9911 - rmse_m: 0.0842\nEpoch 23: val_loss did not improve from 0.31559\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 90ms/step - accuracy: 0.9922 - f1_m: 0.9923 - loss: 0.3206 - mae_m: 0.0582 - mape_m: 5.8171 - precision_m: 0.9936 - recall_m: 0.9911 - rmse_m: 0.0842 - val_accuracy: 0.9204 - val_f1_m: 0.9191 - val_loss: 0.4321 - val_mae_m: 0.1144 - val_mape_m: 11.4406 - val_precision_m: 0.9299 - val_recall_m: 0.9089 - val_rmse_m: 0.1916 - learning_rate: 1.2500e-04\nEpoch 24/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9927 - f1_m: 0.9927 - loss: 0.3211 - mae_m: 0.0588 - mape_m: 5.8758 - precision_m: 0.9936 - recall_m: 0.9918 - rmse_m: 0.0843\nEpoch 24: val_loss improved from 0.31559 to 0.31351, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 91ms/step - accuracy: 0.9927 - f1_m: 0.9927 - loss: 0.3211 - mae_m: 0.0588 - mape_m: 5.8758 - precision_m: 0.9936 - recall_m: 0.9918 - rmse_m: 0.0843 - val_accuracy: 0.9922 - val_f1_m: 0.9920 - val_loss: 0.3135 - val_mae_m: 0.0464 - val_mape_m: 4.6354 - val_precision_m: 0.9927 - val_recall_m: 0.9914 - val_rmse_m: 0.0710 - learning_rate: 1.2500e-04\nEpoch 25/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9923 - f1_m: 0.9921 - loss: 0.3215 - mae_m: 0.0586 - mape_m: 5.8616 - precision_m: 0.9932 - recall_m: 0.9911 - rmse_m: 0.0843\nEpoch 25: val_loss did not improve from 0.31351\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 87ms/step - accuracy: 0.9923 - f1_m: 0.9921 - loss: 0.3215 - mae_m: 0.0586 - mape_m: 5.8616 - precision_m: 0.9932 - recall_m: 0.9911 - rmse_m: 0.0843 - val_accuracy: 0.9900 - val_f1_m: 0.9899 - val_loss: 0.3191 - val_mae_m: 0.0504 - val_mape_m: 5.0406 - val_precision_m: 0.9909 - val_recall_m: 0.9890 - val_rmse_m: 0.0775 - learning_rate: 1.2500e-04\nEpoch 26/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9932 - f1_m: 0.9930 - loss: 0.3205 - mae_m: 0.0585 - mape_m: 5.8525 - precision_m: 0.9941 - recall_m: 0.9920 - rmse_m: 0.0838\nEpoch 26: val_loss did not improve from 0.31351\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 86ms/step - accuracy: 0.9932 - f1_m: 0.9930 - loss: 0.3205 - mae_m: 0.0585 - mape_m: 5.8525 - precision_m: 0.9941 - recall_m: 0.9920 - rmse_m: 0.0838 - val_accuracy: 0.9620 - val_f1_m: 0.9617 - val_loss: 0.3707 - val_mae_m: 0.0744 - val_mape_m: 7.4436 - val_precision_m: 0.9646 - val_recall_m: 0.9590 - val_rmse_m: 0.1400 - learning_rate: 1.2500e-04\nEpoch 27/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9940 - f1_m: 0.9939 - loss: 0.3191 - mae_m: 0.0577 - mape_m: 5.7671 - precision_m: 0.9951 - recall_m: 0.9928 - rmse_m: 0.0811\nEpoch 27: val_loss did not improve from 0.31351\n\nEpoch 27: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 86ms/step - accuracy: 0.9940 - f1_m: 0.9939 - loss: 0.3191 - mae_m: 0.0577 - mape_m: 5.7670 - precision_m: 0.9951 - recall_m: 0.9928 - rmse_m: 0.0811 - val_accuracy: 0.9880 - val_f1_m: 0.9878 - val_loss: 0.3276 - val_mae_m: 0.0614 - val_mape_m: 6.1443 - val_precision_m: 0.9895 - val_recall_m: 0.9860 - val_rmse_m: 0.0970 - learning_rate: 1.2500e-04\nEpoch 28/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9947 - f1_m: 0.9945 - loss: 0.3171 - mae_m: 0.0569 - mape_m: 5.6853 - precision_m: 0.9953 - recall_m: 0.9937 - rmse_m: 0.0795\nEpoch 28: val_loss improved from 0.31351 to 0.30863, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 86ms/step - accuracy: 0.9947 - f1_m: 0.9945 - loss: 0.3171 - mae_m: 0.0569 - mape_m: 5.6852 - precision_m: 0.9953 - recall_m: 0.9937 - rmse_m: 0.0795 - val_accuracy: 0.9938 - val_f1_m: 0.9937 - val_loss: 0.3086 - val_mae_m: 0.0435 - val_mape_m: 4.3542 - val_precision_m: 0.9942 - val_recall_m: 0.9931 - val_rmse_m: 0.0639 - learning_rate: 6.2500e-05\nEpoch 29/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9951 - f1_m: 0.9950 - loss: 0.3155 - mae_m: 0.0556 - mape_m: 5.5590 - precision_m: 0.9961 - recall_m: 0.9940 - rmse_m: 0.0764\nEpoch 29: val_loss improved from 0.30863 to 0.30504, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 88ms/step - accuracy: 0.9951 - f1_m: 0.9950 - loss: 0.3155 - mae_m: 0.0556 - mape_m: 5.5591 - precision_m: 0.9961 - recall_m: 0.9940 - rmse_m: 0.0764 - val_accuracy: 0.9963 - val_f1_m: 0.9963 - val_loss: 0.3050 - val_mae_m: 0.0416 - val_mape_m: 4.1552 - val_precision_m: 0.9967 - val_recall_m: 0.9960 - val_rmse_m: 0.0568 - learning_rate: 6.2500e-05\nEpoch 30/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9956 - f1_m: 0.9955 - loss: 0.3152 - mae_m: 0.0554 - mape_m: 5.5395 - precision_m: 0.9963 - recall_m: 0.9948 - rmse_m: 0.0760\nEpoch 30: val_loss did not improve from 0.30504\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 84ms/step - accuracy: 0.9956 - f1_m: 0.9955 - loss: 0.3152 - mae_m: 0.0554 - mape_m: 5.5395 - precision_m: 0.9963 - recall_m: 0.9948 - rmse_m: 0.0760 - val_accuracy: 0.9958 - val_f1_m: 0.9957 - val_loss: 0.3056 - val_mae_m: 0.0417 - val_mape_m: 4.1659 - val_precision_m: 0.9963 - val_recall_m: 0.9950 - val_rmse_m: 0.0574 - learning_rate: 6.2500e-05\nEpoch 31/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9953 - f1_m: 0.9952 - loss: 0.3148 - mae_m: 0.0555 - mape_m: 5.5466 - precision_m: 0.9960 - recall_m: 0.9945 - rmse_m: 0.0760\nEpoch 31: val_loss did not improve from 0.30504\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 85ms/step - accuracy: 0.9953 - f1_m: 0.9952 - loss: 0.3148 - mae_m: 0.0555 - mape_m: 5.5466 - precision_m: 0.9960 - recall_m: 0.9945 - rmse_m: 0.0760 - val_accuracy: 0.9952 - val_f1_m: 0.9954 - val_loss: 0.3079 - val_mae_m: 0.0471 - val_mape_m: 4.7070 - val_precision_m: 0.9960 - val_recall_m: 0.9948 - val_rmse_m: 0.0667 - learning_rate: 6.2500e-05\nEpoch 32/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9956 - f1_m: 0.9956 - loss: 0.3144 - mae_m: 0.0551 - mape_m: 5.5131 - precision_m: 0.9964 - recall_m: 0.9948 - rmse_m: 0.0754\nEpoch 32: val_loss did not improve from 0.30504\n\nEpoch 32: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 85ms/step - accuracy: 0.9956 - f1_m: 0.9956 - loss: 0.3144 - mae_m: 0.0551 - mape_m: 5.5131 - precision_m: 0.9964 - recall_m: 0.9948 - rmse_m: 0.0754 - val_accuracy: 0.9946 - val_f1_m: 0.9946 - val_loss: 0.3096 - val_mae_m: 0.0452 - val_mape_m: 4.5199 - val_precision_m: 0.9953 - val_recall_m: 0.9939 - val_rmse_m: 0.0646 - learning_rate: 6.2500e-05\nEpoch 33/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9966 - f1_m: 0.9965 - loss: 0.3127 - mae_m: 0.0543 - mape_m: 5.4288 - precision_m: 0.9973 - recall_m: 0.9957 - rmse_m: 0.0728\nEpoch 33: val_loss improved from 0.30504 to 0.30266, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 89ms/step - accuracy: 0.9966 - f1_m: 0.9965 - loss: 0.3127 - mae_m: 0.0543 - mape_m: 5.4289 - precision_m: 0.9973 - recall_m: 0.9957 - rmse_m: 0.0728 - val_accuracy: 0.9971 - val_f1_m: 0.9969 - val_loss: 0.3027 - val_mae_m: 0.0416 - val_mape_m: 4.1648 - val_precision_m: 0.9971 - val_recall_m: 0.9968 - val_rmse_m: 0.0551 - learning_rate: 3.1250e-05\nEpoch 34/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9958 - f1_m: 0.9956 - loss: 0.3135 - mae_m: 0.0545 - mape_m: 5.4544 - precision_m: 0.9963 - recall_m: 0.9949 - rmse_m: 0.0736\nEpoch 34: val_loss improved from 0.30266 to 0.30206, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 89ms/step - accuracy: 0.9958 - f1_m: 0.9956 - loss: 0.3135 - mae_m: 0.0545 - mape_m: 5.4545 - precision_m: 0.9963 - recall_m: 0.9949 - rmse_m: 0.0736 - val_accuracy: 0.9977 - val_f1_m: 0.9976 - val_loss: 0.3021 - val_mae_m: 0.0380 - val_mape_m: 3.8033 - val_precision_m: 0.9977 - val_recall_m: 0.9975 - val_rmse_m: 0.0493 - learning_rate: 3.1250e-05\nEpoch 35/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9964 - f1_m: 0.9964 - loss: 0.3126 - mae_m: 0.0539 - mape_m: 5.3865 - precision_m: 0.9969 - recall_m: 0.9960 - rmse_m: 0.0722\nEpoch 35: val_loss improved from 0.30206 to 0.30117, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 89ms/step - accuracy: 0.9964 - f1_m: 0.9964 - loss: 0.3126 - mae_m: 0.0539 - mape_m: 5.3865 - precision_m: 0.9969 - recall_m: 0.9960 - rmse_m: 0.0722 - val_accuracy: 0.9979 - val_f1_m: 0.9978 - val_loss: 0.3012 - val_mae_m: 0.0391 - val_mape_m: 3.9116 - val_precision_m: 0.9980 - val_recall_m: 0.9977 - val_rmse_m: 0.0501 - learning_rate: 3.1250e-05\nEpoch 36/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9971 - f1_m: 0.9969 - loss: 0.3113 - mae_m: 0.0534 - mape_m: 5.3430 - precision_m: 0.9976 - recall_m: 0.9963 - rmse_m: 0.0709\nEpoch 36: val_loss did not improve from 0.30117\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 96ms/step - accuracy: 0.9971 - f1_m: 0.9969 - loss: 0.3113 - mae_m: 0.0534 - mape_m: 5.3431 - precision_m: 0.9976 - recall_m: 0.9963 - rmse_m: 0.0709 - val_accuracy: 0.9934 - val_f1_m: 0.9938 - val_loss: 0.3093 - val_mae_m: 0.0473 - val_mape_m: 4.7300 - val_precision_m: 0.9946 - val_recall_m: 0.9930 - val_rmse_m: 0.0687 - learning_rate: 3.1250e-05\nEpoch 37/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9959 - f1_m: 0.9961 - loss: 0.3127 - mae_m: 0.0544 - mape_m: 5.4389 - precision_m: 0.9969 - recall_m: 0.9952 - rmse_m: 0.0730\nEpoch 37: val_loss did not improve from 0.30117\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 88ms/step - accuracy: 0.9959 - f1_m: 0.9961 - loss: 0.3127 - mae_m: 0.0544 - mape_m: 5.4389 - precision_m: 0.9969 - recall_m: 0.9952 - rmse_m: 0.0730 - val_accuracy: 0.9979 - val_f1_m: 0.9976 - val_loss: 0.3018 - val_mae_m: 0.0398 - val_mape_m: 3.9824 - val_precision_m: 0.9979 - val_recall_m: 0.9973 - val_rmse_m: 0.0519 - learning_rate: 3.1250e-05\nEpoch 38/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9971 - f1_m: 0.9969 - loss: 0.3121 - mae_m: 0.0541 - mape_m: 5.4073 - precision_m: 0.9973 - recall_m: 0.9966 - rmse_m: 0.0719\nEpoch 38: val_loss did not improve from 0.30117\n\nEpoch 38: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 86ms/step - accuracy: 0.9971 - f1_m: 0.9969 - loss: 0.3121 - mae_m: 0.0541 - mape_m: 5.4073 - precision_m: 0.9973 - recall_m: 0.9966 - rmse_m: 0.0719 - val_accuracy: 0.9972 - val_f1_m: 0.9971 - val_loss: 0.3028 - val_mae_m: 0.0392 - val_mape_m: 3.9201 - val_precision_m: 0.9972 - val_recall_m: 0.9969 - val_rmse_m: 0.0514 - learning_rate: 3.1250e-05\nEpoch 39/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9974 - f1_m: 0.9972 - loss: 0.3111 - mae_m: 0.0536 - mape_m: 5.3646 - precision_m: 0.9977 - recall_m: 0.9968 - rmse_m: 0.0707\nEpoch 39: val_loss did not improve from 0.30117\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 85ms/step - accuracy: 0.9974 - f1_m: 0.9972 - loss: 0.3111 - mae_m: 0.0536 - mape_m: 5.3647 - precision_m: 0.9977 - recall_m: 0.9968 - rmse_m: 0.0707 - val_accuracy: 0.9978 - val_f1_m: 0.9977 - val_loss: 0.3018 - val_mae_m: 0.0389 - val_mape_m: 3.8866 - val_precision_m: 0.9978 - val_recall_m: 0.9977 - val_rmse_m: 0.0505 - learning_rate: 1.5625e-05\nEpoch 40/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9971 - f1_m: 0.9970 - loss: 0.3114 - mae_m: 0.0539 - mape_m: 5.3855 - precision_m: 0.9976 - recall_m: 0.9964 - rmse_m: 0.0712\nEpoch 40: val_loss did not improve from 0.30117\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 84ms/step - accuracy: 0.9971 - f1_m: 0.9970 - loss: 0.3114 - mae_m: 0.0539 - mape_m: 5.3856 - precision_m: 0.9976 - recall_m: 0.9964 - rmse_m: 0.0712 - val_accuracy: 0.9971 - val_f1_m: 0.9970 - val_loss: 0.3023 - val_mae_m: 0.0400 - val_mape_m: 4.0015 - val_precision_m: 0.9973 - val_recall_m: 0.9967 - val_rmse_m: 0.0531 - learning_rate: 1.5625e-05\nEpoch 41/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9968 - f1_m: 0.9966 - loss: 0.3117 - mae_m: 0.0537 - mape_m: 5.3716 - precision_m: 0.9972 - recall_m: 0.9962 - rmse_m: 0.0713\nEpoch 41: val_loss improved from 0.30117 to 0.30115, saving model to best_model.keras\n\nEpoch 41: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 84ms/step - accuracy: 0.9968 - f1_m: 0.9966 - loss: 0.3117 - mae_m: 0.0537 - mape_m: 5.3716 - precision_m: 0.9972 - recall_m: 0.9962 - rmse_m: 0.0713 - val_accuracy: 0.9977 - val_f1_m: 0.9976 - val_loss: 0.3011 - val_mae_m: 0.0385 - val_mape_m: 3.8496 - val_precision_m: 0.9980 - val_recall_m: 0.9972 - val_rmse_m: 0.0494 - learning_rate: 1.5625e-05\nEpoch 42/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9972 - f1_m: 0.9971 - loss: 0.3114 - mae_m: 0.0537 - mape_m: 5.3702 - precision_m: 0.9978 - recall_m: 0.9965 - rmse_m: 0.0709\nEpoch 42: val_loss improved from 0.30115 to 0.30093, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 83ms/step - accuracy: 0.9972 - f1_m: 0.9971 - loss: 0.3114 - mae_m: 0.0537 - mape_m: 5.3702 - precision_m: 0.9978 - recall_m: 0.9965 - rmse_m: 0.0709 - val_accuracy: 0.9980 - val_f1_m: 0.9979 - val_loss: 0.3009 - val_mae_m: 0.0387 - val_mape_m: 3.8677 - val_precision_m: 0.9981 - val_recall_m: 0.9977 - val_rmse_m: 0.0494 - learning_rate: 7.8125e-06\nEpoch 43/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9979 - f1_m: 0.9979 - loss: 0.3104 - mae_m: 0.0531 - mape_m: 5.3142 - precision_m: 0.9986 - recall_m: 0.9973 - rmse_m: 0.0690\nEpoch 43: val_loss improved from 0.30093 to 0.30068, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 85ms/step - accuracy: 0.9979 - f1_m: 0.9979 - loss: 0.3104 - mae_m: 0.0531 - mape_m: 5.3142 - precision_m: 0.9986 - recall_m: 0.9973 - rmse_m: 0.0690 - val_accuracy: 0.9978 - val_f1_m: 0.9979 - val_loss: 0.3007 - val_mae_m: 0.0392 - val_mape_m: 3.9165 - val_precision_m: 0.9982 - val_recall_m: 0.9977 - val_rmse_m: 0.0497 - learning_rate: 7.8125e-06\nEpoch 44/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9968 - f1_m: 0.9967 - loss: 0.3109 - mae_m: 0.0532 - mape_m: 5.3244 - precision_m: 0.9971 - recall_m: 0.9964 - rmse_m: 0.0705\nEpoch 44: val_loss did not improve from 0.30068\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 84ms/step - accuracy: 0.9968 - f1_m: 0.9967 - loss: 0.3109 - mae_m: 0.0532 - mape_m: 5.3245 - precision_m: 0.9971 - recall_m: 0.9964 - rmse_m: 0.0705 - val_accuracy: 0.9980 - val_f1_m: 0.9978 - val_loss: 0.3008 - val_mae_m: 0.0387 - val_mape_m: 3.8677 - val_precision_m: 0.9982 - val_recall_m: 0.9975 - val_rmse_m: 0.0494 - learning_rate: 7.8125e-06\nEpoch 45/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9971 - f1_m: 0.9970 - loss: 0.3103 - mae_m: 0.0531 - mape_m: 5.3149 - precision_m: 0.9975 - recall_m: 0.9966 - rmse_m: 0.0695\nEpoch 45: val_loss did not improve from 0.30068\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 84ms/step - accuracy: 0.9971 - f1_m: 0.9970 - loss: 0.3103 - mae_m: 0.0531 - mape_m: 5.3149 - precision_m: 0.9975 - recall_m: 0.9966 - rmse_m: 0.0695 - val_accuracy: 0.9980 - val_f1_m: 0.9981 - val_loss: 0.3012 - val_mae_m: 0.0386 - val_mape_m: 3.8605 - val_precision_m: 0.9984 - val_recall_m: 0.9978 - val_rmse_m: 0.0494 - learning_rate: 7.8125e-06\nEpoch 46/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9968 - f1_m: 0.9968 - loss: 0.3108 - mae_m: 0.0530 - mape_m: 5.2961 - precision_m: 0.9973 - recall_m: 0.9964 - rmse_m: 0.0700\nEpoch 46: val_loss did not improve from 0.30068\n\nEpoch 46: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 84ms/step - accuracy: 0.9968 - f1_m: 0.9968 - loss: 0.3108 - mae_m: 0.0530 - mape_m: 5.2962 - precision_m: 0.9973 - recall_m: 0.9964 - rmse_m: 0.0700 - val_accuracy: 0.9978 - val_f1_m: 0.9977 - val_loss: 0.3014 - val_mae_m: 0.0387 - val_mape_m: 3.8708 - val_precision_m: 0.9980 - val_recall_m: 0.9973 - val_rmse_m: 0.0502 - learning_rate: 7.8125e-06\nEpoch 47/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9973 - f1_m: 0.9971 - loss: 0.3103 - mae_m: 0.0528 - mape_m: 5.2806 - precision_m: 0.9977 - recall_m: 0.9965 - rmse_m: 0.0691\nEpoch 47: val_loss did not improve from 0.30068\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 85ms/step - accuracy: 0.9973 - f1_m: 0.9971 - loss: 0.3103 - mae_m: 0.0528 - mape_m: 5.2806 - precision_m: 0.9977 - recall_m: 0.9965 - rmse_m: 0.0691 - val_accuracy: 0.9979 - val_f1_m: 0.9978 - val_loss: 0.3007 - val_mae_m: 0.0391 - val_mape_m: 3.9134 - val_precision_m: 0.9981 - val_recall_m: 0.9976 - val_rmse_m: 0.0501 - learning_rate: 3.9063e-06\nEpoch 48/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9977 - f1_m: 0.9977 - loss: 0.3109 - mae_m: 0.0538 - mape_m: 5.3800 - precision_m: 0.9980 - recall_m: 0.9974 - rmse_m: 0.0699\nEpoch 48: val_loss did not improve from 0.30068\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 88ms/step - accuracy: 0.9977 - f1_m: 0.9977 - loss: 0.3109 - mae_m: 0.0538 - mape_m: 5.3801 - precision_m: 0.9980 - recall_m: 0.9974 - rmse_m: 0.0699 - val_accuracy: 0.9979 - val_f1_m: 0.9978 - val_loss: 0.3009 - val_mae_m: 0.0385 - val_mape_m: 3.8465 - val_precision_m: 0.9981 - val_recall_m: 0.9976 - val_rmse_m: 0.0492 - learning_rate: 3.9063e-06\nEpoch 49/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9972 - f1_m: 0.9971 - loss: 0.3112 - mae_m: 0.0536 - mape_m: 5.3610 - precision_m: 0.9975 - recall_m: 0.9967 - rmse_m: 0.0706\nEpoch 49: val_loss did not improve from 0.30068\n\nEpoch 49: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 84ms/step - accuracy: 0.9972 - f1_m: 0.9971 - loss: 0.3112 - mae_m: 0.0536 - mape_m: 5.3610 - precision_m: 0.9975 - recall_m: 0.9967 - rmse_m: 0.0706 - val_accuracy: 0.9980 - val_f1_m: 0.9979 - val_loss: 0.3007 - val_mae_m: 0.0391 - val_mape_m: 3.9094 - val_precision_m: 0.9981 - val_recall_m: 0.9977 - val_rmse_m: 0.0500 - learning_rate: 3.9063e-06\nEpoch 50/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9975 - f1_m: 0.9976 - loss: 0.3099 - mae_m: 0.0530 - mape_m: 5.3027 - precision_m: 0.9983 - recall_m: 0.9969 - rmse_m: 0.0689\nEpoch 50: val_loss improved from 0.30068 to 0.30055, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 85ms/step - accuracy: 0.9975 - f1_m: 0.9976 - loss: 0.3099 - mae_m: 0.0530 - mape_m: 5.3027 - precision_m: 0.9983 - recall_m: 0.9969 - rmse_m: 0.0689 - val_accuracy: 0.9979 - val_f1_m: 0.9979 - val_loss: 0.3005 - val_mae_m: 0.0387 - val_mape_m: 3.8695 - val_precision_m: 0.9981 - val_recall_m: 0.9977 - val_rmse_m: 0.0491 - learning_rate: 1.9531e-06\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy, f1_score, precision, recall, mae, mape, rmse = model.evaluate(x_test_lstm, y_test, verbose=0)\n\n# Print results\nprint(f\"Validation Loss: {loss:.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"Mean Absolute Error (MAE): {mae:.4f}\")\nprint(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:15:16.757711Z","iopub.execute_input":"2025-04-28T12:15:16.758071Z","iopub.status.idle":"2025-04-28T12:15:23.570521Z","shell.execute_reply.started":"2025-04-28T12:15:16.758047Z","shell.execute_reply":"2025-04-28T12:15:23.569079Z"}},"outputs":[{"name":"stdout","text":"Validation Loss: 0.3005\nAccuracy: 0.9979\nF1 Score: 0.9979\nPrecision: 0.9981\nRecall: 0.9977\nMean Absolute Error (MAE): 0.0387\nMean Absolute Percentage Error (MAPE): 3.8695\nRoot Mean Squared Error (RMSE): 0.0491\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_actual_vs_predicted(model, x_test, y_test):\n    # Predict\n    y_pred_probs = model.predict(x_test, batch_size=64, verbose=1)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true = np.argmax(y_test, axis=1)\n\n    # Confirm correct number of samples\n    print(f\"Number of test samples: {len(y_true)}\")\n    print(f\"Number of predictions: {len(y_pred)}\")\n\n    if len(y_true) != len(y_pred):\n        print(\"Mismatch between test samples and predictions!\")\n        return\n\n    # Classes\n    classes = np.unique(y_true)\n    print(f\"Classes found in test set: {classes}\")\n\n    # True and Predicted counts\n    true_counts = [np.sum(y_true == cls) for cls in classes]\n    pred_counts = [np.sum(y_pred == cls) for cls in classes]\n\n    # Correct predictions per class\n    correct_counts = [np.sum((y_true == cls) & (y_pred == cls)) for cls in classes]\n\n    # Per-class accuracy (percentage of correct predictions)\n    class_accuracy = [\n        (correct_counts[i] / true_counts[i]) * 100 if true_counts[i] != 0 else 0\n        for i in range(len(classes))\n    ]\n\n    # Total accuracy\n    total_correct = np.sum(y_true == y_pred)\n    total_samples = len(y_true)\n    total_accuracy = (total_correct / total_samples) * 100\n\n    # Print per-class accuracy\n    print(\"\\nPer-Class Accuracy (Correct Predictions Percentage):\")\n    for i, acc in enumerate(class_accuracy):\n        print(f\"  Class {classes[i]}: {acc:.2f}%\")\n    print(f\"\\nTotal Test Accuracy: {total_accuracy:.2f}%\")\n\n    # Bar plot Actual vs Predicted\n    x = np.arange(len(classes))\n    width = 0.35\n\n    fig, ax = plt.subplots(figsize=(10, 7))\n    rects1 = ax.bar(x - width/2, true_counts, width, label='Actual Count', color='lightblue')\n    rects2 = ax.bar(x + width/2, pred_counts, width, label='Predicted Count', color='salmon')\n\n    ax.set_xlabel('Class Labels')\n    ax.set_ylabel('Number of Samples')\n    ax.set_title(f'Actual vs Predicted Samples (Total Accuracy: {total_accuracy:.2f}%)')\n    ax.set_xticks(x)\n    ax.set_xticklabels(classes)\n    \n    ax.legend(loc='lower center', bbox_to_anchor=(0.5, 1.05),\n              ncol=2, fancybox=True, shadow=True)\n\n\n    # Annotate bar heights\n    def autolabel(rects):\n        for rect in rects:\n            height = rect.get_height()\n            ax.annotate(f'{int(height)}',\n                        xy=(rect.get_x() + rect.get_width() / 2, height),\n                        xytext=(0, 3),\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom')\n\n    autolabel(rects1)\n    autolabel(rects2)\n\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\nplot_actual_vs_predicted(model, x_test_lstm, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:18:52.568752Z","iopub.execute_input":"2025-04-28T12:18:52.569121Z","iopub.status.idle":"2025-04-28T12:19:02.577441Z","shell.execute_reply.started":"2025-04-28T12:18:52.569098Z","shell.execute_reply":"2025-04-28T12:19:02.576371Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step\nNumber of test samples: 9000\nNumber of predictions: 9000\nClasses found in test set: [0 1 2]\n\nPer-Class Accuracy (Correct Predictions Percentage):\n  Class 0: 99.50%\n  Class 1: 99.90%\n  Class 2: 99.97%\n\nTotal Test Accuracy: 99.79%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x700 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA90AAAKzCAYAAAADR24YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5sUlEQVR4nOzdd3gUZd/28XPTA2kEUoiE0KsUAYGIdCRUQVBA8KbLjYautEelqaBwI0Up+ki9DSAoIEXBEKQooUroICWIAgkihFBT5/2DN/uwJECCGULC93McexzudV0785vdzci5c82MxTAMQwAAAAAAINvZ5XQBAAAAAADkVYRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABM4pDTBQAA/hnDMJSUlKTk5OScLgUATOHg4CBHR0dZLJacLgUAsozQDQC5WEJCgk6fPq1r167ldCkAYCo3NzcVK1ZMzs7OOV0KAGSJxTAMI6eLAABkXWpqqvbt2ycHBwc99dRTcnZ25igQgDzHMAwlJCTozz//VHJysipWrEjwBpCrELoBIJe6ceOGjhw5orJly8rNzS2nywEAU127dk3Hjh3TxYsX1bBhQzk5OeV0SQCQKVxIDQByOTs7duUA8r60fd1vv/2miIiIHK4GADKPf6kBAAAg13Bzc1N0dLSSkpJyuhQAyBRCNwAAAHINBwcHJScnKyEhIadLAYBM4erlAJDHLD92/pGur13Zwo90fWazWCxasWKF2rZtm9Ol5ApJY996pOtzHD35ka4vK7p37664uDitXLlSktSgQQNVrVpVU6dOfaR1bNq0SQ0bNtTly5fl5eX1SNcNAEiPI90AgBwRGRkpe3t7tWzZMsuvLVas2CMPMneKiYlR//79VaJECTk7OyswMFCtW7fOkfNMLRaLNeQhve7du8tischiscjJyUmlSpXSuHHjHsl97ZcvX673338/U2M3bdoki8WiuLg4c4u6w969e/XKK6/Iz89PLi4uKl26tF5//XX99ttvj6wGKWe2HQAeJUI3ACBHzJkzR/3799eWLVt07ty5nC4n006fPq3q1atr48aNmjRpkg4cOKB169apYcOGCg0NzenykIFmzZrp/PnzOn78uN566y2NGTNGkyZNynBsYmJitq3X29tb7u7u2ba87LRmzRrVrl1bCQkJCgsL05EjR/TVV1/J09NT7733Xk6XBwB5CqEbAPDIXbt2TV9//bXeeOMNtWzZUvPnz083ZvXq1Xr22Wfl4uKiQoUK6aWXXpJ0e8ru77//rsGDB1uPYErSmDFjVLVqVZtlTJ06VcWKFbM+37Vrl1544QUVKlRInp6eql+/vn799dcs1f7mm2/KYrFo586dat++vcqUKaOKFStqyJAh2r59u3XcmTNn1KZNG7m5ucnDw0MdOnRQbGystb979+7pprAPGjRIDRo0sD5v0KCBBgwYoGHDhsnb21v+/v4aM2aMtT9t21566SVZLBabbcX/cXZ2lr+/v4KCgvTGG2+oSZMmWrVqlaT/+xw+/PBDBQQEqGzZspKkP/74Qx06dJCXl5e8vb3Vpk0bnT592rrMlJQUDRkyRF5eXipYsKCGDRumu+/C2qBBAw0aNMj6PCEhQcOHD1dgYKCcnZ1VqlQpzZkzR6dPn1bDhg0lSQUKFJDFYlH37t0lSampqZowYYKKFy8uV1dXValSRd98843Ner7//nuVKVNGrq6uatiwoU2dGblx44Z69OihFi1aaNWqVWrSpImKFy+uWrVq6T//+Y8+//xz69jNmzerZs2acnZ2VuHChTVixAibWQIZzTqpWrWqzffUYrHoyy+/1EsvvaR8+fKpdOnS1vf/ftsOAHkFoRsA8MgtXbpU5cqVU9myZfXaa69p7ty5NoFl7dq1eumll9SiRQvt3btXERERqlmzpqTbU3aLFCmicePG6fz58zp/PvPnsF+9elXdunXTzz//rO3bt6t06dJq0aKFrl69mqnXX7p0SevWrVNoaKjy58+frj/t/NnU1FS1adNGly5d0ubNmxUeHq5Tp06pY8eOma41zYIFC5Q/f37t2LFDEydO1Lhx4xQeHi7p9o8IkjRv3jydP3/e+hz35+rqanNEOyIiQseOHVN4eLjWrFmjpKQkhYSEyN3dXVu3btUvv/wiNzc3NWvWzPq6yZMna/78+Zo7d65+/vlnXbp0SStWrLjvert27arFixdr+vTpOnLkiD7//HO5ubkpMDBQ3377rSTp2LFjOn/+vKZNmyZJmjBhghYuXKjZs2fr0KFDGjx4sF577TVt3rxZ0u0fB9q1a6fWrVsrKipKvXv31ogRI+5bx/r163Xx4kUNGzYsw/607/HZs2fVokULPfvss9q3b59mzZqlOXPm6IMPPnjwm3yXsWPHqkOHDtq/f79atGihLl266NKlS/fddgDIK7iQGgDgkZszZ45ee+01Sben/l65ckWbN2+2HuX98MMP1alTJ40dO9b6mipVqki6PWXX3t5e7u7u8vf3z9J6GzVqZPP8iy++kJeXlzZv3qxWrVo98PUnTpyQYRgqV67cfcdFRETowIEDio6OVmBgoCRp4cKFqlixonbt2qVnn3020zVXrlxZo0ePliSVLl1an332mSIiIvTCCy/Ix8dH0u2QlNX34klkGIYiIiK0fv169e/f39qeP39+ffnll3JycpIkffXVV0pNTdWXX35pnUkxb948eXl5adOmTWratKmmTp2qkSNHql27dpKk2bNna/369fdc92+//aalS5cqPDxcTZo0kSSVKFHC2u/t7S1J8vX1tYbehIQEjR8/Xhs2bFBwcLD1NT///LM+//xz1a9fX7NmzVLJkiU1efLtC8yVLVtWBw4c0Mcff3zPWo4fPy5JD/wez5w5U4GBgfrss89ksVhUrlw5nTt3TsOHD9eoUaOs983OjO7du+vVV1+VJI0fP17Tp0/Xzp071axZswy3HQDyEkI3AOCROnbsmHbu3Gk9Kujg4KCOHTtqzpw51tAdFRWl119/PdvXHRsbq3fffVebNm3ShQsXlJKSohs3bujMmTOZev3d04fv5ciRIwoMDLQGbkmqUKGCvLy8dOTIkSyH7jsVLlxYFy5cyPTrcfv8ZTc3NyUlJSk1NVWdO3e2mf5cqVIla+CWpH379unEiRPpzse+deuWTp48qStXruj8+fOqVauWtc/BwUE1atS453ckKipK9vb2ql+/fqbrPnHihG7cuKEXXnjBpj0xMVHPPPOMpNvftTvrkGQN6PeSle9xcHCw9YcHSapTp46uXbumP//8U0WLFs3UciTb73H+/Pnl4eHB9xjAE4PQDQB4pObMmaPk5GQFBARY2wzDkLOzsz777DN5enrK1dU1y8u1s7NLFyaSkpJsnnfr1k1///23pk2bpqCgIDk7Oys4ODjTF88qXbq0LBaLjh49muX6HqZeSXJ0dLR5brFYlJqa+o/X/yRp2LChZs2aJScnJwUEBMjBwfafP3efKnDt2jVVr15dYWFh6ZaVNrsgqx7mO33t2jVJt0+3eOqpp2z6nJ2dH6oOSSpTpowk6ejRow8M6A/C9xgAHoxzugEAj0xycrIWLlyoyZMnKyoqyvrYt2+fAgICtHjxYkm3j4rd7/ZbTk5OSklJsWnz8fFRTEyMTQCIioqyGfPLL79owIABatGihSpWrChnZ2ddvHgx0/V7e3srJCREM2bM0PXr19P1p93yqHz58vrjjz/0xx9/WPsOHz6suLg4VahQwVrv3eej311vZjg6OqZ7L2Arf/78KlWqlIoWLZoucGekWrVqOn78uHx9fVWqVCmbh6enpzw9PVW4cGHt2LHD+prk5GTt2bPnnsusVKmSUlNTredi3y3tSPudn2WFChXk7OysM2fOpKsjbRZF+fLltXPnTptl3XlBv4w0bdpUhQoV0sSJEzPsv/N7HBkZafM39csvv8jd3V1FihSRlP57HB8fr+jo6Puu/24ZbTsA5CWEbgDAI7NmzRpdvnxZvXr10tNPP23zaN++vebMmSNJGj16tBYvXqzRo0fryJEj6c5RLVasmLZs2aKzZ89aQ3ODBg30119/aeLEiTp58qRmzJihH374wWb9pUuX1n//+18dOXJEO3bsUJcuXbJ8BHLGjBlKSUlRzZo19e233+r48eM6cuSIpk+fbj1q2KRJE1WqVEldunTRr7/+qp07d6pr166qX7++atSoIen2+eW7d+/WwoULdfz4cY0ePVoHDx7M8ntarFgxRUREKCYmRpcvX87y65Fely5dVKhQIbVp00Zbt25VdHS0Nm3apAEDBujPP/+UJA0cOFAfffSRVq5cqaNHj+rNN9+8732mixUrpm7duqlnz55auXKldZlLly6VJAUFBclisWjNmjX666+/dO3aNbm7u+vtt9/W4MGDtWDBAp08eVK//vqrPv30Uy1YsECS1LdvXx0/flxDhw7VsWPHtGjRogzvBnCntHPY165dqxdffFEbNmzQ6dOntXv3bg0bNkx9+/aVdPtK/X/88Yf69++vo0eP6rvvvtPo0aM1ZMgQ6/ncjRo10n//+19t3bpVBw4cULdu3WRvb5+l9zujbQeAPMUAAORK169fN3bv3m1cv349p0vJtFatWhktWrTIsG/Hjh2GJGPfvn2GYRjGt99+a1StWtVwcnIyChUqZLRr1846NjIy0qhcubLh7Oxs3Pm/slmzZhmBgYFG/vz5ja5duxoffvihERQUZO3/9ddfjRo1ahguLi5G6dKljWXLlhlBQUHGlClTrGMkGStWrLjvdpw7d84IDQ01goKCDCcnJ+Opp54yXnzxReOnn36yjvn999+NF1980cifP7/h7u5uvPLKK0ZMTIzNckaNGmX4+fkZnp6exuDBg41+/foZ9evXt/bXr1/fGDhwoM1r2rRpY3Tr1s36fNWqVUapUqUMBwcHm23Fbd26dTPatGmT5f7z588bXbt2NQoVKmQ4OzsbJUqUMF5//XXjypUrhmEYRlJSkjFw4EDDw8PD8PLyMoYMGWJ07drVZll3f343b940Bg8ebBQuXNhwcnIySpUqZcydO9faP27cOMPf39+wWCzWzzg1NdWYOnWqUbZsWcPR0dHw8fExQkJCjM2bN1tft3r1aqNUqVKGs7OzUbduXWPu3LmGJOPy5cv3fW927dpltGvXzvDx8TGcnZ2NUqVKGX369DGOHz9uHbNp0ybj2WefNZycnAx/f39j+PDhRlJSkrX/ypUrRseOHQ0PDw8jMDDQmD9/vlGlShVj9OjR1jEZ/U15enoa8+bNu++23y1tn7dw4UJj2rRpxtWrV++7fQDwuLAYRiavpgEAeKzcuHFDR44cUfny5ZUvX76cLgcATJW2zzt8+LAuX76snj17ys3NLafLAoAHYno5AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwDkcqmpqTldAgCYjn0dgNyK0A0AuZSTk5MkcU9bAE+EtH1dYmJiDlcCAFnjkNMFAAAejoODgwoVKqSzZ89Kktzc3GRnx2+pAPKW1NRUXbt2TWfPnlVcXJySk5NlsVhyuiwAyDRCNwDkYkWLFlVKSoo1eANAXhUXF6fY2FjdunVLLi4ucnV1zemSACBTCN0AkItZLBaVKFFCW7Zs0YEDB+Ti4iInJyeOAgHIUxITE5WcnKybN28qISFBNWvWlL29fU6XBQCZYjEMw8jpIgAA/0xKSoq2bdumgwcPKikpKafLAQBTODo6qkqVKqpduzan0wDINQjdAJCHJCUl6ebNmzldBgCYIl++fHJwYKImgNyF0A0AAAAAgEmYlwMAAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQA5yGKxaMyYMTldRo5r0KCBGjRoYH1++vRpWSwWzZ8/P8dqutvdNeZFY8aMkcViyZF1t2jRQq+//nqOrPt+HsfvIp4MtWvX1rBhw3K6DADZgNANIM+YOXOmLBaLatWq9dDLOHfunMaMGaOoqKjsK+wxt2nTJlksFuvD0dFRJUqUUNeuXXXq1KmcLi9Ltm3bpjFjxiguLi7HakhMTNS0adP0zDPPyMPDQ15eXqpYsaL69Omjo0eP5lhdj7NffvlFP/74o4YPHy5JKlasmM138l6PzAThmTNnPvLA/P3338tisSggIECpqamPdN150ZIlS1StWjW5uLjIx8dHvXr10sWLF9ONi42NVY8ePeTr6ytXV1dVq1ZNy5Yty9Q6unfvft/v2tmzZ61jk5KSNHbsWJUoUULOzs4qUaKEPvjgAyUnJ9ss8+zZs2rZsqU8PDxUoUIFrV69Ot16ly9fLl9fX125ciVd3/DhwzVjxgzFxMRkahsAPL4ccroAAMguYWFhKlasmHbu3KkTJ06oVKlSWV7GuXPnNHbsWBUrVkxVq1bN/iIfYwMGDNCzzz6rpKQk/frrr/riiy+0du1aHThwQAEBAY+0lqCgIN28eVOOjo5Zet22bds0duxYde/eXV5eXuYU9wDt27fXDz/8oFdffVWvv/66kpKSdPToUa1Zs0bPPfecypUrlyN1Pc4mTZqkxo0bW/9mp06dqmvXrln7v//+ey1evFhTpkxRoUKFrO3PPffcA5c9c+ZMFSpUSN27d8/2uu8lbV90+vRpbdy4UU2aNHlk685rZs2apTfffFONGzfWJ598oj///FPTpk3T7t27tWPHDrm4uEiS4uPj9fzzzys2NlYDBw6Uv7+/li5dqg4dOigsLEydO3e+73r+/e9/p/ucDMNQ3759VaxYMT311FPW9tdee03Lli1Tz549VaNGDW3fvl3vvfeezpw5oy+++MI6rlu3bjp79qw+/vhj/fLLL3rllVd09OhRFStWTJJ069Ytvf322/rggw/k6emZrqY2bdrIw8NDM2fO1Lhx4x72LQTwODAAIA84deqUIclYvny54ePjY4wZM+ahlrNr1y5DkjFv3rzsLfAeJBmjR49+JOu6l59++smQZCxbtsymffr06YYkY/z48fd87bVr17Klhvr16xv169f/x8uZNGmSIcmIjo7+x8u6W2Zq3LlzpyHJ+PDDD9P1JScnGxcvXsz2urLT6NGjjUf9T4PY2FjDwcHB+PLLL+855p98rhUrVvxH363o6Ogs7ROuXbtm5M+f35g+fbrxzDPPGN27d3/odZstu/5+zZKQkGB4eXkZ9erVM1JTU63tq1evNiQZ06dPt7ZNnDjRkGRERERY21JSUoxnn33W8Pf3NxISErK8/q1bt6b7e077G3/vvfdsxr711luGxWIx9u3bZxiGYdy4ccOwWCzG5s2bDcMwjNTUVKN48eLG7Nmzra95//33japVqxopKSn3rKFfv35GUFCQzfYDyH2YXg4gTwgLC1OBAgXUsmVLvfzyywoLC8twXFxcnAYPHqxixYrJ2dlZRYoUUdeuXXXx4kVt2rRJzz77rCSpR48e6aawFitWLMOjZXef65uYmKhRo0apevXq8vT0VP78+VW3bl399NNPWd6u2NhYOTg4aOzYsen6jh07JovFos8++0zS/015LF26tFxcXFSwYEE9//zzCg8Pz/J6JalRo0aSpOjoaEn/d77v4cOH1blzZxUoUEDPP/+8dfxXX32l6tWry9XVVd7e3urUqZP++OOPdMv94osvVLJkSbm6uqpmzZraunVrujH3Oo/26NGj6tChg3x8fOTq6qqyZcvqnXfesdY3dOhQSVLx4sWtn9/p06dNqTEjJ0+elCTVqVMnXZ+9vb0KFixoff7777/rzTffVNmyZeXq6qqCBQvqlVdesalXkubPny+LxaKff/5ZAwYMkI+Pj7y8vPTvf/9biYmJiouLU9euXVWgQAEVKFBAw4YNk2EY6d7L//znP5oyZYqCgoLk6uqq+vXr6+DBg5narsy8b8ePH1f79u3l7+8vFxcXFSlSRJ06dcpw2uyd1q5dq+Tk5CwfDU5OTtb777+vkiVLytnZWcWKFdP//M//KCEhwTqmWLFiOnTokDZv3mz9PqT9rV66dElvv/22KlWqJDc3N3l4eKh58+bat29fluq424oVK3Tz5k298sor6tSpk5YvX65bt26lG3fr1i2NGTNGZcqUkYuLiwoXLqx27dpZv0OSlJqaqmnTpqlSpUrWqdXNmjXT7t27Jd3/fPO7rxdxv7/f/fv3q3v37ipRooRcXFzk7++vnj176u+//0633LNnz6pXr14KCAiQs7OzihcvrjfeeEOJiYk6deqULBaLpkyZku5127Ztk8Vi0eLFi3Xjxg0dPXo0wynidzp48KDi4uLUsWNHm2sNtGrVSm5ublqyZIm1bevWrfLx8bHutyTJzs5OHTp0UExMjDZv3nzfdWVk0aJFslgsNkfJ0/YFnTp1shnbqVMnGYahr7/+WtLtz9cwDBUoUEDS7c/Dy8tLN27ckHT7ffzoo480bdo02dnd+5/jL7zwgn7//fcn6pQnIC9iejmAPCEsLEzt2rWTk5OTXn31Vc2aNUu7du2yhmhJunbtmurWrasjR46oZ8+eqlatmi5evKhVq1bpzz//VPny5TVu3DiNGjVKffr0Ud26dSVlbgrrneLj4/Xll19apxdfvXpVc+bMUUhIiHbu3Jmlaet+fn6qX7++li5dqtGjR9v0ff3117K3t9crr7wi6fY/qidMmKDevXurZs2aio+P1+7du/Xrr7/qhRdeyNI2SP8XIO8MipL0yiuvqHTp0ho/frw13H344Yd677331KFDB/Xu3Vt//fWXPv30U9WrV0979+61TvWeM2eO/v3vf+u5557ToEGDdOrUKb344ovy9vZWYGDgfevZv3+/6tatK0dHR/Xp00fFihXTyZMntXr1an344Ydq166dfvvtt3TTkH18fB5ZjUFBQZJufx/r1KkjB4d7/292165d2rZtmzp16qQiRYro9OnTmjVrlho0aKDDhw8rX758NuP79+8vf39/jR07Vtu3b9cXX3whLy8vbdu2TUWLFtX48eP1/fffa9KkSXr66afVtWtXm9cvXLhQV69eVWhoqG7duqVp06apUaNGOnDggPz8/O5ZZ2bet8TERIWEhCghIcFa59mzZ7VmzRrFxcVlOHU2zbZt21SwYEHre5dZvXv31oIFC/Tyyy/rrbfe0o4dOzRhwgQdOXJEK1askHR7mnr//v3l5uZm/XEmbVtPnTqllStX6pVXXlHx4sUVGxurzz//XPXr19fhw4cf+pSKsLAwNWzYUP7+/urUqZNGjBih1atXW/9OJSklJUWtWrVSRESEOnXqpIEDB+rq1asKDw/XwYMHVbJkSUlSr169NH/+fDVv3ly9e/dWcnKytm7dqu3bt6tGjRoPVV9Gf7/h4eE6deqUevToIX9/fx06dEhffPGFDh06pO3bt1sD77lz51SzZk3FxcWpT58+KleunM6ePatvvvlGN27cUIkSJVSnTh2FhYVp8ODB6d4Xd3d3tWnTRjt37lTDhg01evTo+15IMu0HFFdX13R9rq6u2rt3r1JTU2VnZ6eEhIQMx6X9He3ZsydL+8GkpCQtXbpUzz33nHU6+P1qunM9klSgQAGVLFlS48eP1/jx47Vt2zZFRUXp008/lSQNGzZMzZs3V7169e5bR/Xq1SXdvu7BM888k+n6ATxmcvQ4OwBkg927dxuSjPDwcMMwbk/jK1KkiDFw4ECbcaNGjbJOQb9b2tS9+00vDwoKMrp165au/e5px8nJyemmMl6+fNnw8/MzevbsadOuTEwv//zzzw1JxoEDB2zaK1SoYDRq1Mj6vEqVKkbLli3vu6yMpE0vnzt3rvHXX38Z586dM9auXWsUK1bMsFgsxq5duwzD+L+px6+++qrN60+fPm3Y29unm1J94MABw8HBwdqemJho+Pr6GlWrVrV5f7744gtDks17mNGU3nr16hnu7u7G77//brOeO6dd3msashk1ZiQ1NdWoX7++Icnw8/MzXn31VWPGjBnpajaM29NP7xYZGWlIMhYuXGhtmzdvniHJCAkJsdnW4OBgw2KxGH379rW2JScnG0WKFMnwvXR1dTX+/PNPa/uOHTsMScbgwYOtbXdPL8/s+7Z3794MT1HIjOeff96oXr36fcfc/blGRUUZkozevXvbjHv77bcNScbGjRutbfeaXn7r1q1003qjo6MNZ2dnY9y4cTZt99on3C1tqvz//u//Wtuee+45o02bNjbj5s6da0gyPvnkk3TLSPuMN27caEgyBgwYcM8x96vt7n3Lvf5+DSPj7+LixYsNScaWLVusbV27djXs7Oys+4SMakrbXx05csTal5iYaBQqVMi6/0zb5zxo3/fXX38ZFovF6NWrl0370aNHDUmGJOspG/379zfs7OyM06dP24zt1KmTIcno16/ffdd1t7Qp7DNnzrRp//bbbw1Jxn//+1+b9tmzZxuSjKefftraFhERYRQoUMBa66BBgwzDMIxffvnFcHV1TVfrvTg5ORlvvPFGluoH8HhhejmAXC8sLEx+fn5q2LChpNvT+Dp27KglS5YoJSXFOu7bb79VlSpV9NJLL6VbRnbeJsne3l5OTk6Sbk8PvXTpkpKTk1WjRg39+uuvWV5eu3bt5ODgYJ22KN2ednn48GF17NjR2ubl5aVDhw7p+PHjD1V3z5495ePjo4CAALVs2VLXr1/XggUL0h1R69u3r83z5cuXKzU1VR06dNDFixetD39/f5UuXdo6rX737t26cOGC+vbta31/pNtXDb7fkVBJ+uuvv7Rlyxb17NlTRYsWtenLzGf3KGpMq2X9+vX64IMPVKBAAS1evFihoaEKCgpSx44dba6qfueRsqSkJP39998qVaqUvLy8Mvye9OrVy2Zba9WqJcMw1KtXL2ubvb29atSokeFV59u2bWtzMaiaNWuqVq1a+v777++5PZl939Lem/Xr11unz2bW33//bZ2Cm1lpNQ8ZMsSm/a233pJ0e8r6gzg7O1un9aakpOjvv/+Wm5ubypYt+1B/p9Ltq2zb2dmpffv21rZXX31VP/zwgy5fvmxt+/bbb1WoUCH1798/3TLSPuNvv/1WFosl3QyXO8c8jLv/fiXb7+KtW7d08eJF1a5dW5Ks70VqaqpWrlyp1q1bZ3iUPa2mDh06yMXFxeYUn/Xr1+vixYt67bXXJN0+JccwjAfeLrFQoULq0KGDFixYoMmTJ+vUqVPaunWrOnbsaL3I4s2bNyXdnvlgb2+vDh06aNu2bTp58qQmTJhgnfWQNi6zFi1aJEdHR3Xo0MGmvUWLFgoKCtLbb7+t5cuX6/fff9fSpUv1zjvvyMHBwWY9jRo10pkzZ7R9+3adOXNGU6ZMUWpqqgYMGKC33npLQUFBmjVrlsqVK6eyZctq9uzZGdZSoECBB07FB/B4I3QDyNVSUlK0ZMkSNWzYUNHR0Tpx4oROnDihWrVqKTY2VhEREdaxJ0+e1NNPP/1I6lqwYIEqV65sPbfax8dHa9eufeD5rRkpVKiQGjdurKVLl1rbvv76azk4OKhdu3bWtnHjxikuLk5lypRRpUqVNHToUO3fvz/T6xk1apTCw8O1ceNG7d+/X+fOndO//vWvdOOKFy9u8/z48eMyDEOlS5eWj4+PzePIkSO6cOGCpNvnMEtS6dKlbV6fdouy+0kLkQ/7+T2KGtM4OzvrnXfe0ZEjR3Tu3DktXrxYtWvX1tKlS9WvXz/ruJs3b2rUqFEKDAyUs7OzChUqJB8fH8XFxWX4Pbn7x4a0oHv3lHdPT0+bgJfm7m2SpDJlyqQ7h/xOmX3fihcvriFDhujLL79UoUKFFBISohkzZmT6+27ccQ56Zvz++++ys7NLd4cCf39/eXl5WT/H+0lNTdWUKVNUunRpm/d///79D/V3Kt0+971mzZr6+++/rfuiZ555RomJiTa3rjp58qTKli1739MPTp48qYCAAHl7ez9ULfdy99+vdPv89oEDB8rPz0+urq7y8fGxjkt7L/766y/Fx8c/8G/Qy8tLrVu31qJFi6xtYWFheuqpp2zOt86szz//XC1atNDbb7+tkiVLql69eqpUqZJat24tSXJzc5MkVa5cWYsWLdLJkydVp04dlSpVStOnT9fUqVNtxmXGtWvX9N133ykkJCTd6TUuLi5au3atChYsqPbt26tYsWLq2rWrRo0aJW9v73TrcXNzU61atax/p/PmzVNMTIxGjBihDRs2aOjQofroo480ceJEvfXWWxle+8MwjGz9YRjAo8c53QBytY0bN+r8+fNasmSJzUV10oSFhalp06bZsq57/aMnJSVF9vb21udfffWVunfvrrZt22ro0KHy9fWVvb29JkyYYHORpKzo1KmTevTooaioKFWtWlVLly5V48aNbW6fVK9ePZ08eVLfffedfvzxR3355ZeaMmWKZs+erd69ez9wHZUqVcrUxazuPpcxNTVVFotFP/zwg837kCYr/9g1S07VWLhwYXXq1Ent27dXxYoVtXTpUs2fP18ODg7q37+/5s2bp0GDBik4OFienp6yWCzq1KlThvd2zqjue7VnNcTeS1bet8mTJ6t79+7W79+AAQM0YcIEbd++XUWKFLnnOgoWLJjhjwSZ8U+CyPjx4/Xee++pZ8+eev/99+Xt7S07OzsNGjTooe6tffz4ce3atUtSxj9whIWFqU+fPg9db0but0+6l4zOe047Ojx06FBVrVpVbm5uSk1NVbNmzR7qvejatauWLVumbdu2qVKlSlq1apXefPPN+14w7F48PT313Xff6cyZMzp9+rSCgoIUFBSk5557znpRwTQvv/yyXnzxRe3bt08pKSmqVq2aNm3aJOn2D0yZtXLlSt24cUNdunTJsL9ixYrW2UaXL19WhQoV5OrqqsGDB6t+/fr3XG58fLzeeecd/ec//1H+/Pm1ePFivfzyy2rbtq21/rRrAtwpLi7OZl8PIPchdAPI1cLCwuTr66sZM2ak61u+fLlWrFih2bNny9XVVSVLlnzg1Zrv94/4AgUK2EwPTvP777/bHAX95ptvVKJECS1fvtxmeRlNE82stm3b6t///rd1ivlvv/2mkSNHphvn7e2tHj16qEePHrp27Zrq1aunMWPGZCp0P6ySJUvKMAwVL178vv+wTbtQ1vHjx22OeCUlJSk6OlpVqlS552vT3t+H/fweRY334+joqMqVK+v48ePW6dnffPONunXrpsmTJ1vH3bp1K8PvWHbI6LSD3377zeYiUXfL7PuWplKlSqpUqZLeffddbdu2TXXq1NHs2bP1wQcf3PM15cqV07fffpupbUgTFBSk1NRUHT9+XOXLl7e2x8bGKi4uzuaibPf6TnzzzTdq2LCh5syZY9P+sAEnLCxMjo6O+u9//5vuB4qff/5Z06dP15kzZ1S0aFGVLFlSO3bsUFJS0j3vRV+yZEmtX79ely5duufR7rRp+Xd/ZzJzpD/N5cuXFRERobFjx2rUqFHW9ru/Lz4+PvLw8MjUFe+bNWsmHx8fhYWFqVatWrpx40aGs2ayomjRotbZHnFxcdqzZ4/NNP40Tk5ONhfQ3LBhgyRl6er4YWFhcnNz04svvnjPMRaLRRUrVrQ+//7775Wamnrf9YwbN07Fixe3hvlz587ZXBwtICAg3VXKz549q8TERJvvOYDch+nlAHKtmzdvavny5WrVqpVefvnldI9+/frp6tWrWrVqlSSpffv22rdvn/UcvzulHRnMnz+/pPT/iJVu/yN4+/btSkxMtLatWbMm3a2T0v7BfefRxh07digyMvKht9XLy0shISFaunSplixZIicnJ+vRkTR3397Hzc1NpUqVsrmFkhnatWsne3t7jR07Nt0RVsMwrHXVqFFDPj4+mj17ts17OH/+/AcGTR8fH9WrV09z587VmTNn0q0jzb0+v0dRo3Q7qNxdX1o9kZGRKlCggPVq6vb29ulq+fTTT+97lPKfWLlypc6ePWt9vnPnTu3YsUPNmze/52sy+77Fx8crOTnZpr9SpUrWq0rfT3BwsC5fvpzheej30qJFC0myTh1O88knn0iSWrZsaW3Lnz9/hp9dRu//smXLbN6jrAgLC1PdunXVsWPHdPuitFvZLV68WNLtfdHFixett/u7U1pN7du3l2EYGd4uMG2Mh4eHChUqpC1bttj0z5w5M9N1Z7S/ktK/t3Z2dmrbtq1Wr15tvWVZRjVJkoODg1599VXrzI5KlSqpcuXK1v7M3jLsXkaOHKnk5OR0V0i/2/HjxzV79my1atXK5kejixcv6ujRoxlef+Cvv/7Shg0b9NJLL6W7g8C93Lx5U++9954KFy6sV199NcMxv/32mz777DNNmzbN+kOQn5+fjh49ah1z5MgR+fv727wu7WroWb2LBoDHC0e6AeRaq1at0tWrV+95NKJ27drWoy0dO3bU0KFD9c033+iVV15Rz549Vb16dV26dEmrVq3S7NmzVaVKFZUsWVJeXl6aPXu23N3dlT9/ftWqVUvFixdX79699c0336hZs2bq0KGDTp48qa+++sp6e580rVq10vLly/XSSy+pZcuWio6O1uzZs1WhQgVdu3btobe3Y8eOeu211zRz5kyFhITYTKuUpAoVKqhBgwaqXr26vL29tXv3bn3zzTc25xGboWTJkvrggw80cuRInT59Wm3btpW7u7uio6O1YsUK9enTR2+//bYcHR31wQcf6N///rcaNWqkjh07Kjo6WvPmzcvU+dLTp0/X888/r2rVqqlPnz4qXry4Tp8+rbVr11qPDqXdXuedd95Rp06d5OjoqNatWz+yGvft26fOnTurefPmqlu3rry9vXX27FktWLBA586d09SpU60hp1WrVvrvf/8rT09PVahQQZGRkdqwYUO6c0izS6lSpfT888/rjTfeUEJCgqZOnaqCBQtq2LBh93xNZt+3jRs3ql+/fnrllVdUpkwZJScnW4/4ZnQ08k4tW7aUg4ODNmzYkOnp11WqVFG3bt30xRdfKC4uTvXr19fOnTu1YMECtW3b1mZ6bvXq1TVr1ix98MEHKlWqlHx9fdWoUSO1atVK48aNU48ePfTcc8/pwIEDCgsLy/S5+3fasWOHTpw4cc+/taeeekrVqlVTWFiYhg8frq5du2rhwoUaMmSIdu7cqbp16+r69evasGGD3nzzTbVp00YNGzbUv/71L02fPl3Hjx+3TvXeunWrGjZsaF1X79699dFHH6l3796qUaOGtmzZot9++y3TtXt4eKhevXqaOHGikpKS9NRTT+nHH39UdHR0urHjx4/Xjz/+qPr166tPnz4qX768zp8/r2XLlunnn3+22Sd17dpV06dP108//aSPP/7YZjmZvWWYJH300Uc6ePCgatWqJQcHB61cuVI//vijPvjgA5sj2tLtfeArr7yiokWLKjo6WrNmzZK3t3e6C5R99tlnGjt2rH766SfrfdvTfP3110pOTr7n1HLp9nT8gIAAVahQQfHx8Zo7d65OnTqltWvXyt3dPcPXDB48WB07dlTNmjWtbS+//LLatGmj//mf/5EkrV69WmvWrLF5XXh4uIoWLcrtwoDc7hFdJR0Asl3r1q0NFxcX4/r16/cc0717d8PR0dF6W5m///7b6Nevn/HUU08ZTk5ORpEiRYxu3bpZ+w3DML777jujQoUKhoODQ7rb8UyePNl46qmnDGdnZ6NOnTrG7t27090yLDU11Rg/frwRFBRkODs7G88884yxZs0ao1u3bkZQUJBNfcrEbXPSxMfHG66uroYk46uvvkrX/8EHHxg1a9Y0vLy8DFdXV6NcuXLGhx9+aCQmJt53uWm373nQ7Z7Sbjn0119/Zdj/7bffGs8//7yRP39+I3/+/Ea5cuWM0NBQ49ixYzbjZs6caRQvXtxwdnY2atSoYWzZsiXde3ivWyEdPHjQeOmllwwvLy/DxcXFKFu2rPHee+/ZjHn//feNp556yrCzs0t3+7DsrDEjsbGxxkcffWTUr1/fKFy4sOHg4GAUKFDAaNSokfHNN9/YjL18+bLRo0cPo1ChQoabm5sREhJiHD16NN2t6dJuGXb3bZru9Xl069bNyJ8/f7r3ctKkScbkyZONwMBAw9nZ2ahbt66xb9++DJd5twe9b6dOnTJ69uxplCxZ0nBxcTG8vb2Nhg0bGhs2bLjv+5XmxRdfNBo3bnzP/oxuBZeUlGSMHTvWKF68uOHo6GgEBgYaI0eONG7dumXz2piYGKNly5aGu7u7zW3fbt26Zbz11ltG4cKFDVdXV6NOnTpGZGRkpr+Ld+rfv78hyTh58uQ9x4wZM8aQZH3Pb9y4YbzzzjvW+v39/Y2XX37ZZhnJycnGpEmTjHLlyhlOTk6Gj4+P0bx5c2PPnj3WMTdu3DB69epleHp6Gu7u7kaHDh2MCxcu3POWYRn9/f7555/WvytPT0/jlVdeMc6dO5fh/un33383unbtavj4+BjOzs5GiRIljNDQ0HS3STSM27drs7Ozs7lVnWFk/pZhhmEYa9asMWrWrGm4u7sb+fLlM2rXrm0sXbo0w7GdOnUyAgMDDScnJyMgIMDo27evERsbm25c2nvx008/peurXbu24evrayQnJ9+zpo8//tgoV66c4eLiYhQoUMB48cUXjb17995z/Nq1aw03Nzfj3Llz6fomTJhgBAQEGIULFzY+/vhjm76UlBSjcOHCxrvvvnvPZQPIHSyGkU1XWwEAAI+d06dPq3jx4po0aZLefvvtnC4nQ1u3blWDBg109OjRDC9ChtzpmWeekbe3t81dJJB5K1euVOfOnXXy5EkVLlw4p8sB8A9wTjcAAMhRdevWVdOmTTVx4sScLgXZZPfu3YqKilLXrl1zupRc6+OPP1a/fv0I3EAewDndAAAgx/3www85XQKywcGDB7Vnzx5NnjxZhQsXVseOHXO6pFzrn1x8E8DjhSPdAAAAyBbffPONevTooaSkJC1evFguLi45XRIA5DjO6QYAAAAAwCQc6QYAAAAAwCSEbgAAAAAATMKF1DIhNTVV586dk7u7uywWS06XAwAAAADIYYZh6OrVqwoICJCd3b2PZxO6M+HcuXMKDAzM6TIAAAAAAI+ZP/74Q0WKFLlnP6E7E9zd3SXdfjM9PDxyuBoAAAAAQE6Lj49XYGCgNS/eC6E7E9KmlHt4eBC6AQAAAABWDzoFmQupAQAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAOSgWbNmqXLlyvLw8JCHh4eCg4P1ww8/WPtv3bql0NBQFSxYUG5ubmrfvr1iY2NtljFgwABVr15dzs7Oqlq1aobr2b9/v+rWrSsXFxcFBgZq4sSJZm4W/j9CNwAAAADkoCJFiuijjz7Snj17tHv3bjVq1Eht2rTRoUOHJEmDBw/W6tWrtWzZMm3evFnnzp1Tu3bt0i2nZ8+e6tixY4briI+PV9OmTRUUFKQ9e/Zo0qRJGjNmjL744gtTtw2EbpgsO361O3PmjFq2bKl8+fLJ19dXQ4cOVXJyss2YTZs2qVq1anJ2dlapUqU0f/78R7F5API49mG5x6P4rM6fP6/OnTurTJkysrOz06BBgx7V5gEPhX1Y7tG6dWu1aNFCpUuXVpkyZfThhx/Kzc1N27dv15UrVzRnzhx98sknatSokapXr6558+Zp27Zt2r59u3UZ06dPV2hoqEqUKJHhOsLCwpSYmKi5c+eqYsWK6tSpkwYMGKBPPvnkUW3mE4vQDVP901/tUlJS1LJlSyUmJmrbtm1asGCB5s+fr1GjRlnHREdHq2XLlmrYsKGioqI0aNAg9e7dW+vXr3/k2wsgb2Eflns8is8qISFBPj4+evfdd1WlSpVHvo1AVrEPy51SUlK0ZMkSXb9+XcHBwdqzZ4+SkpLUpEkT65hy5cqpaNGiioyMzPRyIyMjVa9ePTk5OVnbQkJCdOzYMV2+fDlbtwF3MfBAV65cMSQZV65cyelS8oQCBQoYX375pREXF2c4Ojoay5Yts/YdOXLEkGRERkYahmEY33//vWFnZ2fExMRYx8yaNcvw8PAwEhISDMMwjGHDhhkVK1a0WUfHjh2NkJCQR7A1ecf48eONGjVqGG5uboaPj4/Rpk0b4+jRozZjTpw4YbRt29YoVKiQ4e7ubrzyyis2n41hGMaxY8eMF1980ShYsKDh7u5u1KlTx9i4caPNmA0bNhjBwcGGm5ub4efnZwwbNsxISkoyfRuB7MA+LPfI7s/qTvXr1zcGDhxo+jYA2Y192ONr//79Rv78+Q17e3vD09PTWLt2rWEYhhEWFmY4OTmlG//ss88aw4YNS9c+evRoo0qVKunaX3jhBaNPnz42bYcOHTIkGYcPH86ejXjCZDYncqQbj8zD/GoXGRmpSpUqyc/PzzomJCRE8fHx1l9pIyMjbZaRNiYrv/xB2rx5s0JDQ7V9+3aFh4crKSlJTZs21fXr1yVJ169fV9OmTWWxWLRx40b98ssvSkxMVOvWrZWammpdTqtWrZScnKyNGzdqz549qlKlilq1aqWYmBhJ0r59+9SiRQs1a9ZMe/fu1ddff61Vq1ZpxIgRObLdQGaxD8s9zPqsgNyMfdjjr2zZsoqKitKOHTv0xhtvqFu3bjp8+HBOl4Vs4JDTBSDvO3DggIKDg3Xr1i25ublpxYoVqlChgqKiouTk5CQvLy+b8X5+ftaAFhMTY7OjT+tP67vfmPj4eN28eVOurq4mbVnesm7dOpvn8+fPl6+vr/bs2aN69erpl19+0enTp7V37155eHhIkhYsWKACBQpo48aNatKkiS5evKjjx49rzpw5qly5siTpo48+0syZM3Xw4EH5+/vr66+/VuXKla1T00qVKqWJEyeqQ4cOGj16tNzd3R/thgMPwD4s9zD7swJyI/ZhuYeTk5NKlSolSapevbp27dqladOmqWPHjkpMTFRcXJzN5xUbGyt/f/9ML9/f3z/dOftpz7OyHGQdR7phOn61y52uXLkiSfL29pZ0+1xGi8UiZ2dn6xgXFxfZ2dnp559/liQVLFhQZcuW1cKFC3X9+nUlJyfr888/l6+vr6pXr25djouLi826XF1ddevWLe3Zs+dRbBqQJezDcg8+KyA9/i5yr9TUVCUkJKh69epydHRURESEte/YsWM6c+aMgoODM7284OBgbdmyRUlJSda28PBwlS1bVgUKFMjW2mGL0A3Tpf1qV716dU2YMEFVqlTRtGnT5O/vb/3V7k53/mqXmV/k7jXGw8ODX1cfUmpqqgYNGqQ6dero6aefliTVrl1b+fPn1/Dhw3Xjxg1dv35db7/9tlJSUnT+/HlJksVi0YYNG7R37165u7vLxcVFn3zyidatW2fdmYeEhGjbtm1avHixUlJSdPbsWY0bN06SrMsBHifsw3IPsz8rIDdiH5Y7jBw5Ulu2bNHp06d14MABjRw5Ups2bVKXLl3k6empXr16aciQIfrpp5+0Z88e9ejRQ8HBwapdu7Z1GSdOnFBUVJRiYmJ08+ZNRUVFKSoqSomJiZKkzp07y8nJSb169dKhQ4f09ddfa9q0aRoyZEhObfYTg9CNRy4rv9oFBwfrwIEDunDhgnVMeHi4PDw8VKFCBeuYO5eRNiYrv/zBVmhoqA4ePKglS5ZY23x8fLRs2TKtXr1abm5u8vT0VFxcnKpVqyY7u9u7EsMwFBoaKl9fX23dulU7d+5U27Zt1bp1a2ugbtq0qSZNmqS+ffvK2dlZZcqUUYsWLSTJuhzgccY+LPfI7s8KyAvYhz2eLly4oK5du6ps2bJq3Lixdu3apfXr1+uFF16QJE2ZMkWtWrVS+/btVa9ePfn7+2v58uU2y+jdu7eeeeYZff755/rtt9/0zDPP6JlnntG5c+ckSZ6envrxxx8VHR2t6tWr66233tKoUaPUp0+fR769T5xHc1233I2rlz+8ESNGGJs3bzaio6ON/fv3GyNGjDAsFovx448/GoZhGH379jWKFi1qbNy40di9e7cRHBxsBAcHW1+fnJxsPP3000bTpk2NqKgoY926dYaPj48xcuRI65hTp04Z+fLlM4YOHWocOXLEmDFjhmFvb2+sW7fukW9vXhAaGmoUKVLEOHXq1D3H/PXXX8bly5cNwzAMPz8/Y+LEiYZh3L4quZ2dXbq/lVKlShkTJkywaUtNTTXOnj1r3Lhxwzh8+LAhydi5c2f2bgzwD7EPyz0exWdlGIaxd+9eY+/evUb16tWNzp07G3v37jUOHTr0SLcVyCz2YYC5MpsTCd2ZQOh+eD179jSCgoIMJycnw8fHx2jcuLF1R28YhnHz5k3jzTffNAoUKGDky5fPeOmll4zz58/bLOP06dNG8+bNDVdXV6NQoULGW2+9le72Uj/99JNRtWpVw8nJyShRooQxb968R7F5eUpqaqoRGhpqBAQEGL/99lumXhMREWFYLBbrrcVWrVpl2NnZGVevXrUZV6ZMGePDDz+853Lee+89IzAw0EhOTn74DQBMwD4s93hUn5WkdI+goKBHsYlAlrEPA8yV2ZxoMQzDyKmj7LlFfHy8PD09deXKFetVm4G85s0339SiRYv03XffqWzZstZ2T09P6zlZ8+bNU/ny5eXj46PIyEgNHDhQ3bt31+TJkyVJFy9eVLly5VS/fn2NGjVKrq6u+t///V9NmzZNu3btUpUqVSRJkyZNUrNmzWRnZ6fly5fr/fff19KlS9W2bdtHvt0AAADAw8hsTiR0ZwKhG08Ci8WSYfu8efPUvXt3SdKIESM0f/58Xbp0ScWKFVPfvn01ePBgm9fu3r1b77zzjnbv3q2kpCRVrFhRo0aNUvPmza1jGjVqpF9//VUJCQmqUqWKRo8ebdMPAAAAPO4I3dmI0A0AAAAAuFNmc2KOXip41qxZqly5sjw8POTh4aHg4GD98MMP1v5bt24pNDRUBQsWlJubm9q3b5/ulgRnzpxRy5YtlS9fPvn6+mro0KFKTk62GbNp0yZVq1ZNzs7OKlWqlObPn/8oNg8AAAAA8ITL0dBdpEgRffTRR9qzZ492796tRo0aqU2bNjp06JAkafDgwVq9erWWLVumzZs369y5c2rXrp319SkpKWrZsqUSExO1bds2LViwQPPnz9eoUaOsY6Kjo9WyZUs1bNhQUVFRGjRokHr37q3169c/8u0FAAAAADxZHrvp5d7e3po0aZJefvll+fj4aNGiRXr55ZclSUePHlX58uUVGRmp2rVr64cfflCrVq107tw5+fn5SZJmz56t4cOH66+//pKTk5OGDx+utWvX6uDBg9Z1dOrUSXFxcVq3bl2mamJ6OQAAAJA3JI19K6dLQCY5jp6c0yXcV66YXn6nlJQULVmyRNevX1dwcLD27NmjpKQkNWnSxDqmXLlyKlq0qCIjIyVJkZGRqlSpkjVwS1JISIji4+OtR8sjIyNtlpE2Jm0ZGUlISFB8fLzNAwAAAACArHLI6QIOHDig4OBg3bp1S25ublqxYoUqVKigqKgoOTk5ycvLy2a8n5+fYmJiJEkxMTE2gTutP63vfmPi4+N18+ZN662Q7jRhwgSNHTs2uzbxkVp+7HxOl4BMaFe2cE6XADx22H/lHq2X/CenS0AmPe5HifIS9mG5R+ucLgBPnBw/0l22bFlFRUVpx44deuONN9StWzcdPnw4R2saOXKkrly5Yn388ccfOVoPAAAAACB3yvEj3U5OTipVqpQkqXr16tq1a5emTZumjh07KjExUXFxcTZHu2NjY+Xv7y9J8vf3186dO22Wl3Z18zvH3H3F89jYWHl4eGR4lFuSnJ2d5ezsnC3bB2SEc4lyD44SAQAA4J/I8SPdd0tNTVVCQoKqV68uR0dHRUREWPuOHTumM2fOKDg4WJIUHBysAwcO6MKFC9Yx4eHh8vDwUIUKFaxj7lxG2pi0ZQAAAAAAYJYcPdI9cuRINW/eXEWLFtXVq1e1aNEibdq0SevXr5enp6d69eqlIUOGyNvbWx4eHurfv7+Cg4NVu3ZtSVLTpk1VoUIF/etf/9LEiRMVExOjd999V6GhodYj1X379tVnn32mYcOGqWfPntq4caOWLl2qtWvX5uSmAwAAAACeADkaui9cuKCuXbvq/Pnz8vT0VOXKlbV+/Xq98MILkqQpU6bIzs5O7du3V0JCgkJCQjRz5kzr6+3t7bVmzRq98cYbCg4OVv78+dWtWzeNGzfOOqZ48eJau3atBg8erGnTpqlIkSL68ssvFRIS8si3FwAAAADwZMnR0D1nzpz79ru4uGjGjBmaMWPGPccEBQXp+++/v+9yGjRooL179z5UjQAAAAAAPKzH7pxuAAAAAADyCkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgkhwN3RMmTNCzzz4rd3d3+fr6qm3btjp27JjNmAYNGshisdg8+vbtazPmzJkzatmypfLlyydfX18NHTpUycnJNmM2bdqkatWqydnZWaVKldL8+fPN3jwAAAAAwBMuR0P35s2bFRoaqu3btys8PFxJSUlq2rSprl+/bjPu9ddf1/nz562PiRMnWvtSUlLUsmVLJSYmatu2bVqwYIHmz5+vUaNGWcdER0erZcuWatiwoaKiojRo0CD17t1b69evf2TbCgAAAAB48jjk5MrXrVtn83z+/Pny9fXVnj17VK9ePWt7vnz55O/vn+EyfvzxRx0+fFgbNmyQn5+fqlatqvfff1/Dhw/XmDFj5OTkpNmzZ6t48eKaPHmyJKl8+fL6+eefNWXKFIWEhJi3gQAAAACAJ9pjdU73lStXJEne3t427WFhYSpUqJCefvppjRw5Ujdu3LD2RUZGqlKlSvLz87O2hYSEKD4+XocOHbKOadKkic0yQ0JCFBkZmWEdCQkJio+Pt3kAAAAAAJBVOXqk+06pqakaNGiQ6tSpo6efftra3rlzZwUFBSkgIED79+/X8OHDdezYMS1fvlySFBMTYxO4JVmfx8TE3HdMfHy8bt68KVdXV5u+CRMmaOzYsdm+jQAAAACAJ8tjE7pDQ0N18OBB/fzzzzbtffr0sf53pUqVVLhwYTVu3FgnT55UyZIlTall5MiRGjJkiPV5fHy8AgMDTVkXAAAAACDveiyml/fr109r1qzRTz/9pCJFitx3bK1atSRJJ06ckCT5+/srNjbWZkza87TzwO81xsPDI91RbklydnaWh4eHzQMAAAAAgKzK0dBtGIb69eunFStWaOPGjSpevPgDXxMVFSVJKly4sCQpODhYBw4c0IULF6xjwsPD5eHhoQoVKljHRERE2CwnPDxcwcHB2bQlAAAAAACkl6OhOzQ0VF999ZUWLVokd3d3xcTEKCYmRjdv3pQknTx5Uu+//7727Nmj06dPa9WqVeratavq1aunypUrS5KaNm2qChUq6F//+pf27dun9evX691331VoaKicnZ0lSX379tWpU6c0bNgwHT16VDNnztTSpUs1ePDgHNt2AAAAAEDel6Ohe9asWbpy5YoaNGigwoULWx9ff/21JMnJyUkbNmxQ06ZNVa5cOb311ltq3769Vq9ebV2Gvb291qxZI3t7ewUHB+u1115T165dNW7cOOuY4sWLa+3atQoPD1eVKlU0efJkffnll9wuDAAAAABgqhy9kJphGPftDwwM1ObNmx+4nKCgIH3//ff3HdOgQQPt3bs3S/UBAAAAAPBPPBYXUgMAAAAAIC8idAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGCSHA3dEyZM0LPPPit3d3f5+vqqbdu2OnbsmM2YW7duKTQ0VAULFpSbm5vat2+v2NhYmzFnzpxRy5YtlS9fPvn6+mro0KFKTk62GbNp0yZVq1ZNzs7OKlWqlObPn2/25gEAAAAAnnA5Gro3b96s0NBQbd++XeHh4UpKSlLTpk11/fp165jBgwdr9erVWrZsmTZv3qxz586pXbt21v6UlBS1bNlSiYmJ2rZtmxYsWKD58+dr1KhR1jHR0dFq2bKlGjZsqKioKA0aNEi9e/fW+vXrH+n2AgAAAACeLA45ufJ169bZPJ8/f758fX21Z88e1atXT1euXNGcOXO0aNEiNWrUSJI0b948lS9fXtu3b1ft2rX1448/6vDhw9qwYYP8/PxUtWpVvf/++xo+fLjGjBkjJycnzZ49W8WLF9fkyZMlSeXLl9fPP/+sKVOmKCQk5JFvNwAAAADgyfBYndN95coVSZK3t7ckac+ePUpKSlKTJk2sY8qVK6eiRYsqMjJSkhQZGalKlSrJz8/POiYkJETx8fE6dOiQdcydy0gbk7aMuyUkJCg+Pt7mAQAAAABAVj02oTs1NVWDBg1SnTp19PTTT0uSYmJi5OTkJC8vL5uxfn5+iomJsY65M3Cn9af13W9MfHy8bt68ma6WCRMmyNPT0/oIDAzMlm0EAAAAADxZHpvQHRoaqoMHD2rJkiU5XYpGjhypK1euWB9//PFHTpcEAAAAAMiFcvSc7jT9+vXTmjVrtGXLFhUpUsTa7u/vr8TERMXFxdkc7Y6NjZW/v791zM6dO22Wl3Z18zvH3H3F89jYWHl4eMjV1TVdPc7OznJ2ds6WbQMAAAAAPLly9Ei3YRjq16+fVqxYoY0bN6p48eI2/dWrV5ejo6MiIiKsbceOHdOZM2cUHBwsSQoODtaBAwd04cIF65jw8HB5eHioQoUK1jF3LiNtTNoyAAAAAAAwQ44e6Q4NDdWiRYv03Xffyd3d3XoOtqenp1xdXeXp6alevXppyJAh8vb2loeHh/r376/g4GDVrl1bktS0aVNVqFBB//rXvzRx4kTFxMTo3XffVWhoqPVodd++ffXZZ59p2LBh6tmzpzZu3KilS5dq7dq1ObbtAAAAAIC8L0ePdM+aNUtXrlxRgwYNVLhwYevj66+/to6ZMmWKWrVqpfbt26tevXry9/fX8uXLrf329vZas2aN7O3tFRwcrNdee01du3bVuHHjrGOKFy+utWvXKjw8XFWqVNHkyZP15ZdfcrswAAAAAICpcvRIt2EYDxzj4uKiGTNmaMaMGfccExQUpO+///6+y2nQoIH27t2b5RoBAAAAAHhYj83VywEAAAAAyGsI3QAAAAAAmCTLofuPP/7Qn3/+aX2+c+dODRo0SF988UW2FgYAAAAAQG6X5dDduXNn/fTTT5KkmJgYvfDCC9q5c6feeecdm4uXAQAAAADwpMty6D548KBq1qwpSVq6dKmefvppbdu2TWFhYZo/f3521wcAAAAAQK6V5dCdlJRkvf/1hg0b9OKLL0qSypUrp/Pnz2dvdQAAAAAA5GJZDt0VK1bU7NmztXXrVoWHh6tZs2aSpHPnzqlgwYLZXiAAAAAAALlVlkP3xx9/rM8//1wNGjTQq6++qipVqkiSVq1aZZ12DgAAAAAAJIesvqBBgwa6ePGi4uPjVaBAAWt7nz59lC9fvmwtDgAAAACA3Oyh7tNtGIb27Nmjzz//XFevXpUkOTk5EboBAAAAALhDlo90//7772rWrJnOnDmjhIQEvfDCC3J3d9fHH3+shIQEzZ4924w6AQAAAADIdbJ8pHvgwIGqUaOGLl++LFdXV2v7Sy+9pIiIiGwtDgAAAACA3CzLR7q3bt2qbdu2ycnJyaa9WLFiOnv2bLYVBgAAAABAbpflI92pqalKSUlJ1/7nn3/K3d09W4oCAAAAACAvyHLobtq0qaZOnWp9brFYdO3aNY0ePVotWrTIztoAAAAAAMjVsjy9fPLkyQoJCVGFChV069Ytde7cWcePH1ehQoW0ePFiM2oEAAAAACBXynLoLlKkiPbt26clS5Zo//79unbtmnr16qUuXbrYXFgNAAAAAIAnXZZDtyQ5ODjotddey+5aAAAAAADIUzIVuletWpXpBb744osPXQwAAAAAAHlJpkJ327ZtM7Uwi8WS4ZXNAQAAAAB4EmUqdKempppdBwAAAAAAeU6WbxkGAAAAAAAy56FCd0REhFq1aqWSJUuqZMmSatWqlTZs2JDdtQEAAAAAkKtlOXTPnDlTzZo1k7u7uwYOHKiBAwfKw8NDLVq00IwZM8yoEQAAAACAXCnLtwwbP368pkyZon79+lnbBgwYoDp16mj8+PEKDQ3N1gIBAAAAAMitsnykOy4uTs2aNUvX3rRpU125ciVbigIAAAAAIC/Icuh+8cUXtWLFinTt3333nVq1apUtRQEAAAAAkBdkeXp5hQoV9OGHH2rTpk0KDg6WJG3fvl2//PKL3nrrLU2fPt06dsCAAdlXKQAAAAAAuUyWQ/ecOXNUoEABHT58WIcPH7a2e3l5ac6cOdbnFouF0A0AAAAAeKJlOXRHR0ebUQcAAAAAAHnOQ92nGwAAAAAAPFiWj3QbhqFvvvlGP/30ky5cuKDU1FSb/uXLl2dbcQAAAAAA5GZZDt2DBg3S559/roYNG8rPz08Wi8WMugAAAAAAyPWyHLr/+9//avny5WrRooUZ9QAAAAAAkGdk+ZxuT09PlShRwoxaAAAAAADIU7IcuseMGaOxY8fq5s2bZtQDAAAAAECekeXp5R06dNDixYvl6+urYsWKydHR0ab/119/zbbiAAAAAADIzbIcurt166Y9e/botdde40JqAAAAAADcR5ZD99q1a7V+/Xo9//zzZtQDAAAAAECekeVzugMDA+Xh4WFGLQAAAAAA5ClZDt2TJ0/WsGHDdPr0aRPKAQAAAAAg78jy9PLXXntNN27cUMmSJZUvX750F1K7dOlSthUHAAAAAEBuluXQPXXqVBPKAAAAAAAg73moq5cDAAAAAIAHy3LovtOtW7eUmJho08ZF1gAAAAAAuC3LF1K7fv26+vXrJ19fX+XPn18FChSweQAAAAAAgNuyHLqHDRumjRs3atasWXJ2dtaXX36psWPHKiAgQAsXLjSjRgAAAAAAcqUsTy9fvXq1Fi5cqAYNGqhHjx6qW7euSpUqpaCgIIWFhalLly5m1AkAAAAAQK6T5SPdly5dUokSJSTdPn877RZhzz//vLZs2ZK91QEAAAAAkItlOXSXKFFC0dHRkqRy5cpp6dKlkm4fAffy8srW4gAAAAAAyM2yHLp79Oihffv2SZJGjBihGTNmyMXFRYMHD9bQoUOzvUAAAAAAAHKrLJ/TPXjwYOt/N2nSREeOHNGvv/6qUqVKqXLlytlaHAAAAAAAudk/uk+3JBUrVkzFihXLhlIAAAAAAMhbMj29PDIyUmvWrLFpW7hwoYoXLy5fX1/16dNHCQkJ2V4gAAAAAAC5VaZD97hx43To0CHr8wMHDqhXr15q0qSJRowYodWrV2vChAmmFAkAAAAAQG6U6dAdFRWlxo0bW58vWbJEtWrV0v/+7/9qyJAhmj59uvVK5gAAAAAAIAuh+/Lly/Lz87M+37x5s5o3b259/uyzz+qPP/7I3uoAAAAAAMjFMh26/fz8rPfnTkxM1K+//qratWtb+69evSpHR8fsrxAAAAAAgFwq06G7RYsWGjFihLZu3aqRI0cqX758qlu3rrV///79KlmypClFAgAAAACQG2X6lmHvv/++2rVrp/r168vNzU0LFiyQk5OTtX/u3Llq2rSpKUUCAAAAAJAbZTp0FypUSFu2bNGVK1fk5uYme3t7m/5ly5bJzc0t2wsEAAAAACC3ynToTuPp6Zlhu7e39z8uBgAAAACAvCTT53QDAAAAAICsIXQDAAAAAGASQjcAAAAAACbJVOiuVq2aLl++LEkaN26cbty4YWpRAAAAAADkBZkK3UeOHNH169clSWPHjtW1a9dMLQoAAAAAgLwgU1cvr1q1qnr06KHnn39ehmHoP//5zz1vDzZq1KhsLRAAAAAAgNwqU6F7/vz5Gj16tNasWSOLxaIffvhBDg7pX2qxWAjdAAAAAAD8f5kK3WXLltWSJUskSXZ2doqIiJCvr6+phQEAAAAAkNtlKnTfKTU11Yw6AAAAAADIc7IcuiXp5MmTmjp1qo4cOSJJqlChggYOHKiSJUtma3EAAAAAAORmWb5P9/r161WhQgXt3LlTlStXVuXKlbVjxw5VrFhR4eHhZtQIAAAAAECulOUj3SNGjNDgwYP10UcfpWsfPny4XnjhhWwrDgAAAACA3CzLR7qPHDmiXr16pWvv2bOnDh8+nC1FAQAAAACQF2Q5dPv4+CgqKipde1RUFFc0BwAAAADgDlmeXv7666+rT58+OnXqlJ577jlJ0i+//KKPP/5YQ4YMyfYCAQAAAADIrbIcut977z25u7tr8uTJGjlypCQpICBAY8aM0YABA7K9QAAAAAAAcqssh26LxaLBgwdr8ODBunr1qiTJ3d092wsDAAAAACC3y/I53Xdyd3f/R4F7y5Ytat26tQICAmSxWLRy5Uqb/u7du8tisdg8mjVrZjPm0qVL6tKlizw8POTl5aVevXrp2rVrNmP279+vunXrysXFRYGBgZo4ceJD1wwAAAAAQGb9o9D9T12/fl1VqlTRjBkz7jmmWbNmOn/+vPWxePFim/4uXbro0KFDCg8P15o1a7Rlyxb16dPH2h8fH6+mTZsqKChIe/bs0aRJkzRmzBh98cUXpm0XAAAAAADSQ0wvz07NmzdX8+bN7zvG2dlZ/v7+GfYdOXJE69at065du1SjRg1J0qeffqoWLVroP//5jwICAhQWFqbExETNnTtXTk5OqlixoqKiovTJJ5/YhHMAAAAAALJbjh7pzoxNmzbJ19dXZcuW1RtvvKG///7b2hcZGSkvLy9r4JakJk2ayM7OTjt27LCOqVevnpycnKxjQkJCdOzYMV2+fDnDdSYkJCg+Pt7mAQAAAABAVmUpdCclJalx48Y6fvy4WfXYaNasmRYuXKiIiAh9/PHH2rx5s5o3b66UlBRJUkxMTLp7gzs4OMjb21sxMTHWMX5+fjZj0p6njbnbhAkT5OnpaX0EBgZm96YBAAAAAJ4AWZpe7ujoqP3795tVSzqdOnWy/nelSpVUuXJllSxZUps2bVLjxo1NW+/IkSNt7jkeHx9P8AYAAAAAZFmWp5e/9tprmjNnjhm1PFCJEiVUqFAhnThxQpLk7++vCxcu2IxJTk7WpUuXrOeB+/v7KzY21mZM2vN7nSvu7OwsDw8PmwcAAAAAAFmV5QupJScna+7cudqwYYOqV6+u/Pnz2/R/8skn2Vbc3f7880/9/fffKly4sCQpODhYcXFx2rNnj6pXry5J2rhxo1JTU1WrVi3rmHfeeUdJSUlydHSUJIWHh6ts2bIqUKCAabUCAAAAAJDl0H3w4EFVq1ZNkvTbb7/Z9Fksliwt69q1a9aj1pIUHR2tqKgoeXt7y9vbW2PHjlX79u3l7++vkydPatiwYSpVqpRCQkIkSeXLl1ezZs30+uuva/bs2UpKSlK/fv3UqVMnBQQESJI6d+6ssWPHqlevXho+fLgOHjyoadOmacqUKVnddAAAAAAAsiTLofunn37KtpXv3r1bDRs2tD5PO4+6W7dumjVrlvbv368FCxYoLi5OAQEBatq0qd5//305OztbXxMWFqZ+/fqpcePGsrOzU/v27TV9+nRrv6enp3788UeFhoaqevXqKlSokEaNGsXtwgAAAAAApnvo+3SfOHFCJ0+eVL169eTq6irDMLJ8pLtBgwYyDOOe/evXr3/gMry9vbVo0aL7jqlcubK2bt2apdoAAAAAAPinsnwhtb///luNGzdWmTJl1KJFC50/f16S1KtXL7311lvZXiAAAAAAALlVlkP34MGD5ejoqDNnzihfvnzW9o4dO2rdunXZWhwAAAAAALlZlqeX//jjj1q/fr2KFCli0166dGn9/vvv2VYYAAAAAAC5XZaPdF+/ft3mCHeaS5cu2VzgDAAAAACAJ12WQ3fdunW1cOFC63OLxaLU1FRNnDjR5krkAAAAAAA86bI8vXzixIlq3Lixdu/ercTERA0bNkyHDh3SpUuX9Msvv5hRIwAAAAAAuVKWj3Q//fTT+u233/T888+rTZs2un79utq1a6e9e/eqZMmSZtQIAAAAAECu9FD36fb09NQ777yT3bUAAAAAAJCnPFTovnz5subMmaMjR45IkipUqKAePXrI29s7W4sDAAAAACA3y/L08i1btqhYsWKaPn26Ll++rMuXL2v69OkqXry4tmzZYkaNAAAAAADkSlk+0h0aGqqOHTtq1qxZsre3lySlpKTozTffVGhoqA4cOJDtRQIAAAAAkBtl+Uj3iRMn9NZbb1kDtyTZ29tryJAhOnHiRLYWBwAAAABAbpbl0F2tWjXrudx3OnLkiKpUqZItRQEAAAAAkBdkanr5/v37rf89YMAADRw4UCdOnFDt2rUlSdu3b9eMGTP00UcfmVMlAAAAAAC5UKZCd9WqVWWxWGQYhrVt2LBh6cZ17txZHTt2zL7qAAAAAADIxTIVuqOjo82uAwAAAACAPCdToTsoKMjsOgAAAAAAyHOyfMswSTp37px+/vlnXbhwQampqTZ9AwYMyJbCAAAAAADI7bIcuufPn69///vfcnJyUsGCBWWxWKx9FouF0A0AAAAAwP+X5dD93nvvadSoURo5cqTs7LJ8xzEAAAAAAJ4YWU7NN27cUKdOnQjcAAAAAAA8QJaTc69evbRs2TIzagEAAAAAIE/J8vTyCRMmqFWrVlq3bp0qVaokR0dHm/5PPvkk24oDAAAAACA3e6jQvX79epUtW1aS0l1IDQAAAAAA3Jbl0D158mTNnTtX3bt3N6EcAAAAAADyjiyf0+3s7Kw6deqYUQsAAAAAAHlKlkP3wIED9emnn5pRCwAAAAAAeUqWp5fv3LlTGzdu1Jo1a1SxYsV0F1Jbvnx5thUHAAAAAEBuluXQ7eXlpXbt2plRCwAAAAAAeUqWQ/e8efPMqAMAAAAAgDwny+d0AwAAAACAzMnyke7ixYvf937cp06d+kcFAQAAAACQV2Q5dA8aNMjmeVJSkvbu3at169Zp6NCh2VUXAAAAAAC5XpZD98CBAzNsnzFjhnbv3v2PCwIAAAAAIK/ItnO6mzdvrm+//Ta7FgcAAAAAQK6XbaH7m2++kbe3d3YtDgAAAACAXC/L08ufeeYZmwupGYahmJgY/fXXX5o5c2a2FgcAAAAAQG6W5dDdtm1bm+d2dnby8fFRgwYNVK5cueyqCwAAAACAXC/LoXv06NFm1AEAAAAAQJ6Tbed0AwAAAAAAW5k+0m1nZ2dzLndGLBaLkpOT/3FRAAAAAADkBZkO3StWrLhnX2RkpKZPn67U1NRsKQoAAAAAgLwg06G7TZs26dqOHTumESNGaPXq1erSpYvGjRuXrcUBAAAAAJCbPdQ53efOndPrr7+uSpUqKTk5WVFRUVqwYIGCgoKyuz4AAAAAAHKtLIXuK1euaPjw4SpVqpQOHTqkiIgIrV69Wk8//bRZ9QEAAAAAkGtlenr5xIkT9fHHH8vf31+LFy/OcLo5AAAAAAD4P5kO3SNGjJCrq6tKlSqlBQsWaMGCBRmOW758ebYVBwAAAABAbpbp0N21a9cH3jIMAAAAAAD8n0yH7vnz55tYBgAAAAAAec9DXb0cAAAAAAA8GKEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk+Ro6N6yZYtat26tgIAAWSwWrVy50qbfMAyNGjVKhQsXlqurq5o0aaLjx4/bjLl06ZK6dOkiDw8PeXl5qVevXrp27ZrNmP3796tu3bpycXFRYGCgJk6caPamAQAAAACQs6H7+vXrqlKlimbMmJFh/8SJEzV9+nTNnj1bO3bsUP78+RUSEqJbt25Zx3Tp0kWHDh1SeHi41qxZoy1btqhPnz7W/vj4eDVt2lRBQUHas2ePJk2apDFjxuiLL74wffsAAAAAAE82h5xcefPmzdW8efMM+wzD0NSpU/Xuu++qTZs2kqSFCxfKz89PK1euVKdOnXTkyBGtW7dOu3btUo0aNSRJn376qVq0aKH//Oc/CggIUFhYmBITEzV37lw5OTmpYsWKioqK0ieffGITzgEAAAAAyG6P7Tnd0dHRiomJUZMmTaxtnp6eqlWrliIjIyVJkZGR8vLysgZuSWrSpIns7Oy0Y8cO65h69erJycnJOiYkJETHjh3T5cuXM1x3QkKC4uPjbR4AAAAAAGTVYxu6Y2JiJEl+fn427X5+fta+mJgY+fr62vQ7ODjI29vbZkxGy7hzHXebMGGCPD09rY/AwMB/vkEAAAAAgCfOYxu6c9LIkSN15coV6+OPP/7I6ZIAAAAAALnQYxu6/f39JUmxsbE27bGxsdY+f39/XbhwwaY/OTlZly5dshmT0TLuXMfdnJ2d5eHhYfMAAAAAACCrHtvQXbx4cfn7+ysiIsLaFh8frx07dig4OFiSFBwcrLi4OO3Zs8c6ZuPGjUpNTVWtWrWsY7Zs2aKkpCTrmPDwcJUtW1YFChR4RFsDAAAAAHgS5WjovnbtmqKiohQVFSXp9sXToqKidObMGVksFg0aNEgffPCBVq1apQMHDqhr164KCAhQ27ZtJUnly5dXs2bN9Prrr2vnzp365Zdf1K9fP3Xq1EkBAQGSpM6dO8vJyUm9evXSoUOH9PXXX2vatGkaMmRIDm01AAAAAOBJkaO3DNu9e7caNmxofZ4WhLt166b58+dr2LBhun79uvr06aO4uDg9//zzWrdunVxcXKyvCQsLU79+/dS4cWPZ2dmpffv2mj59urXf09NTP/74o0JDQ1W9enUVKlRIo0aN4nZhAAAAAADT5WjobtCggQzDuGe/xWLRuHHjNG7cuHuO8fb21qJFi+67nsqVK2vr1q0PXScAAAAAAA/jsT2nGwAAAACA3I7QDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmOSxDt1jxoyRxWKxeZQrV87af+vWLYWGhqpgwYJyc3NT+/btFRsba7OMM2fOqGXLlsqXL598fX01dOhQJScnP+pNAQAAAAA8gRxyuoAHqVixojZs2GB97uDwfyUPHjxYa9eu1bJly+Tp6al+/fqpXbt2+uWXXyRJKSkpatmypfz9/bVt2zadP39eXbt2laOjo8aPH//ItwUAAAAA8GR57EO3g4OD/P3907VfuXJFc+bM0aJFi9SoUSNJ0rx581S+fHlt375dtWvX1o8//qjDhw9rw4YN8vPzU9WqVfX+++9r+PDhGjNmjJycnB715gAAAAAAniCP9fRySTp+/LgCAgJUokQJdenSRWfOnJEk7dmzR0lJSWrSpIl1bLly5VS0aFFFRkZKkiIjI1WpUiX5+flZx4SEhCg+Pl6HDh265zoTEhIUHx9v8wAAAAAAIKse69Bdq1YtzZ8/X+vWrdOsWbMUHR2tunXr6urVq4qJiZGTk5O8vLxsXuPn56eYmBhJUkxMjE3gTutP67uXCRMmyNPT0/oIDAzM3g0DAAAAADwRHuvp5c2bN7f+d+XKlVWrVi0FBQVp6dKlcnV1NW29I0eO1JAhQ6zP4+PjCd4AAAAAgCx7rI90383Ly0tlypTRiRMn5O/vr8TERMXFxdmMiY2NtZ4D7u/vn+5q5mnPMzpPPI2zs7M8PDxsHgAAAAAAZFWuCt3Xrl3TyZMnVbhwYVWvXl2Ojo6KiIiw9h87dkxnzpxRcHCwJCk4OFgHDhzQhQsXrGPCw8Pl4eGhChUqPPL6AQAAAABPlsd6evnbb7+t1q1bKygoSOfOndPo0aNlb2+vV199VZ6enurVq5eGDBkib29veXh4qH///goODlbt2rUlSU2bNlWFChX0r3/9SxMnTlRMTIzeffddhYaGytnZOYe3DgAAAACQ1z3WofvPP//Uq6++qr///ls+Pj56/vnntX37dvn4+EiSpkyZIjs7O7Vv314JCQkKCQnRzJkzra+3t7fXmjVr9MYbbyg4OFj58+dXt27dNG7cuJzaJAAAAADAE+SxDt1Lliy5b7+Li4tmzJihGTNm3HNMUFCQvv/+++wuDQAAAACAB8pV53QDAAAAAJCbELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTPFGhe8aMGSpWrJhcXFxUq1Yt7dy5M6dLAgAAAADkYU9M6P766681ZMgQjR49Wr/++quqVKmikJAQXbhwIadLAwAAAADkUU9M6P7kk0/0+uuvq0ePHqpQoYJmz56tfPnyae7cuTldGgAAAAAgj3LI6QIehcTERO3Zs0cjR460ttnZ2alJkyaKjIxMNz4hIUEJCQnW51euXJEkxcfHm1/sP3Tj2tWcLgGZEH8r4cGD8FhwzAV/93kF+6/cg31Y7sE+7NFhH5Z7sA/LPR73fVhaPjQM477jnojQffHiRaWkpMjPz8+m3c/PT0ePHk03fsKECRo7dmy69sDAQNNqBPCY+mhGTlcAAA+PfRiA3CyX7MOuXr0qT0/Pe/Y/EaE7q0aOHKkhQ4ZYn6empurSpUsqWLCgLBZLDlaGvCA+Pl6BgYH6448/5OHhkdPlAECWsA8DkJuxD0N2MgxDV69eVUBAwH3HPRGhu1ChQrK3t1dsbKxNe2xsrPz9/dONd3Z2lrOzs02bl5eXmSXiCeTh4cHOHkCuxT4MQG7GPgzZ5X5HuNM8ERdSc3JyUvXq1RUREWFtS01NVUREhIKDg3OwMgAAAABAXvZEHOmWpCFDhqhbt26qUaOGatasqalTp+r69evq0aNHTpcGAAAAAMijnpjQ3bFjR/31118aNWqUYmJiVLVqVa1bty7dxdUAszk7O2v06NHpTmEAgNyAfRiA3Ix9GHKCxXjQ9c0BAAAAAMBDeSLO6QYAAAAAICcQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbeMRmzJihYsWKycXFRbVq1dLOnTtzuiQAeKAtW7aodevWCggIkMVi0cqVK3O6JADItAkTJujZZ5+Vu7u7fH191bZtWx07diyny8ITgtANPEJff/21hgwZotGjR+vXX39VlSpVFBISogsXLuR0aQBwX9evX1eVKlU0Y8aMnC4FALJs8+bNCg0N1fbt2xUeHq6kpCQ1bdpU169fz+nS8ATglmHAI1SrVi09++yz+uyzzyRJqampCgwMVP/+/TVixIgcrg4AMsdisWjFihVq27ZtTpcCAA/lr7/+kq+vrzZv3qx69erldDnI4zjSDTwiiYmJ2rNnj5o0aWJts7OzU5MmTRQZGZmDlQEAADxZrly5Ikny9vbO4UrwJCB0A4/IxYsXlZKSIj8/P5t2Pz8/xcTE5FBVAAAAT5bU1FQNGjRIderU0dNPP53T5eAJ4JDTBQAAAADAoxIaGqqDBw/q559/zulS8IQgdAOPSKFChWRvb6/Y2Fib9tjYWPn7++dQVQAAAE+Ofv36ac2aNdqyZYuKFCmS0+XgCcH0cuARcXJyUvXq1RUREWFtS01NVUREhIKDg3OwMgAAgLzNMAz169dPK1as0MaNG1W8ePGcLglPEI50A4/QkCFD1K1bN9WoUUM1a9bU1KlTdf36dfXo0SOnSwOA+7p27ZpOnDhhfR4dHa2oqCh5e3uraNGiOVgZADxYaGioFi1apO+++07u7u7W6+l4enrK1dU1h6tDXsctw4BH7LPPPtOkSZMUExOjqlWravr06apVq1ZOlwUA97Vp0yY1bNgwXXu3bt00f/78R18QAGSBxWLJsH3evHnq3r37oy0GTxxCNwAAAAAAJuGcbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAgl7FYLFq5cmVOl/FQxowZo6pVq/6jZZw+fVoWi0VRUVHZUhMAAGYidAMA8BiJiYlR//79VaJECTk7OyswMFCtW7dWRERETpcmSWrQoIEGDRqU02UAAJBrOOR0AQAA4LbTp0+rTp068vLy0qRJk1SpUiUlJSVp/fr1Cg0N1dGjR3O6RAAAkEUc6QYA4DHx5ptvymKxaOfOnWrfvr3KlCmjihUrasiQIdq+ffs9Xzd8+HCVKVNG+fLlU4kSJfTee+8pKSnJ2r9v3z41bNhQ7u7u8vDwUPXq1bV7925J0u+//67WrVurQIECyp8/vypWrKjvv//+obfhQbWk+fzzzxUYGKh8+fKpQ4cOunLlik3/l19+qfLly8vFxUXlypXTzJkz77nOy5cvq0uXLvLx8ZGrq6tKly6tefPmPfQ2AACQnTjSDQDAY+DSpUtat26dPvzwQ+XPnz9dv5eX1z1f6+7urvnz5ysgIEAHDhzQ66+/Lnd3dw0bNkyS1KVLFz3zzDOaNWuW7O3tFRUVJUdHR0lSaGioEhMTtWXLFuXPn1+HDx+Wm5vbQ2/Hg2qRpBMnTmjp0qVavXq14uPj1atXL7355psKCwuTJIWFhWnUqFH67LPP9Mwzz2jv3r16/fXXlT9/fnXr1i3dOt977z0dPnxYP/zwgwoVKqQTJ07o5s2bD70NAABkJ0I3AACPgRMnTsgwDJUrVy7Lr3333Xet/12sWDG9/fbbWrJkiTXonjlzRkOHDrUuu3Tp0tbxZ86cUfv27VWpUiVJUokSJf7JZjywFkm6deuWFi5cqKeeekr6f+3dTUiUXRiH8cuC6IMUIsmCiinHqEgIp6CiVVLqRMRMtYly4QRJMTiai7APLVqVFIlIuSzENrWxjUHtKihM6IsWSg5iRJQRRkxM2aoB0azXtwkX1w+exTzPOXPue/ln5pwHaGlpIRwO09zcTEFBAadPn6a5uZlIJAJAIBDgxYsXXLlyZcLQnUwmWb9+PaFQKLOuJEnThaFbkqRpYHR0dMpzb9y4weXLl+nr62NkZIR0Ok1ubm7meW1tLbFYjGvXrlFaWsrevXtZuXIlAPF4nOrqarq7uyktLSUajVJcXJy1WgCWLVuWCdwAmzZt4vv377x69Yr58+fT19dHVVUVhw4dyoxJp9Pk5eVNuGZ1dTXRaJSenh62b9/O7t272bx585R7kCTpb3JPtyRJ00AwGCQnJ+c/H5b24MED9u/fT0VFBV1dXTx58oSGhga+fv2aGdPY2Mjz588Jh8PcvXuXNWvWcOvWLQBisRj9/f0cOHCAp0+fEgqFaGlpmVIPf1LL74yMjADQ3t5Ob29v5nr27Nkv97WXl5czMDBAIpFgaGiIbdu2cezYsSn1IEnS32boliRpGliwYAE7duygtbWVz58/j3v+8ePHCefdv3+f5cuX09DQQCgUIhgMMjAwMG5cUVERiUSC7u5uIpHImIPGli5dyuHDh7l58yZ1dXW0t7dPqYc/rSWZTDI0NJT5/PDhQ2bMmMGqVatYtGgRS5Ysob+/n8LCwjFXIBD45dr5+flUVlZy/fp1Ll26xNWrV6fUgyRJf5t/L5ckaZpobW1ly5YtbNy4kTNnzlBcXEw6nebOnTu0tbXx8uXLcXOCwSDJZJLOzk42bNjA7du3M79iA3z58oX6+nr27NlDIBBgcHCQR48eEY1GAaipqaG8vJyioiKGh4e5d+8eq1evnrTOd+/e0dvbO+be4sWLf1vLT7Nnz6ayspILFy7w6dMn4vE4+/bto6CgAICmpibi8Th5eXmUlZWRSqV4/Pgxw8PD1NbWjvu+U6dOUVJSwtq1a0mlUnR1df22B0mS/hVDtyRJ08SKFSvo6enh3Llz1NXV8ebNG/Lz8ykpKaGtrW3CObt27SKRSHD06FFSqRThcJiTJ0/S2NgIwMyZM3n//j0HDx7k7du3LFy4kEgkQlNTEwDfvn3jyJEjDA4OkpubS1lZGRcvXpy0zo6ODjo6OsbcO3v2LCdOnJi0lp8KCwuJRCJUVFTw4cMHdu7cOeaVYLFYjLlz53L+/Hnq6+uZN28e69ato6amZsJ6Zs2axfHjx3n9+jVz5sxh69atdHZ2TtqDJEn/Ss7o/zm5RZIkSZIk/ZJ7uiVJkiRJyhJDtyRJkiRJWWLoliRJkiQpSwzdkiRJkiRliaFbkiRJkqQsMXRLkiRJkpQlhm5JkiRJkrLE0C1JkiRJUpYYuiVJkiRJyhJDtyRJkiRJWWLoliRJkiQpSwzdkiRJkiRlyQ9mgy8e0wtDegAAAABJRU5ErkJggg==\n"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\ndef plot_precision_recall_f1(model, x_test, y_test):\n    # Predict\n    y_pred_probs = model.predict(x_test, batch_size=64, verbose=1)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true = np.argmax(y_test, axis=1)\n\n    # Confirm correct number of samples\n    print(f\"Number of test samples: {len(y_true)}\")\n    print(f\"Number of predictions: {len(y_pred)}\")\n\n    if len(y_true) != len(y_pred):\n        print(\"Mismatch between test samples and predictions!\")\n        return\n\n    # Classes\n    classes = np.unique(y_true)\n    print(f\"Classes found in test set: {classes}\")\n\n    # Calculate metrics per class\n    precision = precision_score(y_true, y_pred, labels=classes, average=None)\n    recall = recall_score(y_true, y_pred, labels=classes, average=None)\n    f1 = f1_score(y_true, y_pred, labels=classes, average=None)\n\n    # Print\n    print(\"\\nPer-Class Precision, Recall, F1-Score:\")\n    for idx, cls in enumerate(classes):\n        print(f\"Class {cls} -> Precision: {precision[idx]:.4f}, Recall: {recall[idx]:.4f}, F1-Score: {f1[idx]:.4f}\")\n\n    # Plot\n    x = np.arange(len(classes))\n    width = 0.25  # bar width\n\n    fig, ax = plt.subplots(figsize=(12, 7))\n    rects1 = ax.bar(x - width, precision, width, label='Precision', color='skyblue')\n    rects2 = ax.bar(x, recall, width, label='Recall', color='lightgreen')\n    rects3 = ax.bar(x + width, f1, width, label='F1-Score', color='salmon')\n\n    ax.set_xlabel('Class Labels')\n    ax.set_ylabel('Score')\n    ax.set_title('Precision, Recall, F1-Score per Class')\n    ax.set_xticks(x)\n    ax.set_xticklabels(classes)\n    ax.set_ylim(0, 1.05)\n    ax.legend(loc='lower center', bbox_to_anchor=(0.5, 1.05),\n              ncol=3, fancybox=True, shadow=True)\n\n    # Annotate bar heights\n    def autolabel(rects):\n        for rect in rects:\n            height = rect.get_height()\n            ax.annotate(f'{height:.2f}',\n                        xy=(rect.get_x() + rect.get_width() / 2, height),\n                        xytext=(0, 3),\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom')\n\n    autolabel(rects1)\n    autolabel(rects2)\n    autolabel(rects3)\n\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\nplot_precision_recall_f1(model, x_test_lstm, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:19:47.920313Z","iopub.execute_input":"2025-04-28T12:19:47.920610Z","iopub.status.idle":"2025-04-28T12:19:53.598566Z","shell.execute_reply.started":"2025-04-28T12:19:47.920583Z","shell.execute_reply":"2025-04-28T12:19:53.597477Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step\nNumber of test samples: 9000\nNumber of predictions: 9000\nClasses found in test set: [0 1 2]\n\nPer-Class Precision, Recall, F1-Score:\nClass 0 -> Precision: 0.9987, Recall: 0.9950, F1-Score: 0.9968\nClass 1 -> Precision: 0.9987, Recall: 0.9990, F1-Score: 0.9988\nClass 2 -> Precision: 0.9963, Recall: 0.9997, F1-Score: 0.9980\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x700 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":20}]}