{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":271117,"sourceType":"datasetVersion","datasetId":113673}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyts","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:00:01.330885Z","iopub.execute_input":"2025-04-28T13:00:01.331148Z","iopub.status.idle":"2025-04-28T13:00:08.259712Z","shell.execute_reply.started":"2025-04-28T13:00:01.331103Z","shell.execute_reply":"2025-04-28T13:00:08.258554Z"}},"outputs":[{"name":"stdout","text":"Collecting pyts\n  Downloading pyts-0.13.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.26.4)\nRequirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.15.2)\nRequirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.4.2)\nRequirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.11/dist-packages (from pyts) (0.60.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.55.2->pyts) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.4->pyts) (2.4.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pyts) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.4->pyts) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.4->pyts) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pyts) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.4->pyts) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.4->pyts) (2024.2.0)\nDownloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyts\nSuccessfully installed pyts-0.13.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom pyts.image import GramianAngularField\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\ndef root_directory():\n    \"\"\"Returns the root directory of the project.\"\"\"\n    return \"/kaggle/input/swell-heart-rate-variability-hrv/hrv dataset\"\n\ndef data_directory():\n    \"\"\"Returns the data directory path.\"\"\"\n    return os.path.join(root_directory(), \"data\") \ndef load_train_set():\n    \"\"\"Loads training dataset as a Pandas DataFrame.\"\"\"\n    train_file = os.path.join(data_directory(), \"final\", \"train.csv\")\n    return pd.read_csv(train_file)\n\ndef load_test_set():\n    \"\"\"Loads test dataset as a Pandas DataFrame.\"\"\"\n    test_file = os.path.join(data_directory(), \"final\", \"test.csv\")\n    return pd.read_csv(test_file)\n\ntrain = load_train_set()\ntest = load_test_set()\n\ntarget = \"condition\"\n\nhrv_features = [col for col in train.columns if col != target]\n\nlabel_map = {\"no stress\": 0, \"interruption\": 1, \"time pressure\": 2}\ntrain[target] = train[target].map(label_map)\ntest[target] = test[target].map(label_map)\n\n\ndef sample_data(df, label_col, n_samples):\n    \"\"\"Safely sample n_samples per class without errors.\"\"\"\n    sampled_df = []\n    for label in df[label_col].unique():\n        class_data = df[df[label_col] == label]\n        sample_size = min(n_samples, len(class_data))  \n        sampled_df.append(class_data.sample(n=sample_size, random_state=42))\n    return pd.concat(sampled_df).reset_index(drop=True)\n\ntrain_balanced = sample_data(train, target, 10000)\ntest_balanced = sample_data(test, target, 3000)  \n\nX_train = train_balanced[hrv_features]\ny_train = train_balanced[target]\n\nif \"datasetId\" in X_train.columns:\n    X_train = X_train.drop(columns=\"datasetId\")\n\nX_test = test_balanced[hrv_features]\ny_test = test_balanced[target]\n\nif \"datasetId\" in X_test.columns:\n    X_test = X_test.drop(columns=\"datasetId\")\n\nprint(f\"Train Set Shape: {X_train.shape}, Labels Shape: {y_train.shape}\")\nprint(f\"Test Set Shape: {X_test.shape}, Labels Shape: {y_test.shape}\")\n\ndisplay(X_train.head())\ndisplay(y_train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:00:54.476574Z","iopub.execute_input":"2025-04-28T13:00:54.477458Z","iopub.status.idle":"2025-04-28T13:00:58.898499Z","shell.execute_reply.started":"2025-04-28T13:00:54.477425Z","shell.execute_reply":"2025-04-28T13:00:58.897695Z"}},"outputs":[{"name":"stdout","text":"Train Set Shape: (30000, 34), Labels Shape: (30000,)\nTest Set Shape: (9000, 34), Labels Shape: (9000,)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      MEAN_RR   MEDIAN_RR        SDRR      RMSSD       SDSD  SDRR_RMSSD  \\\n0  896.720876  880.459590  106.101117  13.924951  13.924949    7.619497   \n1  903.325242  905.495460   72.285411  12.387407  12.386563    5.835395   \n2  934.870026  916.307545  128.556268  16.728592  16.728579    7.684823   \n3  726.048217  726.396200   58.167902   9.760850   9.760850    5.959307   \n4  903.212333  918.237180  108.998652  16.905228  16.905228    6.447630   \n\n          HR      pNN25     pNN50        SD1  ...     LF_PCT      LF_NU  \\\n0  67.818401   7.733333  0.466667   9.849712  ...  28.035932  98.809256   \n1  66.855229   4.466667  0.133333   8.761546  ...  23.244445  99.726832   \n2  65.364253  13.200000  1.066667  11.832839  ...  28.280122  99.507931   \n3  83.181060   1.400000  0.000000   6.904267  ...  22.022647  93.990424   \n4  67.479959  12.400000  1.333333  11.957790  ...  23.825552  98.769012   \n\n          HF    HF_PCT     HF_NU           TP       LF_HF     HF_LF    sampen  \\\n0   9.922258  0.337859  1.190744  2936.803667   82.981135  0.012051  2.127076   \n1   1.783522  0.063670  0.273168  2801.178306  365.074431  0.002739  2.192351   \n2   6.164162  0.139846  0.492069  4407.828115  202.223606  0.004945  2.160318   \n3  26.015607  1.408088  6.009576  1847.584044   15.640109  0.063938  2.157452   \n4  13.625402  0.296945  1.230988  4588.526989   80.235569  0.012463  2.179244   \n\n     higuci  \n0  1.134921  \n1  1.069071  \n2  1.126186  \n3  1.152640  \n4  1.177820  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEAN_RR</th>\n      <th>MEDIAN_RR</th>\n      <th>SDRR</th>\n      <th>RMSSD</th>\n      <th>SDSD</th>\n      <th>SDRR_RMSSD</th>\n      <th>HR</th>\n      <th>pNN25</th>\n      <th>pNN50</th>\n      <th>SD1</th>\n      <th>...</th>\n      <th>LF_PCT</th>\n      <th>LF_NU</th>\n      <th>HF</th>\n      <th>HF_PCT</th>\n      <th>HF_NU</th>\n      <th>TP</th>\n      <th>LF_HF</th>\n      <th>HF_LF</th>\n      <th>sampen</th>\n      <th>higuci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>896.720876</td>\n      <td>880.459590</td>\n      <td>106.101117</td>\n      <td>13.924951</td>\n      <td>13.924949</td>\n      <td>7.619497</td>\n      <td>67.818401</td>\n      <td>7.733333</td>\n      <td>0.466667</td>\n      <td>9.849712</td>\n      <td>...</td>\n      <td>28.035932</td>\n      <td>98.809256</td>\n      <td>9.922258</td>\n      <td>0.337859</td>\n      <td>1.190744</td>\n      <td>2936.803667</td>\n      <td>82.981135</td>\n      <td>0.012051</td>\n      <td>2.127076</td>\n      <td>1.134921</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>903.325242</td>\n      <td>905.495460</td>\n      <td>72.285411</td>\n      <td>12.387407</td>\n      <td>12.386563</td>\n      <td>5.835395</td>\n      <td>66.855229</td>\n      <td>4.466667</td>\n      <td>0.133333</td>\n      <td>8.761546</td>\n      <td>...</td>\n      <td>23.244445</td>\n      <td>99.726832</td>\n      <td>1.783522</td>\n      <td>0.063670</td>\n      <td>0.273168</td>\n      <td>2801.178306</td>\n      <td>365.074431</td>\n      <td>0.002739</td>\n      <td>2.192351</td>\n      <td>1.069071</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>934.870026</td>\n      <td>916.307545</td>\n      <td>128.556268</td>\n      <td>16.728592</td>\n      <td>16.728579</td>\n      <td>7.684823</td>\n      <td>65.364253</td>\n      <td>13.200000</td>\n      <td>1.066667</td>\n      <td>11.832839</td>\n      <td>...</td>\n      <td>28.280122</td>\n      <td>99.507931</td>\n      <td>6.164162</td>\n      <td>0.139846</td>\n      <td>0.492069</td>\n      <td>4407.828115</td>\n      <td>202.223606</td>\n      <td>0.004945</td>\n      <td>2.160318</td>\n      <td>1.126186</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>726.048217</td>\n      <td>726.396200</td>\n      <td>58.167902</td>\n      <td>9.760850</td>\n      <td>9.760850</td>\n      <td>5.959307</td>\n      <td>83.181060</td>\n      <td>1.400000</td>\n      <td>0.000000</td>\n      <td>6.904267</td>\n      <td>...</td>\n      <td>22.022647</td>\n      <td>93.990424</td>\n      <td>26.015607</td>\n      <td>1.408088</td>\n      <td>6.009576</td>\n      <td>1847.584044</td>\n      <td>15.640109</td>\n      <td>0.063938</td>\n      <td>2.157452</td>\n      <td>1.152640</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>903.212333</td>\n      <td>918.237180</td>\n      <td>108.998652</td>\n      <td>16.905228</td>\n      <td>16.905228</td>\n      <td>6.447630</td>\n      <td>67.479959</td>\n      <td>12.400000</td>\n      <td>1.333333</td>\n      <td>11.957790</td>\n      <td>...</td>\n      <td>23.825552</td>\n      <td>98.769012</td>\n      <td>13.625402</td>\n      <td>0.296945</td>\n      <td>1.230988</td>\n      <td>4588.526989</td>\n      <td>80.235569</td>\n      <td>0.012463</td>\n      <td>2.179244</td>\n      <td>1.177820</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0    0\n1    0\n2    0\n3    0\n4    0\nName: condition, dtype: int64"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def quantile_normalize(df):\n    \"\"\"Applies quantile normalization to the DataFrame.\"\"\"\n    df_sorted = pd.DataFrame(np.sort(df.values, axis=0), index=df.index, columns=df.columns)\n    df_mean = df_sorted.mean(axis=1)\n    df_mean.index = np.arange(1, len(df_mean) + 1)\n    df_qn = df.rank(method=\"min\").stack().astype(int).map(df_mean).unstack()\n    return df_qn\n\n\nx_train_swell = quantile_normalize(X_train)\nx_test_swell = quantile_normalize(X_test)\n\ndisplay(x_train_swell.head())\ndisplay(x_test_swell.head())\nprint(x_train_swell.describe())\nprint(x_test_swell.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:01:04.859333Z","iopub.execute_input":"2025-04-28T13:01:04.859657Z","iopub.status.idle":"2025-04-28T13:01:05.643437Z","shell.execute_reply.started":"2025-04-28T13:01:04.859631Z","shell.execute_reply":"2025-04-28T13:01:05.642538Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"      MEAN_RR   MEDIAN_RR        SDRR       RMSSD        SDSD  SDRR_RMSSD  \\\n0  276.697101  261.548330  281.634094  201.939225  201.948873  306.099269   \n1  283.060633  290.437894  183.073989  167.021640  166.952993  215.238532   \n2  312.856441  298.311570  333.659979  277.912510  277.935225  309.649467   \n3  118.124366  124.548167  136.809099  117.415260  117.430190  221.768654   \n4  282.869530  300.263695  289.169845  283.041251  283.046942  248.500700   \n\n           HR       pNN25       pNN50         SD1  ...      LF_PCT  \\\n0  186.792253  220.098299  219.751609  201.948873  ...  209.281585   \n1  178.099179  165.854182  166.058400  166.952993  ...  175.512435   \n2  167.908511  315.431057  277.893149  277.935225  ...  211.163474   \n3  463.050505  112.676927   57.594885  117.430190  ...  165.622387   \n4  183.634928  300.234227  309.342415  283.046942  ...  179.713401   \n\n        LF_NU          HF      HF_PCT       HF_NU          TP       LF_HF  \\\n0  309.383929  166.989622  170.844721  172.502720  229.176610  309.383929   \n1  527.319177  104.591577  111.702021  111.394438  220.181001  527.319177   \n2  434.164037  141.753598  139.078646  129.723889  339.437487  434.164037   \n3  158.516499  250.212396  280.129440  339.707893  158.679659  158.516499   \n4  305.818680  184.847490  165.565337  174.383861  355.878824  305.818680   \n\n        HF_LF      sampen      higuci  \n0  172.502720  220.280335  160.774105  \n1  111.394438  390.664047   91.473882  \n2  129.723889  264.643133  147.015168  \n3  339.707893  259.802904  193.893174  \n4  174.383861  315.449174  240.393451  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEAN_RR</th>\n      <th>MEDIAN_RR</th>\n      <th>SDRR</th>\n      <th>RMSSD</th>\n      <th>SDSD</th>\n      <th>SDRR_RMSSD</th>\n      <th>HR</th>\n      <th>pNN25</th>\n      <th>pNN50</th>\n      <th>SD1</th>\n      <th>...</th>\n      <th>LF_PCT</th>\n      <th>LF_NU</th>\n      <th>HF</th>\n      <th>HF_PCT</th>\n      <th>HF_NU</th>\n      <th>TP</th>\n      <th>LF_HF</th>\n      <th>HF_LF</th>\n      <th>sampen</th>\n      <th>higuci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276.697101</td>\n      <td>261.548330</td>\n      <td>281.634094</td>\n      <td>201.939225</td>\n      <td>201.948873</td>\n      <td>306.099269</td>\n      <td>186.792253</td>\n      <td>220.098299</td>\n      <td>219.751609</td>\n      <td>201.948873</td>\n      <td>...</td>\n      <td>209.281585</td>\n      <td>309.383929</td>\n      <td>166.989622</td>\n      <td>170.844721</td>\n      <td>172.502720</td>\n      <td>229.176610</td>\n      <td>309.383929</td>\n      <td>172.502720</td>\n      <td>220.280335</td>\n      <td>160.774105</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>283.060633</td>\n      <td>290.437894</td>\n      <td>183.073989</td>\n      <td>167.021640</td>\n      <td>166.952993</td>\n      <td>215.238532</td>\n      <td>178.099179</td>\n      <td>165.854182</td>\n      <td>166.058400</td>\n      <td>166.952993</td>\n      <td>...</td>\n      <td>175.512435</td>\n      <td>527.319177</td>\n      <td>104.591577</td>\n      <td>111.702021</td>\n      <td>111.394438</td>\n      <td>220.181001</td>\n      <td>527.319177</td>\n      <td>111.394438</td>\n      <td>390.664047</td>\n      <td>91.473882</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>312.856441</td>\n      <td>298.311570</td>\n      <td>333.659979</td>\n      <td>277.912510</td>\n      <td>277.935225</td>\n      <td>309.649467</td>\n      <td>167.908511</td>\n      <td>315.431057</td>\n      <td>277.893149</td>\n      <td>277.935225</td>\n      <td>...</td>\n      <td>211.163474</td>\n      <td>434.164037</td>\n      <td>141.753598</td>\n      <td>139.078646</td>\n      <td>129.723889</td>\n      <td>339.437487</td>\n      <td>434.164037</td>\n      <td>129.723889</td>\n      <td>264.643133</td>\n      <td>147.015168</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>118.124366</td>\n      <td>124.548167</td>\n      <td>136.809099</td>\n      <td>117.415260</td>\n      <td>117.430190</td>\n      <td>221.768654</td>\n      <td>463.050505</td>\n      <td>112.676927</td>\n      <td>57.594885</td>\n      <td>117.430190</td>\n      <td>...</td>\n      <td>165.622387</td>\n      <td>158.516499</td>\n      <td>250.212396</td>\n      <td>280.129440</td>\n      <td>339.707893</td>\n      <td>158.679659</td>\n      <td>158.516499</td>\n      <td>339.707893</td>\n      <td>259.802904</td>\n      <td>193.893174</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>282.869530</td>\n      <td>300.263695</td>\n      <td>289.169845</td>\n      <td>283.041251</td>\n      <td>283.046942</td>\n      <td>248.500700</td>\n      <td>183.634928</td>\n      <td>300.234227</td>\n      <td>309.342415</td>\n      <td>283.046942</td>\n      <td>...</td>\n      <td>179.713401</td>\n      <td>305.818680</td>\n      <td>184.847490</td>\n      <td>165.565337</td>\n      <td>174.383861</td>\n      <td>355.878824</td>\n      <td>305.818680</td>\n      <td>174.383861</td>\n      <td>315.449174</td>\n      <td>240.393451</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      MEAN_RR   MEDIAN_RR        SDRR       RMSSD        SDSD  SDRR_RMSSD  \\\n0  154.981903  130.948799  357.917964  218.603896  218.603896  399.488499   \n1  206.332670  212.064032  158.559158  158.894224  158.894224  188.846044   \n2  108.774609  110.761248  174.510012  123.887169  123.887169  272.919928   \n3  184.635339  206.397936  343.041840  204.879360  204.879360  387.853716   \n4  173.729083  170.568761  115.378578  158.499353  158.499353  143.334814   \n\n           HR       pNN25       pNN50         SD1  ...      LF_PCT  \\\n0  376.844594  226.243094  239.203434  218.603896  ...  181.232421   \n1  240.684831  152.445046   58.596835  158.894224  ...  190.435567   \n2  513.057777  134.679136   58.596835  123.887169  ...  207.303791   \n3  305.771471  206.484818  278.290686  204.879360  ...  166.258531   \n4  289.746416  143.353928   58.596835  158.499353  ...  522.481666   \n\n        LF_NU          HF      HF_PCT       HF_NU          TP       LF_HF  \\\n0  142.039242  396.002894  311.944479  386.663115  242.885987  142.039242   \n1  171.716120  259.323638  280.144485  306.319210  163.331167  171.716120   \n2  223.802244  209.252014  228.533895  232.983896  175.664416  223.802244   \n3  211.404028  272.407888  219.344145  244.743676  281.113670  211.404028   \n4  276.389324  196.987243  244.559104  188.324377  140.363456  276.389324   \n\n        HF_LF      sampen      higuci  \n0  386.663115   94.875043  272.298257  \n1  306.319210  250.749993  301.416603  \n2  232.983896  297.822034  161.413623  \n3  244.743676  194.813778  174.500443  \n4  188.324377  267.048739  166.388660  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEAN_RR</th>\n      <th>MEDIAN_RR</th>\n      <th>SDRR</th>\n      <th>RMSSD</th>\n      <th>SDSD</th>\n      <th>SDRR_RMSSD</th>\n      <th>HR</th>\n      <th>pNN25</th>\n      <th>pNN50</th>\n      <th>SD1</th>\n      <th>...</th>\n      <th>LF_PCT</th>\n      <th>LF_NU</th>\n      <th>HF</th>\n      <th>HF_PCT</th>\n      <th>HF_NU</th>\n      <th>TP</th>\n      <th>LF_HF</th>\n      <th>HF_LF</th>\n      <th>sampen</th>\n      <th>higuci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>154.981903</td>\n      <td>130.948799</td>\n      <td>357.917964</td>\n      <td>218.603896</td>\n      <td>218.603896</td>\n      <td>399.488499</td>\n      <td>376.844594</td>\n      <td>226.243094</td>\n      <td>239.203434</td>\n      <td>218.603896</td>\n      <td>...</td>\n      <td>181.232421</td>\n      <td>142.039242</td>\n      <td>396.002894</td>\n      <td>311.944479</td>\n      <td>386.663115</td>\n      <td>242.885987</td>\n      <td>142.039242</td>\n      <td>386.663115</td>\n      <td>94.875043</td>\n      <td>272.298257</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>206.332670</td>\n      <td>212.064032</td>\n      <td>158.559158</td>\n      <td>158.894224</td>\n      <td>158.894224</td>\n      <td>188.846044</td>\n      <td>240.684831</td>\n      <td>152.445046</td>\n      <td>58.596835</td>\n      <td>158.894224</td>\n      <td>...</td>\n      <td>190.435567</td>\n      <td>171.716120</td>\n      <td>259.323638</td>\n      <td>280.144485</td>\n      <td>306.319210</td>\n      <td>163.331167</td>\n      <td>171.716120</td>\n      <td>306.319210</td>\n      <td>250.749993</td>\n      <td>301.416603</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>108.774609</td>\n      <td>110.761248</td>\n      <td>174.510012</td>\n      <td>123.887169</td>\n      <td>123.887169</td>\n      <td>272.919928</td>\n      <td>513.057777</td>\n      <td>134.679136</td>\n      <td>58.596835</td>\n      <td>123.887169</td>\n      <td>...</td>\n      <td>207.303791</td>\n      <td>223.802244</td>\n      <td>209.252014</td>\n      <td>228.533895</td>\n      <td>232.983896</td>\n      <td>175.664416</td>\n      <td>223.802244</td>\n      <td>232.983896</td>\n      <td>297.822034</td>\n      <td>161.413623</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>184.635339</td>\n      <td>206.397936</td>\n      <td>343.041840</td>\n      <td>204.879360</td>\n      <td>204.879360</td>\n      <td>387.853716</td>\n      <td>305.771471</td>\n      <td>206.484818</td>\n      <td>278.290686</td>\n      <td>204.879360</td>\n      <td>...</td>\n      <td>166.258531</td>\n      <td>211.404028</td>\n      <td>272.407888</td>\n      <td>219.344145</td>\n      <td>244.743676</td>\n      <td>281.113670</td>\n      <td>211.404028</td>\n      <td>244.743676</td>\n      <td>194.813778</td>\n      <td>174.500443</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>173.729083</td>\n      <td>170.568761</td>\n      <td>115.378578</td>\n      <td>158.499353</td>\n      <td>158.499353</td>\n      <td>143.334814</td>\n      <td>289.746416</td>\n      <td>143.353928</td>\n      <td>58.596835</td>\n      <td>158.499353</td>\n      <td>...</td>\n      <td>522.481666</td>\n      <td>276.389324</td>\n      <td>196.987243</td>\n      <td>244.559104</td>\n      <td>188.324377</td>\n      <td>140.363456</td>\n      <td>276.389324</td>\n      <td>188.324377</td>\n      <td>267.048739</td>\n      <td>166.388660</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"            MEAN_RR     MEDIAN_RR          SDRR         RMSSD          SDSD  \\\ncount  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \nmean     272.534334    272.434753    272.534334    272.534334    272.534334   \nstd      161.064480    160.681748    161.064480    161.064480    161.064480   \nmin       57.594885     57.594885     57.594885     57.594885     57.594885   \n25%      161.769849    161.769849    161.769849    161.769849    161.769849   \n50%      229.496375    229.489324    229.496375    229.496375    229.496375   \n75%      332.274137    332.242212    332.274137    332.274137    332.274137   \nmax     1242.394745   1144.375092   1242.394745   1242.394745   1242.394745   \n\n         SDRR_RMSSD            HR         pNN25         pNN50           SD1  \\\ncount  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \nmean     272.534334    272.534334    271.779447    253.502644    272.534334   \nstd      161.064480    161.064480    160.934737    173.991796    161.064480   \nmin       57.594885     57.594885     57.594885     57.594885     57.594885   \n25%      161.769849    161.769849    161.525190    157.635702    161.769849   \n50%      229.496375    229.496375    228.712355    224.236676    229.496375   \n75%      332.274137    332.274137    331.051105    332.262775    332.274137   \nmax     1242.394745   1242.394745   1242.394745   1242.394745   1242.394745   \n\n       ...        LF_PCT         LF_NU            HF        HF_PCT  \\\ncount  ...  30000.000000  30000.000000  30000.000000  30000.000000   \nmean   ...    272.534334    272.534334    272.534334    272.534334   \nstd    ...    161.064480    161.064480    161.064480    161.064480   \nmin    ...     57.594885     57.594885     57.594885     57.594885   \n25%    ...    161.769849    161.769849    161.769849    161.769849   \n50%    ...    229.496375    229.496375    229.496375    229.496375   \n75%    ...    332.274137    332.274137    332.274137    332.274137   \nmax    ...   1242.394745   1242.394745   1242.394745   1242.394745   \n\n              HF_NU            TP         LF_HF         HF_LF        sampen  \\\ncount  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \nmean     272.534334    272.534334    272.534334    272.534334    272.518826   \nstd      161.064480    161.064480    161.064480    161.064480    161.039607   \nmin       57.594885     57.594885     57.594885     57.594885     57.594885   \n25%      161.769849    161.769849    161.769849    161.769849    161.768069   \n50%      229.496375    229.496375    229.496375    229.496375    229.496375   \n75%      332.274137    332.274137    332.274137    332.274137    332.262775   \nmax     1242.394745   1242.394745   1242.394745   1242.394745   1242.394745   \n\n             higuci  \ncount  30000.000000  \nmean     272.534334  \nstd      161.064480  \nmin       57.594885  \n25%      161.769849  \n50%      229.496375  \n75%      332.274137  \nmax     1242.394745  \n\n[8 rows x 34 columns]\n           MEAN_RR    MEDIAN_RR         SDRR        RMSSD         SDSD  \\\ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000   \nmean    270.802541   270.717383   270.802541   270.802541   270.802541   \nstd     160.659658   160.343754   160.659658   160.659658   160.659658   \nmin      58.596835    58.596835    58.596835    58.596835    58.596835   \n25%     160.556477   160.556477   160.556477   160.556477   160.556477   \n50%     228.452560   228.452560   228.452560   228.452560   228.452560   \n75%     330.168948   330.168948   330.168948   330.168948   330.168948   \nmax    1234.324066  1167.337049  1234.324066  1234.324066  1234.324066   \n\n        SDRR_RMSSD           HR        pNN25        pNN50          SD1  ...  \\\ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000  ...   \nmean    270.802541   270.802541   270.047725   252.342726   270.802541  ...   \nstd     160.659658   160.659658   160.541381   173.061263   160.659658  ...   \nmin      58.596835    58.596835    58.596835    58.596835    58.596835  ...   \n25%     160.556477   160.556477   160.241940   156.411510   160.556477  ...   \n50%     228.452560   228.452560   227.704178   223.068524   228.452560  ...   \n75%     330.168948   330.168948   329.177168   327.284772   330.168948  ...   \nmax    1234.324066  1234.324066  1234.324066  1234.324066  1234.324066  ...   \n\n            LF_PCT        LF_NU           HF       HF_PCT        HF_NU  \\\ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000   \nmean    270.802541   270.802541   270.802541   270.802541   270.802541   \nstd     160.659658   160.659658   160.659658   160.659658   160.659658   \nmin      58.596835    58.596835    58.596835    58.596835    58.596835   \n25%     160.556477   160.556477   160.556477   160.556477   160.556477   \n50%     228.452560   228.452560   228.452560   228.452560   228.452560   \n75%     330.168948   330.168948   330.168948   330.168948   330.168948   \nmax    1234.324066  1234.324066  1234.324066  1234.324066  1234.324066   \n\n                TP        LF_HF        HF_LF       sampen       higuci  \ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000  \nmean    270.802541   270.802541   270.802541   270.783826   270.802541  \nstd     160.659658   160.659658   160.659658   160.619619   160.659658  \nmin      58.596835    58.596835    58.596835    58.596835    58.596835  \n25%     160.556477   160.556477   160.556477   160.535503   160.556477  \n50%     228.452560   228.452560   228.452560   228.452560   228.452560  \n75%     330.168948   330.168948   330.168948   330.120840   330.168948  \nmax    1234.324066  1234.324066  1234.324066  1234.324066  1234.324066  \n\n[8 rows x 34 columns]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"gaf = GramianAngularField()\n\nX_train_gaf = gaf.fit_transform(X_train.to_numpy())\nX_test_gaf = gaf.fit_transform(X_test.to_numpy())\n\nX_train_gaf = X_train_gaf.reshape(X_train_gaf.shape[0], 34, 34, 1)\nX_test_gaf = X_test_gaf.reshape(X_test_gaf.shape[0], 34, 34, 1)\n\nX_train_gaf /= np.max(X_train_gaf, axis=(1, 2, 3), keepdims=True)\nX_test_gaf /= np.max(X_test_gaf, axis=(1, 2, 3), keepdims=True)\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=3)\nprint(X_train_gaf.shape)\nprint(X_test_gaf.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:01:11.300628Z","iopub.execute_input":"2025-04-28T13:01:11.301066Z","iopub.status.idle":"2025-04-28T13:01:16.182542Z","shell.execute_reply.started":"2025-04-28T13:01:11.301022Z","shell.execute_reply":"2025-04-28T13:01:16.181230Z"}},"outputs":[{"name":"stdout","text":"(30000, 34, 34, 1)\n(9000, 34, 34, 1)\n(30000, 3)\n(9000, 3)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"x_train_lstm = X_train_gaf.reshape(-1, 34, 34)\nx_test_lstm = X_test_gaf.reshape(-1, 34, 34)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:01:21.345973Z","iopub.execute_input":"2025-04-28T13:01:21.346284Z","iopub.status.idle":"2025-04-28T13:01:21.350827Z","shell.execute_reply.started":"2025-04-28T13:01:21.346261Z","shell.execute_reply":"2025-04-28T13:01:21.349923Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(\"Train set:\", x_train_lstm.shape, y_train.shape)   \nprint(\"Test set:\", x_test_lstm.shape, y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:01:24.784064Z","iopub.execute_input":"2025-04-28T13:01:24.784373Z","iopub.status.idle":"2025-04-28T13:01:24.790528Z","shell.execute_reply.started":"2025-04-28T13:01:24.784349Z","shell.execute_reply":"2025-04-28T13:01:24.789341Z"}},"outputs":[{"name":"stdout","text":"Train set: (30000, 34, 34) (30000, 3)\nTest set: (9000, 34, 34) (9000, 3)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    return true_positives / (predicted_positives + K.epsilon())\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:01:27.440597Z","iopub.execute_input":"2025-04-28T13:01:27.441031Z","iopub.status.idle":"2025-04-28T13:01:27.449435Z","shell.execute_reply.started":"2025-04-28T13:01:27.440991Z","shell.execute_reply":"2025-04-28T13:01:27.448491Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\n# Mean Absolute Error (MAE)\ndef mae_m(y_true, y_pred):\n    y_true = K.cast(y_true, dtype='float32')  \n    y_pred = K.cast(y_pred, dtype='float32')  \n    return K.mean(K.abs(y_true - y_pred))\n\ndef mape_m(y_true, y_pred):\n    y_true = K.cast(y_true, dtype='float32')\n    y_pred = K.cast(y_pred, dtype='float32')\n    diff = K.abs(y_true - y_pred)\n    denom = K.maximum(K.abs(y_true), 1.0)  # Use 1.0 instead of tiny epsilon\n    return 100.0 * K.mean(diff / denom)\n\n# Root Mean Squared Error (RMSE)\ndef rmse_m(y_true, y_pred):\n    y_true = K.cast(y_true, dtype='float32')\n    y_pred = K.cast(y_pred, dtype='float32')\n    return K.sqrt(K.mean(K.square(y_true - y_pred)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:01:30.505588Z","iopub.execute_input":"2025-04-28T13:01:30.505934Z","iopub.status.idle":"2025-04-28T13:01:30.513080Z","shell.execute_reply.started":"2025-04-28T13:01:30.505908Z","shell.execute_reply":"2025-04-28T13:01:30.512150Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, regularizers, callbacks\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, BatchNormalization, Dense\nfrom tensorflow.keras.optimizers import Adam\n\ndef model_LSTM():\n    model = Sequential()\n    model.add(LSTM(64, return_sequences=True, input_shape=(34, 34), activation='tanh'))\n    model.add(BatchNormalization())\n    model.add(LSTM(64, return_sequences=True, activation='tanh'))\n    model.add(BatchNormalization())\n    model.add(LSTM(64, activation='tanh'))\n    model.add(BatchNormalization())\n    model.add(Dense(6)) \n    model.add(Dense(3, activation='softmax'))  \n    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m,mae_m, mape_m, rmse_m])\n    return model\n    \nmodel=model_LSTM()\n\nloss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss=loss,\n    metrics=['accuracy', f1_m, precision_m, recall_m,mae_m, mape_m, rmse_m]\n)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:01:39.558492Z","iopub.execute_input":"2025-04-28T13:01:39.558865Z","iopub.status.idle":"2025-04-28T13:01:39.708153Z","shell.execute_reply.started":"2025-04-28T13:01:39.558839Z","shell.execute_reply":"2025-04-28T13:01:39.707245Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m25,344\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m33,024\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m33,024\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m390\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m21\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,344</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m92,571\u001b[0m (361.61 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,571</span> (361.61 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m92,187\u001b[0m (360.11 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,187</span> (360.11 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"model=model_LSTM()\nmodel_checkpoint = callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor='val_loss', verbose=1)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\nhistory = model.fit(x_train_lstm, y_train, epochs=50, batch_size=32,\n                    validation_data=(x_test_lstm, y_test),\n                    callbacks=[model_checkpoint,reduce_lr])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:01:50.543953Z","iopub.execute_input":"2025-04-28T13:01:50.544267Z","iopub.status.idle":"2025-04-28T13:40:47.382964Z","shell.execute_reply.started":"2025-04-28T13:01:50.544245Z","shell.execute_reply":"2025-04-28T13:40:47.381995Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5333 - f1_m: 0.4718 - loss: 0.9763 - mae_m: 0.3673 - mape_m: 36.7327 - precision_m: 0.6006 - recall_m: 0.3939 - rmse_m: 0.4384\nEpoch 1: val_loss improved from inf to 1.42545, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 50ms/step - accuracy: 0.5334 - f1_m: 0.4720 - loss: 0.9762 - mae_m: 0.3673 - mape_m: 36.7280 - precision_m: 0.6006 - recall_m: 0.3940 - rmse_m: 0.4384 - val_accuracy: 0.4554 - val_f1_m: 0.4358 - val_loss: 1.4254 - val_mae_m: 0.3747 - val_mape_m: 37.4672 - val_precision_m: 0.4493 - val_recall_m: 0.4238 - val_rmse_m: 0.4996 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6963 - f1_m: 0.6797 - loss: 0.6973 - mae_m: 0.2734 - mape_m: 27.3424 - precision_m: 0.7336 - recall_m: 0.6350 - rmse_m: 0.3686\nEpoch 2: val_loss did not improve from 1.42545\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.6963 - f1_m: 0.6798 - loss: 0.6972 - mae_m: 0.2734 - mape_m: 27.3392 - precision_m: 0.7336 - recall_m: 0.6351 - rmse_m: 0.3686 - val_accuracy: 0.4241 - val_f1_m: 0.4171 - val_loss: 1.5348 - val_mae_m: 0.3937 - val_mape_m: 39.3736 - val_precision_m: 0.4311 - val_recall_m: 0.4045 - val_rmse_m: 0.5034 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7684 - f1_m: 0.7611 - loss: 0.5528 - mae_m: 0.2158 - mape_m: 21.5783 - precision_m: 0.7913 - recall_m: 0.7340 - rmse_m: 0.3255\nEpoch 3: val_loss improved from 1.42545 to 1.05431, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.7684 - f1_m: 0.7611 - loss: 0.5528 - mae_m: 0.2158 - mape_m: 21.5772 - precision_m: 0.7913 - recall_m: 0.7340 - rmse_m: 0.3255 - val_accuracy: 0.5491 - val_f1_m: 0.5409 - val_loss: 1.0543 - val_mae_m: 0.3194 - val_mape_m: 31.9421 - val_precision_m: 0.5676 - val_recall_m: 0.5175 - val_rmse_m: 0.4392 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8128 - f1_m: 0.8088 - loss: 0.4623 - mae_m: 0.1792 - mape_m: 17.9207 - precision_m: 0.8308 - recall_m: 0.7887 - rmse_m: 0.2947\nEpoch 4: val_loss did not improve from 1.05431\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.8129 - f1_m: 0.8088 - loss: 0.4623 - mae_m: 0.1792 - mape_m: 17.9199 - precision_m: 0.8308 - recall_m: 0.7887 - rmse_m: 0.2947 - val_accuracy: 0.5376 - val_f1_m: 0.5338 - val_loss: 1.3846 - val_mae_m: 0.3183 - val_mape_m: 31.8252 - val_precision_m: 0.5465 - val_recall_m: 0.5221 - val_rmse_m: 0.4743 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8471 - f1_m: 0.8458 - loss: 0.3830 - mae_m: 0.1475 - mape_m: 14.7524 - precision_m: 0.8607 - recall_m: 0.8319 - rmse_m: 0.2674\nEpoch 5: val_loss did not improve from 1.05431\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.8471 - f1_m: 0.8458 - loss: 0.3830 - mae_m: 0.1475 - mape_m: 14.7518 - precision_m: 0.8607 - recall_m: 0.8319 - rmse_m: 0.2674 - val_accuracy: 0.4124 - val_f1_m: 0.4115 - val_loss: 3.0865 - val_mae_m: 0.3974 - val_mape_m: 39.7366 - val_precision_m: 0.4122 - val_recall_m: 0.4108 - val_rmse_m: 0.5357 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8623 - f1_m: 0.8622 - loss: 0.3406 - mae_m: 0.1303 - mape_m: 13.0272 - precision_m: 0.8745 - recall_m: 0.8505 - rmse_m: 0.2508\nEpoch 6: val_loss did not improve from 1.05431\n\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.8623 - f1_m: 0.8622 - loss: 0.3406 - mae_m: 0.1303 - mape_m: 13.0269 - precision_m: 0.8745 - recall_m: 0.8505 - rmse_m: 0.2508 - val_accuracy: 0.5608 - val_f1_m: 0.5579 - val_loss: 1.7453 - val_mae_m: 0.3069 - val_mape_m: 30.6900 - val_precision_m: 0.5609 - val_recall_m: 0.5551 - val_rmse_m: 0.4692 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9047 - f1_m: 0.9043 - loss: 0.2475 - mae_m: 0.0970 - mape_m: 9.6962 - precision_m: 0.9103 - recall_m: 0.8986 - rmse_m: 0.2095\nEpoch 7: val_loss did not improve from 1.05431\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9047 - f1_m: 0.9043 - loss: 0.2475 - mae_m: 0.0970 - mape_m: 9.6957 - precision_m: 0.9103 - recall_m: 0.8986 - rmse_m: 0.2095 - val_accuracy: 0.6128 - val_f1_m: 0.6108 - val_loss: 1.4811 - val_mae_m: 0.2669 - val_mape_m: 26.6893 - val_precision_m: 0.6143 - val_recall_m: 0.6075 - val_rmse_m: 0.4391 - learning_rate: 5.0000e-04\nEpoch 8/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9148 - f1_m: 0.9139 - loss: 0.2200 - mae_m: 0.0844 - mape_m: 8.4417 - precision_m: 0.9185 - recall_m: 0.9095 - rmse_m: 0.1968\nEpoch 8: val_loss did not improve from 1.05431\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9148 - f1_m: 0.9139 - loss: 0.2199 - mae_m: 0.0844 - mape_m: 8.4411 - precision_m: 0.9186 - recall_m: 0.9095 - rmse_m: 0.1968 - val_accuracy: 0.5863 - val_f1_m: 0.5843 - val_loss: 1.5231 - val_mae_m: 0.2824 - val_mape_m: 28.2354 - val_precision_m: 0.5899 - val_recall_m: 0.5790 - val_rmse_m: 0.4620 - learning_rate: 5.0000e-04\nEpoch 9/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9305 - f1_m: 0.9304 - loss: 0.1876 - mae_m: 0.0721 - mape_m: 7.2110 - precision_m: 0.9340 - recall_m: 0.9269 - rmse_m: 0.1784\nEpoch 9: val_loss did not improve from 1.05431\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9305 - f1_m: 0.9304 - loss: 0.1877 - mae_m: 0.0721 - mape_m: 7.2111 - precision_m: 0.9340 - recall_m: 0.9269 - rmse_m: 0.1784 - val_accuracy: 0.6206 - val_f1_m: 0.6192 - val_loss: 1.3311 - val_mae_m: 0.2612 - val_mape_m: 26.1249 - val_precision_m: 0.6236 - val_recall_m: 0.6149 - val_rmse_m: 0.4237 - learning_rate: 5.0000e-04\nEpoch 10/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9483 - f1_m: 0.9475 - loss: 0.1447 - mae_m: 0.0584 - mape_m: 5.8407 - precision_m: 0.9507 - recall_m: 0.9445 - rmse_m: 0.1537\nEpoch 10: val_loss improved from 1.05431 to 0.45542, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9483 - f1_m: 0.9475 - loss: 0.1447 - mae_m: 0.0584 - mape_m: 5.8404 - precision_m: 0.9507 - recall_m: 0.9445 - rmse_m: 0.1537 - val_accuracy: 0.8397 - val_f1_m: 0.8379 - val_loss: 0.4554 - val_mae_m: 0.1225 - val_mape_m: 12.2481 - val_precision_m: 0.8420 - val_recall_m: 0.8340 - val_rmse_m: 0.2670 - learning_rate: 2.5000e-04\nEpoch 11/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9517 - f1_m: 0.9513 - loss: 0.1334 - mae_m: 0.0522 - mape_m: 5.2150 - precision_m: 0.9531 - recall_m: 0.9495 - rmse_m: 0.1448\nEpoch 11: val_loss did not improve from 0.45542\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9517 - f1_m: 0.9513 - loss: 0.1334 - mae_m: 0.0521 - mape_m: 5.2149 - precision_m: 0.9531 - recall_m: 0.9495 - rmse_m: 0.1448 - val_accuracy: 0.8336 - val_f1_m: 0.8332 - val_loss: 0.4852 - val_mae_m: 0.1265 - val_mape_m: 12.6479 - val_precision_m: 0.8374 - val_recall_m: 0.8292 - val_rmse_m: 0.2837 - learning_rate: 2.5000e-04\nEpoch 12/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9551 - f1_m: 0.9550 - loss: 0.1216 - mae_m: 0.0468 - mape_m: 4.6849 - precision_m: 0.9566 - recall_m: 0.9535 - rmse_m: 0.1372\nEpoch 12: val_loss did not improve from 0.45542\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9551 - f1_m: 0.9550 - loss: 0.1216 - mae_m: 0.0469 - mape_m: 4.6850 - precision_m: 0.9566 - recall_m: 0.9535 - rmse_m: 0.1372 - val_accuracy: 0.6289 - val_f1_m: 0.6280 - val_loss: 1.5293 - val_mae_m: 0.2514 - val_mape_m: 25.1372 - val_precision_m: 0.6306 - val_recall_m: 0.6256 - val_rmse_m: 0.4292 - learning_rate: 2.5000e-04\nEpoch 13/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9585 - f1_m: 0.9581 - loss: 0.1124 - mae_m: 0.0443 - mape_m: 4.4274 - precision_m: 0.9598 - recall_m: 0.9565 - rmse_m: 0.1332\nEpoch 13: val_loss did not improve from 0.45542\n\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9585 - f1_m: 0.9581 - loss: 0.1124 - mae_m: 0.0443 - mape_m: 4.4273 - precision_m: 0.9598 - recall_m: 0.9565 - rmse_m: 0.1332 - val_accuracy: 0.8570 - val_f1_m: 0.8571 - val_loss: 0.4605 - val_mae_m: 0.1131 - val_mape_m: 11.3110 - val_precision_m: 0.8604 - val_recall_m: 0.8539 - val_rmse_m: 0.2683 - learning_rate: 2.5000e-04\nEpoch 14/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9656 - f1_m: 0.9658 - loss: 0.0927 - mae_m: 0.0370 - mape_m: 3.6996 - precision_m: 0.9669 - recall_m: 0.9647 - rmse_m: 0.1163\nEpoch 14: val_loss improved from 0.45542 to 0.29486, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9656 - f1_m: 0.9658 - loss: 0.0926 - mae_m: 0.0370 - mape_m: 3.6993 - precision_m: 0.9669 - recall_m: 0.9647 - rmse_m: 0.1163 - val_accuracy: 0.8992 - val_f1_m: 0.9000 - val_loss: 0.2949 - val_mae_m: 0.0803 - val_mape_m: 8.0308 - val_precision_m: 0.9031 - val_recall_m: 0.8969 - val_rmse_m: 0.2146 - learning_rate: 1.2500e-04\nEpoch 15/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9669 - f1_m: 0.9670 - loss: 0.0887 - mae_m: 0.0351 - mape_m: 3.5145 - precision_m: 0.9681 - recall_m: 0.9660 - rmse_m: 0.1151\nEpoch 15: val_loss did not improve from 0.29486\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9669 - f1_m: 0.9670 - loss: 0.0887 - mae_m: 0.0351 - mape_m: 3.5144 - precision_m: 0.9681 - recall_m: 0.9660 - rmse_m: 0.1151 - val_accuracy: 0.8973 - val_f1_m: 0.8966 - val_loss: 0.3044 - val_mae_m: 0.0815 - val_mape_m: 8.1483 - val_precision_m: 0.8999 - val_recall_m: 0.8935 - val_rmse_m: 0.2167 - learning_rate: 1.2500e-04\nEpoch 16/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9696 - f1_m: 0.9696 - loss: 0.0804 - mae_m: 0.0324 - mape_m: 3.2412 - precision_m: 0.9704 - recall_m: 0.9689 - rmse_m: 0.1088\nEpoch 16: val_loss did not improve from 0.29486\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9696 - f1_m: 0.9696 - loss: 0.0804 - mae_m: 0.0324 - mape_m: 3.2413 - precision_m: 0.9704 - recall_m: 0.9689 - rmse_m: 0.1088 - val_accuracy: 0.7938 - val_f1_m: 0.7939 - val_loss: 0.7286 - val_mae_m: 0.1447 - val_mape_m: 14.4729 - val_precision_m: 0.7969 - val_recall_m: 0.7910 - val_rmse_m: 0.3189 - learning_rate: 1.2500e-04\nEpoch 17/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9709 - f1_m: 0.9713 - loss: 0.0809 - mae_m: 0.0314 - mape_m: 3.1390 - precision_m: 0.9721 - recall_m: 0.9705 - rmse_m: 0.1069\nEpoch 17: val_loss improved from 0.29486 to 0.10436, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 50ms/step - accuracy: 0.9709 - f1_m: 0.9713 - loss: 0.0809 - mae_m: 0.0314 - mape_m: 3.1388 - precision_m: 0.9721 - recall_m: 0.9705 - rmse_m: 0.1069 - val_accuracy: 0.9611 - val_f1_m: 0.9607 - val_loss: 0.1044 - val_mae_m: 0.0350 - val_mape_m: 3.5022 - val_precision_m: 0.9618 - val_recall_m: 0.9596 - val_rmse_m: 0.1132 - learning_rate: 1.2500e-04\nEpoch 18/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9726 - f1_m: 0.9729 - loss: 0.0751 - mae_m: 0.0290 - mape_m: 2.8991 - precision_m: 0.9735 - recall_m: 0.9724 - rmse_m: 0.1019\nEpoch 18: val_loss did not improve from 0.10436\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 51ms/step - accuracy: 0.9726 - f1_m: 0.9729 - loss: 0.0751 - mae_m: 0.0290 - mape_m: 2.8992 - precision_m: 0.9735 - recall_m: 0.9724 - rmse_m: 0.1019 - val_accuracy: 0.9494 - val_f1_m: 0.9496 - val_loss: 0.1319 - val_mae_m: 0.0433 - val_mape_m: 4.3268 - val_precision_m: 0.9514 - val_recall_m: 0.9479 - val_rmse_m: 0.1408 - learning_rate: 1.2500e-04\nEpoch 19/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9718 - f1_m: 0.9718 - loss: 0.0749 - mae_m: 0.0290 - mape_m: 2.9030 - precision_m: 0.9724 - recall_m: 0.9712 - rmse_m: 0.1030\nEpoch 19: val_loss did not improve from 0.10436\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9718 - f1_m: 0.9718 - loss: 0.0749 - mae_m: 0.0290 - mape_m: 2.9030 - precision_m: 0.9724 - recall_m: 0.9712 - rmse_m: 0.1030 - val_accuracy: 0.9183 - val_f1_m: 0.9188 - val_loss: 0.2216 - val_mae_m: 0.0624 - val_mape_m: 6.2434 - val_precision_m: 0.9199 - val_recall_m: 0.9177 - val_rmse_m: 0.1784 - learning_rate: 1.2500e-04\nEpoch 20/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9739 - f1_m: 0.9741 - loss: 0.0750 - mae_m: 0.0282 - mape_m: 2.8244 - precision_m: 0.9747 - recall_m: 0.9736 - rmse_m: 0.0998\nEpoch 20: val_loss did not improve from 0.10436\n\nEpoch 20: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9739 - f1_m: 0.9741 - loss: 0.0750 - mae_m: 0.0282 - mape_m: 2.8243 - precision_m: 0.9747 - recall_m: 0.9736 - rmse_m: 0.0998 - val_accuracy: 0.8879 - val_f1_m: 0.8882 - val_loss: 0.3312 - val_mae_m: 0.0874 - val_mape_m: 8.7410 - val_precision_m: 0.8904 - val_recall_m: 0.8860 - val_rmse_m: 0.2321 - learning_rate: 1.2500e-04\nEpoch 21/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9787 - f1_m: 0.9786 - loss: 0.0592 - mae_m: 0.0245 - mape_m: 2.4465 - precision_m: 0.9792 - recall_m: 0.9780 - rmse_m: 0.0875\nEpoch 21: val_loss improved from 0.10436 to 0.05348, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 51ms/step - accuracy: 0.9787 - f1_m: 0.9786 - loss: 0.0592 - mae_m: 0.0245 - mape_m: 2.4466 - precision_m: 0.9792 - recall_m: 0.9780 - rmse_m: 0.0875 - val_accuracy: 0.9838 - val_f1_m: 0.9840 - val_loss: 0.0535 - val_mae_m: 0.0219 - val_mape_m: 2.1919 - val_precision_m: 0.9844 - val_recall_m: 0.9837 - val_rmse_m: 0.0820 - learning_rate: 6.2500e-05\nEpoch 22/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9780 - f1_m: 0.9778 - loss: 0.0626 - mae_m: 0.0249 - mape_m: 2.4941 - precision_m: 0.9785 - recall_m: 0.9772 - rmse_m: 0.0909\nEpoch 22: val_loss improved from 0.05348 to 0.02867, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 51ms/step - accuracy: 0.9780 - f1_m: 0.9778 - loss: 0.0626 - mae_m: 0.0249 - mape_m: 2.4940 - precision_m: 0.9785 - recall_m: 0.9772 - rmse_m: 0.0909 - val_accuracy: 0.9904 - val_f1_m: 0.9905 - val_loss: 0.0287 - val_mae_m: 0.0112 - val_mape_m: 1.1212 - val_precision_m: 0.9906 - val_recall_m: 0.9905 - val_rmse_m: 0.0475 - learning_rate: 6.2500e-05\nEpoch 23/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9812 - f1_m: 0.9812 - loss: 0.0532 - mae_m: 0.0218 - mape_m: 2.1777 - precision_m: 0.9816 - recall_m: 0.9808 - rmse_m: 0.0813\nEpoch 23: val_loss did not improve from 0.02867\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9812 - f1_m: 0.9812 - loss: 0.0532 - mae_m: 0.0218 - mape_m: 2.1778 - precision_m: 0.9816 - recall_m: 0.9808 - rmse_m: 0.0813 - val_accuracy: 0.9830 - val_f1_m: 0.9831 - val_loss: 0.0493 - val_mae_m: 0.0173 - val_mape_m: 1.7316 - val_precision_m: 0.9832 - val_recall_m: 0.9829 - val_rmse_m: 0.0691 - learning_rate: 6.2500e-05\nEpoch 24/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9819 - f1_m: 0.9818 - loss: 0.0555 - mae_m: 0.0222 - mape_m: 2.2180 - precision_m: 0.9821 - recall_m: 0.9815 - rmse_m: 0.0827\nEpoch 24: val_loss did not improve from 0.02867\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 51ms/step - accuracy: 0.9819 - f1_m: 0.9818 - loss: 0.0555 - mae_m: 0.0222 - mape_m: 2.2181 - precision_m: 0.9821 - recall_m: 0.9815 - rmse_m: 0.0828 - val_accuracy: 0.9829 - val_f1_m: 0.9829 - val_loss: 0.0496 - val_mae_m: 0.0167 - val_mape_m: 1.6727 - val_precision_m: 0.9830 - val_recall_m: 0.9828 - val_rmse_m: 0.0714 - learning_rate: 6.2500e-05\nEpoch 25/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9775 - f1_m: 0.9775 - loss: 0.0585 - mae_m: 0.0231 - mape_m: 2.3146 - precision_m: 0.9781 - recall_m: 0.9770 - rmse_m: 0.0871\nEpoch 25: val_loss did not improve from 0.02867\n\nEpoch 25: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9775 - f1_m: 0.9775 - loss: 0.0585 - mae_m: 0.0231 - mape_m: 2.3146 - precision_m: 0.9781 - recall_m: 0.9770 - rmse_m: 0.0871 - val_accuracy: 0.9868 - val_f1_m: 0.9869 - val_loss: 0.0369 - val_mae_m: 0.0135 - val_mape_m: 1.3457 - val_precision_m: 0.9870 - val_recall_m: 0.9868 - val_rmse_m: 0.0589 - learning_rate: 6.2500e-05\nEpoch 26/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9802 - f1_m: 0.9804 - loss: 0.0540 - mae_m: 0.0217 - mape_m: 2.1708 - precision_m: 0.9807 - recall_m: 0.9800 - rmse_m: 0.0820\nEpoch 26: val_loss did not improve from 0.02867\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9802 - f1_m: 0.9804 - loss: 0.0540 - mae_m: 0.0217 - mape_m: 2.1706 - precision_m: 0.9807 - recall_m: 0.9800 - rmse_m: 0.0820 - val_accuracy: 0.9883 - val_f1_m: 0.9884 - val_loss: 0.0325 - val_mae_m: 0.0145 - val_mape_m: 1.4463 - val_precision_m: 0.9885 - val_recall_m: 0.9883 - val_rmse_m: 0.0606 - learning_rate: 3.1250e-05\nEpoch 27/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9827 - f1_m: 0.9828 - loss: 0.0489 - mae_m: 0.0199 - mape_m: 1.9873 - precision_m: 0.9830 - recall_m: 0.9825 - rmse_m: 0.0758\nEpoch 27: val_loss improved from 0.02867 to 0.02161, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9827 - f1_m: 0.9828 - loss: 0.0489 - mae_m: 0.0199 - mape_m: 1.9873 - precision_m: 0.9831 - recall_m: 0.9825 - rmse_m: 0.0758 - val_accuracy: 0.9934 - val_f1_m: 0.9935 - val_loss: 0.0216 - val_mae_m: 0.0082 - val_mape_m: 0.8178 - val_precision_m: 0.9935 - val_recall_m: 0.9935 - val_rmse_m: 0.0389 - learning_rate: 3.1250e-05\nEpoch 28/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9820 - f1_m: 0.9819 - loss: 0.0510 - mae_m: 0.0205 - mape_m: 2.0522 - precision_m: 0.9822 - recall_m: 0.9815 - rmse_m: 0.0785\nEpoch 28: val_loss did not improve from 0.02161\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9820 - f1_m: 0.9819 - loss: 0.0510 - mae_m: 0.0205 - mape_m: 2.0522 - precision_m: 0.9822 - recall_m: 0.9815 - rmse_m: 0.0785 - val_accuracy: 0.9903 - val_f1_m: 0.9903 - val_loss: 0.0312 - val_mae_m: 0.0121 - val_mape_m: 1.2104 - val_precision_m: 0.9905 - val_recall_m: 0.9901 - val_rmse_m: 0.0527 - learning_rate: 3.1250e-05\nEpoch 29/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9838 - f1_m: 0.9836 - loss: 0.0462 - mae_m: 0.0191 - mape_m: 1.9058 - precision_m: 0.9840 - recall_m: 0.9833 - rmse_m: 0.0733\nEpoch 29: val_loss improved from 0.02161 to 0.01917, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9838 - f1_m: 0.9836 - loss: 0.0462 - mae_m: 0.0191 - mape_m: 1.9058 - precision_m: 0.9840 - recall_m: 0.9833 - rmse_m: 0.0733 - val_accuracy: 0.9943 - val_f1_m: 0.9943 - val_loss: 0.0192 - val_mae_m: 0.0083 - val_mape_m: 0.8255 - val_precision_m: 0.9943 - val_recall_m: 0.9943 - val_rmse_m: 0.0377 - learning_rate: 3.1250e-05\nEpoch 30/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9814 - f1_m: 0.9816 - loss: 0.0501 - mae_m: 0.0202 - mape_m: 2.0245 - precision_m: 0.9821 - recall_m: 0.9810 - rmse_m: 0.0775\nEpoch 30: val_loss did not improve from 0.01917\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9814 - f1_m: 0.9816 - loss: 0.0501 - mae_m: 0.0202 - mape_m: 2.0244 - precision_m: 0.9821 - recall_m: 0.9810 - rmse_m: 0.0775 - val_accuracy: 0.9861 - val_f1_m: 0.9861 - val_loss: 0.0418 - val_mae_m: 0.0146 - val_mape_m: 1.4559 - val_precision_m: 0.9865 - val_recall_m: 0.9858 - val_rmse_m: 0.0643 - learning_rate: 3.1250e-05\nEpoch 31/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9834 - f1_m: 0.9834 - loss: 0.0499 - mae_m: 0.0192 - mape_m: 1.9249 - precision_m: 0.9837 - recall_m: 0.9832 - rmse_m: 0.0743\nEpoch 31: val_loss did not improve from 0.01917\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9834 - f1_m: 0.9834 - loss: 0.0499 - mae_m: 0.0192 - mape_m: 1.9249 - precision_m: 0.9837 - recall_m: 0.9832 - rmse_m: 0.0743 - val_accuracy: 0.9930 - val_f1_m: 0.9930 - val_loss: 0.0243 - val_mae_m: 0.0103 - val_mape_m: 1.0329 - val_precision_m: 0.9930 - val_recall_m: 0.9930 - val_rmse_m: 0.0466 - learning_rate: 3.1250e-05\nEpoch 32/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9833 - f1_m: 0.9832 - loss: 0.0467 - mae_m: 0.0193 - mape_m: 1.9254 - precision_m: 0.9834 - recall_m: 0.9831 - rmse_m: 0.0749\nEpoch 32: val_loss did not improve from 0.01917\n\nEpoch 32: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9833 - f1_m: 0.9832 - loss: 0.0467 - mae_m: 0.0193 - mape_m: 1.9254 - precision_m: 0.9834 - recall_m: 0.9831 - rmse_m: 0.0749 - val_accuracy: 0.9881 - val_f1_m: 0.9880 - val_loss: 0.0328 - val_mae_m: 0.0132 - val_mape_m: 1.3159 - val_precision_m: 0.9881 - val_recall_m: 0.9879 - val_rmse_m: 0.0576 - learning_rate: 3.1250e-05\nEpoch 33/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9828 - f1_m: 0.9828 - loss: 0.0481 - mae_m: 0.0197 - mape_m: 1.9700 - precision_m: 0.9830 - recall_m: 0.9825 - rmse_m: 0.0756\nEpoch 33: val_loss did not improve from 0.01917\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9828 - f1_m: 0.9828 - loss: 0.0481 - mae_m: 0.0197 - mape_m: 1.9697 - precision_m: 0.9830 - recall_m: 0.9825 - rmse_m: 0.0756 - val_accuracy: 0.9914 - val_f1_m: 0.9915 - val_loss: 0.0282 - val_mae_m: 0.0117 - val_mape_m: 1.1730 - val_precision_m: 0.9916 - val_recall_m: 0.9915 - val_rmse_m: 0.0517 - learning_rate: 1.5625e-05\nEpoch 34/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9848 - f1_m: 0.9848 - loss: 0.0427 - mae_m: 0.0176 - mape_m: 1.7623 - precision_m: 0.9850 - recall_m: 0.9845 - rmse_m: 0.0696\nEpoch 34: val_loss did not improve from 0.01917\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9848 - f1_m: 0.9848 - loss: 0.0427 - mae_m: 0.0176 - mape_m: 1.7623 - precision_m: 0.9850 - recall_m: 0.9845 - rmse_m: 0.0696 - val_accuracy: 0.9929 - val_f1_m: 0.9929 - val_loss: 0.0208 - val_mae_m: 0.0080 - val_mape_m: 0.7972 - val_precision_m: 0.9929 - val_recall_m: 0.9929 - val_rmse_m: 0.0381 - learning_rate: 1.5625e-05\nEpoch 35/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9861 - f1_m: 0.9861 - loss: 0.0392 - mae_m: 0.0169 - mape_m: 1.6853 - precision_m: 0.9864 - recall_m: 0.9859 - rmse_m: 0.0664\nEpoch 35: val_loss did not improve from 0.01917\n\nEpoch 35: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9860 - f1_m: 0.9861 - loss: 0.0392 - mae_m: 0.0169 - mape_m: 1.6853 - precision_m: 0.9864 - recall_m: 0.9858 - rmse_m: 0.0664 - val_accuracy: 0.9941 - val_f1_m: 0.9941 - val_loss: 0.0194 - val_mae_m: 0.0080 - val_mape_m: 0.7988 - val_precision_m: 0.9941 - val_recall_m: 0.9941 - val_rmse_m: 0.0367 - learning_rate: 1.5625e-05\nEpoch 36/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9860 - f1_m: 0.9860 - loss: 0.0404 - mae_m: 0.0168 - mape_m: 1.6785 - precision_m: 0.9863 - recall_m: 0.9857 - rmse_m: 0.0686\nEpoch 36: val_loss improved from 0.01917 to 0.01800, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9860 - f1_m: 0.9860 - loss: 0.0404 - mae_m: 0.0168 - mape_m: 1.6785 - precision_m: 0.9863 - recall_m: 0.9857 - rmse_m: 0.0686 - val_accuracy: 0.9944 - val_f1_m: 0.9945 - val_loss: 0.0180 - val_mae_m: 0.0072 - val_mape_m: 0.7184 - val_precision_m: 0.9946 - val_recall_m: 0.9945 - val_rmse_m: 0.0350 - learning_rate: 7.8125e-06\nEpoch 37/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9827 - f1_m: 0.9830 - loss: 0.0482 - mae_m: 0.0189 - mape_m: 1.8876 - precision_m: 0.9833 - recall_m: 0.9826 - rmse_m: 0.0727\nEpoch 37: val_loss improved from 0.01800 to 0.01743, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9827 - f1_m: 0.9830 - loss: 0.0482 - mae_m: 0.0189 - mape_m: 1.8875 - precision_m: 0.9833 - recall_m: 0.9826 - rmse_m: 0.0727 - val_accuracy: 0.9951 - val_f1_m: 0.9951 - val_loss: 0.0174 - val_mae_m: 0.0068 - val_mape_m: 0.6761 - val_precision_m: 0.9952 - val_recall_m: 0.9950 - val_rmse_m: 0.0320 - learning_rate: 7.8125e-06\nEpoch 38/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9850 - f1_m: 0.9851 - loss: 0.0417 - mae_m: 0.0172 - mape_m: 1.7175 - precision_m: 0.9852 - recall_m: 0.9849 - rmse_m: 0.0690\nEpoch 38: val_loss improved from 0.01743 to 0.01730, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9850 - f1_m: 0.9851 - loss: 0.0418 - mae_m: 0.0172 - mape_m: 1.7175 - precision_m: 0.9852 - recall_m: 0.9849 - rmse_m: 0.0691 - val_accuracy: 0.9951 - val_f1_m: 0.9952 - val_loss: 0.0173 - val_mae_m: 0.0067 - val_mape_m: 0.6730 - val_precision_m: 0.9952 - val_recall_m: 0.9951 - val_rmse_m: 0.0330 - learning_rate: 7.8125e-06\nEpoch 39/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9846 - f1_m: 0.9845 - loss: 0.0438 - mae_m: 0.0173 - mape_m: 1.7279 - precision_m: 0.9847 - recall_m: 0.9843 - rmse_m: 0.0701\nEpoch 39: val_loss did not improve from 0.01730\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9846 - f1_m: 0.9845 - loss: 0.0438 - mae_m: 0.0173 - mape_m: 1.7279 - precision_m: 0.9847 - recall_m: 0.9843 - rmse_m: 0.0701 - val_accuracy: 0.9943 - val_f1_m: 0.9943 - val_loss: 0.0183 - val_mae_m: 0.0070 - val_mape_m: 0.6982 - val_precision_m: 0.9943 - val_recall_m: 0.9943 - val_rmse_m: 0.0335 - learning_rate: 7.8125e-06\nEpoch 40/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9838 - f1_m: 0.9837 - loss: 0.0424 - mae_m: 0.0173 - mape_m: 1.7334 - precision_m: 0.9841 - recall_m: 0.9833 - rmse_m: 0.0704\nEpoch 40: val_loss did not improve from 0.01730\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9838 - f1_m: 0.9837 - loss: 0.0424 - mae_m: 0.0173 - mape_m: 1.7335 - precision_m: 0.9841 - recall_m: 0.9833 - rmse_m: 0.0704 - val_accuracy: 0.9948 - val_f1_m: 0.9949 - val_loss: 0.0174 - val_mae_m: 0.0068 - val_mape_m: 0.6836 - val_precision_m: 0.9950 - val_recall_m: 0.9948 - val_rmse_m: 0.0334 - learning_rate: 7.8125e-06\nEpoch 41/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9863 - f1_m: 0.9863 - loss: 0.0405 - mae_m: 0.0167 - mape_m: 1.6689 - precision_m: 0.9866 - recall_m: 0.9860 - rmse_m: 0.0666\nEpoch 41: val_loss did not improve from 0.01730\n\nEpoch 41: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9863 - f1_m: 0.9863 - loss: 0.0405 - mae_m: 0.0167 - mape_m: 1.6689 - precision_m: 0.9866 - recall_m: 0.9860 - rmse_m: 0.0666 - val_accuracy: 0.9940 - val_f1_m: 0.9941 - val_loss: 0.0198 - val_mae_m: 0.0073 - val_mape_m: 0.7319 - val_precision_m: 0.9941 - val_recall_m: 0.9940 - val_rmse_m: 0.0358 - learning_rate: 7.8125e-06\nEpoch 42/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9852 - f1_m: 0.9851 - loss: 0.0421 - mae_m: 0.0173 - mape_m: 1.7279 - precision_m: 0.9854 - recall_m: 0.9849 - rmse_m: 0.0690\nEpoch 42: val_loss improved from 0.01730 to 0.01714, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9852 - f1_m: 0.9851 - loss: 0.0421 - mae_m: 0.0173 - mape_m: 1.7279 - precision_m: 0.9854 - recall_m: 0.9849 - rmse_m: 0.0690 - val_accuracy: 0.9956 - val_f1_m: 0.9956 - val_loss: 0.0171 - val_mae_m: 0.0066 - val_mape_m: 0.6586 - val_precision_m: 0.9956 - val_recall_m: 0.9956 - val_rmse_m: 0.0324 - learning_rate: 3.9063e-06\nEpoch 43/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9869 - f1_m: 0.9865 - loss: 0.0396 - mae_m: 0.0162 - mape_m: 1.6155 - precision_m: 0.9869 - recall_m: 0.9861 - rmse_m: 0.0646\nEpoch 43: val_loss did not improve from 0.01714\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9869 - f1_m: 0.9865 - loss: 0.0396 - mae_m: 0.0162 - mape_m: 1.6155 - precision_m: 0.9869 - recall_m: 0.9861 - rmse_m: 0.0646 - val_accuracy: 0.9952 - val_f1_m: 0.9953 - val_loss: 0.0176 - val_mae_m: 0.0067 - val_mape_m: 0.6724 - val_precision_m: 0.9953 - val_recall_m: 0.9952 - val_rmse_m: 0.0331 - learning_rate: 3.9063e-06\nEpoch 44/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9857 - f1_m: 0.9857 - loss: 0.0420 - mae_m: 0.0167 - mape_m: 1.6713 - precision_m: 0.9859 - recall_m: 0.9856 - rmse_m: 0.0678\nEpoch 44: val_loss improved from 0.01714 to 0.01681, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9857 - f1_m: 0.9857 - loss: 0.0420 - mae_m: 0.0167 - mape_m: 1.6713 - precision_m: 0.9859 - recall_m: 0.9856 - rmse_m: 0.0678 - val_accuracy: 0.9958 - val_f1_m: 0.9957 - val_loss: 0.0168 - val_mae_m: 0.0065 - val_mape_m: 0.6522 - val_precision_m: 0.9958 - val_recall_m: 0.9957 - val_rmse_m: 0.0319 - learning_rate: 3.9063e-06\nEpoch 45/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9871 - f1_m: 0.9872 - loss: 0.0378 - mae_m: 0.0158 - mape_m: 1.5804 - precision_m: 0.9875 - recall_m: 0.9870 - rmse_m: 0.0644\nEpoch 45: val_loss did not improve from 0.01681\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9871 - f1_m: 0.9872 - loss: 0.0378 - mae_m: 0.0158 - mape_m: 1.5804 - precision_m: 0.9875 - recall_m: 0.9870 - rmse_m: 0.0644 - val_accuracy: 0.9943 - val_f1_m: 0.9945 - val_loss: 0.0183 - val_mae_m: 0.0069 - val_mape_m: 0.6876 - val_precision_m: 0.9946 - val_recall_m: 0.9943 - val_rmse_m: 0.0339 - learning_rate: 3.9063e-06\nEpoch 46/50\n\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9832 - f1_m: 0.9834 - loss: 0.0435 - mae_m: 0.0173 - mape_m: 1.7305 - precision_m: 0.9838 - recall_m: 0.9830 - rmse_m: 0.0703\nEpoch 46: val_loss improved from 0.01681 to 0.01614, saving model to best_model.keras\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9832 - f1_m: 0.9834 - loss: 0.0435 - mae_m: 0.0173 - mape_m: 1.7304 - precision_m: 0.9838 - recall_m: 0.9830 - rmse_m: 0.0703 - val_accuracy: 0.9956 - val_f1_m: 0.9955 - val_loss: 0.0161 - val_mae_m: 0.0063 - val_mape_m: 0.6330 - val_precision_m: 0.9956 - val_recall_m: 0.9955 - val_rmse_m: 0.0308 - learning_rate: 3.9063e-06\nEpoch 47/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9859 - f1_m: 0.9859 - loss: 0.0406 - mae_m: 0.0165 - mape_m: 1.6499 - precision_m: 0.9861 - recall_m: 0.9858 - rmse_m: 0.0672\nEpoch 47: val_loss did not improve from 0.01614\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9859 - f1_m: 0.9859 - loss: 0.0406 - mae_m: 0.0165 - mape_m: 1.6499 - precision_m: 0.9861 - recall_m: 0.9858 - rmse_m: 0.0672 - val_accuracy: 0.9959 - val_f1_m: 0.9960 - val_loss: 0.0163 - val_mae_m: 0.0064 - val_mape_m: 0.6353 - val_precision_m: 0.9960 - val_recall_m: 0.9959 - val_rmse_m: 0.0314 - learning_rate: 3.9063e-06\nEpoch 48/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9854 - f1_m: 0.9855 - loss: 0.0399 - mae_m: 0.0164 - mape_m: 1.6398 - precision_m: 0.9857 - recall_m: 0.9853 - rmse_m: 0.0671\nEpoch 48: val_loss did not improve from 0.01614\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 51ms/step - accuracy: 0.9854 - f1_m: 0.9855 - loss: 0.0399 - mae_m: 0.0164 - mape_m: 1.6398 - precision_m: 0.9857 - recall_m: 0.9853 - rmse_m: 0.0671 - val_accuracy: 0.9953 - val_f1_m: 0.9953 - val_loss: 0.0169 - val_mae_m: 0.0064 - val_mape_m: 0.6448 - val_precision_m: 0.9955 - val_recall_m: 0.9952 - val_rmse_m: 0.0321 - learning_rate: 3.9063e-06\nEpoch 49/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9851 - f1_m: 0.9851 - loss: 0.0400 - mae_m: 0.0164 - mape_m: 1.6355 - precision_m: 0.9852 - recall_m: 0.9850 - rmse_m: 0.0665\nEpoch 49: val_loss did not improve from 0.01614\n\nEpoch 49: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9851 - f1_m: 0.9851 - loss: 0.0400 - mae_m: 0.0164 - mape_m: 1.6356 - precision_m: 0.9852 - recall_m: 0.9850 - rmse_m: 0.0665 - val_accuracy: 0.9944 - val_f1_m: 0.9945 - val_loss: 0.0190 - val_mae_m: 0.0070 - val_mape_m: 0.6972 - val_precision_m: 0.9945 - val_recall_m: 0.9945 - val_rmse_m: 0.0343 - learning_rate: 3.9063e-06\nEpoch 50/50\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9858 - f1_m: 0.9858 - loss: 0.0418 - mae_m: 0.0162 - mape_m: 1.6172 - precision_m: 0.9860 - recall_m: 0.9856 - rmse_m: 0.0661\nEpoch 50: val_loss did not improve from 0.01614\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9858 - f1_m: 0.9858 - loss: 0.0418 - mae_m: 0.0162 - mape_m: 1.6172 - precision_m: 0.9860 - recall_m: 0.9856 - rmse_m: 0.0661 - val_accuracy: 0.9960 - val_f1_m: 0.9961 - val_loss: 0.0166 - val_mae_m: 0.0063 - val_mape_m: 0.6265 - val_precision_m: 0.9961 - val_recall_m: 0.9960 - val_rmse_m: 0.0310 - learning_rate: 1.9531e-06\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy, f1_score, precision, recall, mae, mape, rmse = model.evaluate(x_test_lstm, y_test, verbose=0)\n\n# Print results\nprint(f\"Validation Loss: {loss:.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"Mean Absolute Error (MAE): {mae:.4f}\")\nprint(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:50:08.123555Z","iopub.execute_input":"2025-04-28T13:50:08.123897Z","iopub.status.idle":"2025-04-28T13:50:12.967910Z","shell.execute_reply.started":"2025-04-28T13:50:08.123874Z","shell.execute_reply":"2025-04-28T13:50:12.967049Z"}},"outputs":[{"name":"stdout","text":"Validation Loss: 0.0166\nAccuracy: 0.9960\nF1 Score: 0.9961\nPrecision: 0.9961\nRecall: 0.9960\nMean Absolute Error (MAE): 0.0063\nMean Absolute Percentage Error (MAPE): 0.6265\nRoot Mean Squared Error (RMSE): 0.0310\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_actual_vs_predicted(model, x_test, y_test):\n    # Predict\n    y_pred_probs = model.predict(x_test, batch_size=64, verbose=1)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true = np.argmax(y_test, axis=1)\n\n    # Confirm correct number of samples\n    print(f\"Number of test samples: {len(y_true)}\")\n    print(f\"Number of predictions: {len(y_pred)}\")\n\n    if len(y_true) != len(y_pred):\n        print(\"Mismatch between test samples and predictions!\")\n        return\n\n    # Classes\n    classes = np.unique(y_true)\n    print(f\"Classes found in test set: {classes}\")\n\n    # True and Predicted counts\n    true_counts = [np.sum(y_true == cls) for cls in classes]\n    pred_counts = [np.sum(y_pred == cls) for cls in classes]\n\n    # Correct predictions per class\n    correct_counts = [np.sum((y_true == cls) & (y_pred == cls)) for cls in classes]\n\n    # Per-class accuracy (percentage of correct predictions)\n    class_accuracy = [\n        (correct_counts[i] / true_counts[i]) * 100 if true_counts[i] != 0 else 0\n        for i in range(len(classes))\n    ]\n\n    # Total accuracy\n    total_correct = np.sum(y_true == y_pred)\n    total_samples = len(y_true)\n    total_accuracy = (total_correct / total_samples) * 100\n\n    # Print per-class accuracy\n    print(\"\\nPer-Class Accuracy (Correct Predictions Percentage):\")\n    for i, acc in enumerate(class_accuracy):\n        print(f\"  Class {classes[i]}: {acc:.2f}%\")\n    print(f\"\\nTotal Test Accuracy: {total_accuracy:.2f}%\")\n\n    # Bar plot Actual vs Predicted\n    x = np.arange(len(classes))\n    width = 0.35\n\n    fig, ax = plt.subplots(figsize=(10, 7))\n    rects1 = ax.bar(x - width/2, true_counts, width, label='Actual Count', color='lightblue')\n    rects2 = ax.bar(x + width/2, pred_counts, width, label='Predicted Count', color='salmon')\n\n    ax.set_xlabel('Class Labels')\n    ax.set_ylabel('Number of Samples')\n    ax.set_title(f'Actual vs Predicted Samples (Total Accuracy: {total_accuracy:.2f}%)')\n    ax.set_xticks(x)\n    ax.set_xticklabels(classes)\n    \n    ax.legend(loc='lower center', bbox_to_anchor=(0.5, 1.05),\n              ncol=2, fancybox=True, shadow=True)\n\n\n    # Annotate bar heights\n    def autolabel(rects):\n        for rect in rects:\n            height = rect.get_height()\n            ax.annotate(f'{int(height)}',\n                        xy=(rect.get_x() + rect.get_width() / 2, height),\n                        xytext=(0, 3),\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom')\n\n    autolabel(rects1)\n    autolabel(rects2)\n\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\nplot_actual_vs_predicted(model, x_test_lstm, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:50:55.871309Z","iopub.execute_input":"2025-04-28T13:50:55.871617Z","iopub.status.idle":"2025-04-28T13:51:01.484292Z","shell.execute_reply.started":"2025-04-28T13:50:55.871596Z","shell.execute_reply":"2025-04-28T13:51:01.483241Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step\nNumber of test samples: 9000\nNumber of predictions: 9000\nClasses found in test set: [0 1 2]\n\nPer-Class Accuracy (Correct Predictions Percentage):\n  Class 0: 99.23%\n  Class 1: 99.73%\n  Class 2: 99.83%\n\nTotal Test Accuracy: 99.60%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x700 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\ndef plot_precision_recall_f1(model, x_test, y_test):\n    # Predict\n    y_pred_probs = model.predict(x_test, batch_size=64, verbose=1)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true = np.argmax(y_test, axis=1)\n\n    # Confirm correct number of samples\n    print(f\"Number of test samples: {len(y_true)}\")\n    print(f\"Number of predictions: {len(y_pred)}\")\n\n    if len(y_true) != len(y_pred):\n        print(\"Mismatch between test samples and predictions!\")\n        return\n\n    # Classes\n    classes = np.unique(y_true)\n    print(f\"Classes found in test set: {classes}\")\n\n    # Calculate metrics per class\n    precision = precision_score(y_true, y_pred, labels=classes, average=None)\n    recall = recall_score(y_true, y_pred, labels=classes, average=None)\n    f1 = f1_score(y_true, y_pred, labels=classes, average=None)\n\n    # Print\n    print(\"\\nPer-Class Precision, Recall, F1-Score:\")\n    for idx, cls in enumerate(classes):\n        print(f\"Class {cls} -> Precision: {precision[idx]:.4f}, Recall: {recall[idx]:.4f}, F1-Score: {f1[idx]:.4f}\")\n\n    # Plot\n    x = np.arange(len(classes))\n    width = 0.25  # bar width\n\n    fig, ax = plt.subplots(figsize=(12, 7))\n    rects1 = ax.bar(x - width, precision, width, label='Precision', color='skyblue')\n    rects2 = ax.bar(x, recall, width, label='Recall', color='lightgreen')\n    rects3 = ax.bar(x + width, f1, width, label='F1-Score', color='salmon')\n\n    ax.set_xlabel('Class Labels')\n    ax.set_ylabel('Score')\n    ax.set_title('Precision, Recall, F1-Score per Class')\n    ax.set_xticks(x)\n    ax.set_xticklabels(classes)\n    ax.set_ylim(0, 1.05)\n    ax.legend(loc='lower center', bbox_to_anchor=(0.5, 1.05),\n              ncol=3, fancybox=True, shadow=True)\n\n    # Annotate bar heights\n    def autolabel(rects):\n        for rect in rects:\n            height = rect.get_height()\n            ax.annotate(f'{height:.2f}',\n                        xy=(rect.get_x() + rect.get_width() / 2, height),\n                        xytext=(0, 3),\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom')\n\n    autolabel(rects1)\n    autolabel(rects2)\n    autolabel(rects3)\n\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\nplot_precision_recall_f1(model, x_test_lstm, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:51:17.381385Z","iopub.execute_input":"2025-04-28T13:51:17.381714Z","iopub.status.idle":"2025-04-28T13:51:21.240640Z","shell.execute_reply.started":"2025-04-28T13:51:17.381662Z","shell.execute_reply":"2025-04-28T13:51:21.239741Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step\nNumber of test samples: 9000\nNumber of predictions: 9000\nClasses found in test set: [0 1 2]\n\nPer-Class Precision, Recall, F1-Score:\nClass 0 -> Precision: 0.9967, Recall: 0.9923, F1-Score: 0.9945\nClass 1 -> Precision: 0.9980, Recall: 0.9973, F1-Score: 0.9977\nClass 2 -> Precision: 0.9934, Recall: 0.9983, F1-Score: 0.9958\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x700 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":15}]}